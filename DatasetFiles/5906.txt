


Paper ID = 5906
Title = Recovering Communities in the General Stochastic
Block Model Without Knowing the Parameters
Emmanuel Abbe
Department of Electrical Engineering and PACM
Princeton University
Princeton, NJ 08540
eabbe@princeton.edu
Colin Sandon
Department of Mathematics
Princeton University
Princeton, NJ 08540
sandon@princeton.edu
Abstract
The stochastic block model (SBM) has recently gathered significant attention due
to new threshold phenomena. However, most developments rely on the knowledge
of the model parameters, or at least on the number of communities. This paper in-
troduces efficient algorithms that do not require such knowledge and yet achieve
the optimal information-theoretic tradeoffs identified in Abbe-Sandon FOCS15.
In the constant degree regime, an algorithm is developed that requires only a
lower-bound on the relative sizes of the communities and achieves the optimal
accuracy scaling for large degrees. This lower-bound requirement is removed for
the regime of arbitrarily slowly diverging degrees, and the model parameters are
learned efficiently. For the logarithmic degree regime, this is further enhanced into
a fully agnostic algorithm that achieves the CH-limit for exact recovery in quasi-
linear time. These provide the first algorithms affording efficiency, universality
and information-theoretic optimality for strong and weak consistency in the SBM.
1 Introduction
This paper studies the problem of recovering communities in the general stochastic block model
with linear size communities, for constant and logarithmic degree regimes. In contrast to [1], this
paper does not require knowledge of the parameters. It shows how to learn these from the graph
toplogy. We next provide some motivations on the problem and further background on the model.
Detecting communities (or clusters) in graphs is a fundamental problem in networks, computer
science and machine learning. This applies to a large variety of complex networks (e.g., social and
biological networks) as well as to data sets engineered as networks via similarly graphs, where one
often attempts to get a first impression on the data by trying to identify groups with similar behavior.
In particular, finding communities allows one to find like-minded people in social networks, to
improve recommendation systems, to segment or classify images, to detect protein complexes, to
find genetically related sub-populations, or discover new tumor subclasses. See [1] for references.
While a large variety of community detection algorithms have been deployed in the past decades, the
understanding of the fundamental limits of community detection has only appeared more recently,
in particular for the SBM [1â€“7]. The SBM is a canonical model for community detection. We use
here the notation SBM(n, p,W ) to refer to a random graph ensemble on the vertex-set V = [n],
where each vertex v âˆˆ V is assigned independently a hidden (or planted) label Ïƒv in [k] under a
probability distribution p = (p1, . . . , pk) on [k], and each unordered pair of nodes (u, v) âˆˆ V Ã— V
is connected independently with probability WÏƒu,Ïƒv , where W is a symmetric k Ã— k matrix with
entries in [0, 1]. Note that G âˆ¼ SBM(n, p,W ) denotes a random graph drawn under this model,
without the hidden (or planted) clusters (i.e., the labels Ïƒv) revealed. The goal is to recover these
labels by observing only the graph.
1
Recently the SBM came back at the center of the attention at both the practical level, due to ex-
tensions allowing overlapping communities that have proved to fit well real data sets in massive
networks [8], and at the theoretical level due to new phase transition phenomena [2â€“6]. The latter
works focus exclusively on the SBM with two symmetric communities, i.e., each community is of
the same size and the connectivity in each community is identical. Denoting by p the intra- and q
the extra-cluster probabilities, most of the results are concerned with two figure of merits: (i) re-
covery (also called exact recovery or strong consistency), which investigates the regimes of p and
q for which there exists an algorithm that recovers with high probability the two communities com-
pletely [7, 9â€“19], (ii) detection, which investigates the regimes for which there exists an algorithm
that recovers with high probability a positively correlated partition [2â€“4].
The sharp threshold for exact recovery was obtained in [5, 6], showing1 that for p = a log(n)/n,
q = b log(n)/n, a, b > 0, exact recovery is solvable if and only if |
âˆš
a âˆ’
âˆš
b| â‰¥
âˆš
2, with efficient
algorithms achieving the threshold. In addition, [5] introduces an SDP, proved to achieve the thresh-
old in [20, 21], while [22] shows that a spectral algorithm also achieves the threshold. The sharp
threshold for detection was obtained in [3, 4], showing that detection is solvable (and so efficiently)
if and only if (aâˆ’ b)2 > 2(a+ b), when p = a/n, q = b/n, settling a conjecture from [2].
Besides the detection and the recovery properties, one may ask about the partial recovery of the
communities, studied in [1, 19, 23â€“25]. Of particular interest to this paper is the case of strong
recovery (also called weak consistency), where only a vanishing fraction of the nodes is allowed to
be misclassified. For two-symmetric communities, [6] shows that strong recovery is possible if and
only if n(pâˆ’ q)2/(p+ q) diverges, extended in [1] for general SBMs.
In the next section, we discuss the results for the general SBM of interest in this paper and the
problem of learning the model parameters. We conclude this section by providing motivations on
the problem of achieving the threshold with an efficient and universal algorithm.
Threshold phenomena have long been studied in fields such as information theory (e.g., Shannonâ€™s
capacity) and constrained satisfaction problems (e.g., the SAT threshold). In particular, the quest of
achieving the threshold has generated major algorithmic developments in these fields (e.g., LDPC
codes, polar codes, survey propagation to name a few). Likewise, identifying thresholds in com-
munity detection models is key to benchmark and guide the development of clustering algorithms.
However, it is particularly crucial to develop benchmarks that do not depend sensitively on the
knowledge of the model parameters. A natural question is hence whether one can solve the various
recovery problems in the SBM without having access to the parameters. This paper answers this
question in the affirmative for the exact and strong recovery of the communities.
1.1 Prior results on the general SBM with known parameters
Most of the previous works are concerned with the SBM having symmetric communities (mainly
2 or sometimes k), with the exception of [19] which provides the first general achievability results
for the SBM.2 Recently, [1] studied fundamental limits for the general model SBM(n, p,W ), with
p independent of n. The results are summarized below. Recall first the recovery requirements:
Definition 1. (Recovery requirements.) An algorithm recovers or detects communities in
SBM(n, p,W ) with an accuracy of Î± âˆˆ [0, 1], if it outputs a labelling of the nodes {Ïƒâ€²(v), v âˆˆ V },
which agrees with the true labelling Ïƒ on a fraction Î± of the nodes with probability 1 âˆ’ on(1).
The agreement is maximized over relabellings of the communities. Strong recovery refers to
Î± = 1âˆ’ on(1) and exact recovery refers to Î± = 1.
The problem is solvable information-theoretically if there exists an algorithm that solves it, and
efficiently if the algorithm runs in polynomial-time in n. Note that exact recovery in SBM(n, p,W )
requires the graph not to have vertices of degree 0 in multiple communities with high probability.
Therefore, for exact recovery, we focus on W = ln(n)Q/n where Q is fixed.
I. Partial and strong recovery in the general SBM. The first result of [1] concerns the regime
where the connectivity matrix W scales as Q/n for a positive symmetric matrix Q (i.e., the node
1 [6] generalizes this to a, b = Î˜(1).
2 [24] also study variations of the k-symmetric model.
2
average degree is constant). The following notion of SNR is first introduced
SNR = |Î»min|2/Î»max (1)
where Î»min and Î»max are respectively the smallest3 and largest eigenvalues of diag(p)Q. The algo-
rithm Sphere-comparison is proposed that solves partial recovery with exponential accuracy
and quasi-linear complexity when the SNR diverges.
Theorem 1. [1] Given any k âˆˆ Z, p âˆˆ (0, 1)k with |p| = 1, and symmetric matrix Q with no
two rows equal, let Î» be the largest eigenvalue of PQ, and Î»â€² be the eigenvalue of PQ with the
smallest nonzero magnitude. If SNR := |Î»
â€²|2
Î» > 4, Î»
7 < (Î»â€²)8, and 4Î»3 < (Î»â€²)4, for some
Îµ = Îµ(Î», Î»â€²) and C = C(p,Q) > 0, Sphere-comparison detects communities in graphs
drawn from SBM(n, p,Q/n) with accuracy 1 âˆ’ 4keâˆ’
CÏ
16k /(1 âˆ’ exp(âˆ’ CÏ16k
(
(Î»â€²)4
Î»3 âˆ’ 1
)
)), provided
that the above is larger than 1 âˆ’ mini pi2 ln(4k) , and runs in O(n
1+) time. Moreover, Îµ can be made
arbitrarily small with 8 ln(Î»
âˆš
2/|Î»â€²|)/ ln(Î»), and C(p, Î±Q) is independent of Î±.
Note that for k symmetric clusters, SNR reduces to (aâˆ’b)
2
k(a+(kâˆ’1)b) , which is the quantity of inter-
est for detection [2, 26]. Moreover, the SNR must diverge to ensure strong recovery in the sym-
metric case [1]. The following is an important consequence of the previous theorem, stating that
Sphere-comparison solves strong recovery when the entries of Q are amplified.
Corollary 1. [1] For any k âˆˆ Z, p âˆˆ (0, 1)a with |p| = 1, and symmetric matrixQ with no two rows
equal, there exist (c) = O(1/ ln(c)) such that for all sufficiently large c, Sphere-comparison
detects communities in SBM(n, p, cQ/n) with accuracy 1âˆ’ eâˆ’â„¦(c) and complexity On(n1+(c)).
The above gives the optimal scaling both in accuracy and complexity.
II. Exact recovery in the general SBM. The second result in [1] is for the regime where the con-
nectivity matrix scales as ln(n)Q/n, Q independent of n, where it is shown that exact recovery has
a sharp threshold characterized by the divergence function
D+(f, g) = max
tâˆˆ[0,1]
âˆ‘
xâˆˆ[k]
(
tf(x) + (1âˆ’ t)g(x)âˆ’ f(x)tg(x)1âˆ’t
)
,
named the CH-divergence in [1]. Specifically, if all pairs of columns in diag(p)Q are atD+-distance
at least 1 from each other, then exact recovery is solvable in the general SBM. We refer to Section
2.3 in [1] for discussion on the connection with Shannonâ€™s channel coding theorem (and CH vs.
KL divergence). An algorithm (Degree-profiling) is also developed in [1] that solves exact
recovery down to theD+ limit in quasi-linear time, showing that exact recovery has no informational
to computational gap.
Theorem 2. [1] (i) Exact recovery is solvable in SBM(n, p, ln(n)Q/n) if and only if
min
i,jâˆˆ[k],i6=j
D+((PQ)i||(PQ)j) â‰¥ 1.
(ii) The Degree-profiling algorithm (see [1]) solves exact recovery whenever it is
information-theoretically solvable and runs in o(n1+) time for all  > 0.
Exact and strong recovery are thus solved for the general SBM with linear-size communities, when
the parameters are known. We next remove the latter assumption.
1.2 Estimating the parameters
For the estimation of the parameters, some results are known for two-symmetric communities. In
the logarithmic degree regime, since the SDP is agnostic to the parameters (it is a relaxation of the
min-bisection), the parameters can be estimated by recovering the communities [5, 20, 21]. For the
constant-degree regime, [26] shows that the parameters can be estimated above the threshold by
counting cycles (which is efficiently approximated by counting non-backtracking walks). These are,
however, for 2 communities. We also became aware of a parallel work [27], which considers private
graphon estimation (including SBMs). In particular, for the logarithmic degree regime, [27] obtains
a (non-efficient) procedure to estimate parameters of graphons in an appropriate version of the L2
norm. For the general SBM, learning the model was to date mainly open.
3The smallest eigenvalue of diag(p)Q is the one with least magnitude.
3
2 Results
Agnostic algorithms are developed for the constant and diverging node degrees (with p, k indepen-
dent of n). These afford optimal accuracy and complexity scaling for large node degrees and achieve
the CH-divergence limit for logarithmic node degrees. In particular, the SBM can be learned effi-
ciently for any diverging degrees.
Note that the assumptions on p and k being independent of n could be slightly relaxed, for example
to slowly growing k, but we leave this for future work.
2.1 Partial recovery
Our main result for partial recovery holds in the constant degree regime and requires a lower bound
Î´ on the least relative size of the communities. This requirement is removed when working with
diverging degrees, as stated in the corollary below.
Theorem 3. Given Î´ > 0 and for any k âˆˆ Z, p âˆˆ (0, 1)k with
âˆ‘
pi = 1 and 0 < Î´ â‰¤ min pi,
and any symmetric matrix Q with no two rows equal such that every entry in Qk is positive (in other
words, Q such that there is a nonzero probability of a path between vertices in any two communities
in a graph drawn from SBM(n, p,Q/n)), there exist (c) = O(1/ ln(c)) such that for all suffi-
ciently large Î±, Agnostic-sphere-comparison detects communities in graphs drawn from
SBM(n, p, Î±Q/n) with accuracy at least 1âˆ’ eâˆ’â„¦(Î±) in On(n1+(Î±)) time.
Note that a vertex in community i has degree 0 with probability exponential in c, and there is no
way to differentiate between vertices of degree 0 from different communities. So, an error rate
that decreases exponentially with c is optimal. In [28], we provide a more detailed version of this
theorem, which yields a quantitate statement on the accuracy of the algorithm in terms of the SNR
(Î»â€²)2/Î» for general SBM(n, p,Q/n).
Corollary 2. If Î± = Ï‰(1) in Theorem 3, the knowledge requirement on Î´ can be removed.
2.2 Exact recovery
Recall that from [1], exact recovery is information-theoretically and computationally solvable in
SBM(n, p, ln(n)Q/n) if and only if,
min
i<j
D+((PQ)i, (PQ)j) â‰¥ 1. (2)
We next show that this can be achieved without any knowledge on the parameters for
SBM(n, p, ln(n)Q/n).
Theorem 4. The Agnostic-degree-profiling algorithm (see Section 3.2) solves exact re-
covery in any SBM(n, p, ln(n)Q/n) for which exact recovery is solvable, using no input except the
graph in question, and runs in o(n1+) time for all  > 0. In particular, exact recovery is efficiently
and universally solvable whenever it is information-theoretically solvable.
3 Proof Techniques and Algorithms
3.1 Partial recovery and the Agnostic-sphere-comparison algorithm
3.1.1 Simplified version of the algorithm for the symmetric case
To ease the presentation of the algorithm, we focus first on the symmetric case, i.e., the SBM with
k communities of relative size 1/k, probability of connecting an inside communities and
b
n across
communities. Let d = (a+ (k âˆ’ 1)b)/k be the average degree.
Definition 2. For any vertex v, let Nr[G](v) be the set of all vertices with shortest path in G to v of
length r. We often drop the subscript G if the graph in question is the original SBM. We also refer
to NÌ„r(v) as the vector whose i-th entry is the number of vertices in Nr(v) that are in community i.
For an arbitrary vertex v and reasonably small r, there will be typically about dr vertices in Nr(v),
and about (aâˆ’bk )
r more of them will be in vâ€™s community than in each other community. Of course,
4
this only holds when r < log n/ log d because there are not enough vertices in the graph otherwise.
The obvious way to try to determine whether or not two vertices v and vâ€² are in the same community
is to guess that they are in the same community if |Nr(v) âˆ©Nr(vâ€²)| > d2r/n and different commu-
nities otherwise. Unfortunately, whether or not a vertex is in Nr(v) is not independent of whether
or not it is in Nr(vâ€²), which compromises this plan. Instead, we propose to rely on the following
graph-splitting step: Randomly assign every edge in G to some set E with a fixed probability c and
then count the number of edges in E that connect Nr[G\E] and Nrâ€²[G\E]. Formally:
Definition 3. For any v, vâ€² âˆˆ G, r, râ€² âˆˆ Z, and subset of Gâ€™s edges E, let Nr,râ€²[E](v Â· vâ€²) be the
number of pairs (v1, v2) such that v1 âˆˆ Nr[G\E](v), v2 âˆˆ Nrâ€²[G\E](vâ€²), and (v1, v2) âˆˆ E.
Note that E and G\E are disjoint. However, in SBM(n, p,Q/n), G is sparse enough that even if
the two graphs were generated independently, a given pair of vertices would have an edge in both
graphs with probability O( 1n2 ). So, E is approximately independent of G\E.
Thus, given v, r, and denoting by Î»1 = (a+ (k âˆ’ 1)b)/k and Î»2 = (aâˆ’ b)/k the two eigvenvalues
of PQ in the symmetric case, the expected number of intra-community neighbors at depth r from v
is approximately 1k (Î»
r
1 + (k âˆ’ 1)Î»r2), whereas the expected number of extra-community neighbors
at depth r from v is approximately 1k (Î»
r
1 âˆ’ Î»r2) for each of the other (k âˆ’ 1) communities. All of
these are scaled by 1âˆ’ c if we do the computations in G\E. Using now the emulated independence
between E and G\E, and assuming v and vâ€² to be in the same community, the expected number
of edges in E connecting Nr[G\E](v) to Nrâ€²[G\E](vâ€²) is approximately given by the inner product
ut(c Â· PQ)u, where u = 1k (Î»
r
1 + (k âˆ’ 1)Î»r2, Î»r1 âˆ’ Î»r2, . . . , Î»r1 âˆ’ Î»r2) and (PQ) is the matrix with a
on the diagonal and b elsewhere. When v and vâ€² are in different communities, the inner product is
between u and a permutation of u. After simplifications, this gives
Nr,râ€²[E](v Â· vâ€²) â‰ˆ
c(1âˆ’ c)r+râ€²
n
[
dr+r
â€²+1 +
(
aâˆ’ b
k
)r+râ€²+1
(kÎ´Ïƒv,Ïƒvâ€² âˆ’ 1)
]
(3)
where Î´Ïƒv,Ïƒvâ€² is 1 if v and v
â€² are in the same community and 0 otherwise. In order forNr,râ€²[E](v Â·vâ€²)
to depend on the relative communities of v and vâ€², it must be that c(1âˆ’ c)r+râ€² |aâˆ’bk |
r+râ€²+1k is large
enough, i.e., more than n, so r + râ€² needs to be at least log n/ log |aâˆ’bk |. A difficulty is that for a
specific pair of vertices, the dr+r
â€²+1 term will be multiplied by a random factor dependent on the
degrees of v, vâ€², and the nearby vertices. So, in order to stop the variation in the dr+r
â€²+1 term from
drowning out the
(
aâˆ’b
k
)r+râ€²+1
(kÎ´Ïƒv,Ïƒvâ€² âˆ’ 1) term, it is necessary to cancel out the dominant term.
This brings us to introduce the following sign-invariant statistics:
Ir,râ€²[E](v Â· vâ€²) := Nr+2,râ€²[E](v Â· vâ€²) Â·Nr,râ€²[E](v Â· vâ€²)âˆ’N2r+1,râ€²[E](v Â· v
â€²)
â‰ˆ c
2(1âˆ’ c)2r+2râ€²+2
n2
Â·
(
dâˆ’ aâˆ’ b
k
)2
Â· dr+r
â€²+1
(
aâˆ’ b
k
)r+râ€²+1
(kÎ´Ïƒv,Ïƒvâ€² âˆ’ 1)
In particular, for r + râ€² odd, Ir,râ€²[E](v Â· vâ€²) will tend to be positive if v and vâ€² are in the same
community and negative otherwise, irrespective of the specific values of a, b, k. That suggests the
following algorithm for partial recovery, it requires knowledge of Î´ < 1/k in the constant degree
regime, but not in the regime where a, b scale with n.
1. Set r = râ€² = 34 log n/ log d and put each of the graphâ€™s edges in E with probability 1/10.
2. Set kmax = 1/Î´ and select kmax ln(4kmax) random vertices, v1, ..., vkmax ln(4kmax).
3. Compute Ir,râ€²[E](vi Â· vj) for each i and j.
4. If there is a possible assignment of these vertices to communities such that Ir,râ€²[E](vi Â·vj) >
0 if and only if vi and vj are in the same community, then randomly select one vertex from
each apparent community, v[1], v[2], ...v[kâ€²]. Otherwise, fail.
5. For every vâ€² in the graph, guess that vâ€² is in the same community as the v[i] that maximizes
the value of Ir,râ€²[E](v[i] Â· vâ€²).
This algorithm succeeds as long as |a âˆ’ b|/k > (10/9)1/6((a + (k âˆ’ 1)b)/k)5/6, to ensure that
the above estimates on Nr,râ€²[E](v Â· vâ€²) are reliable. Further, if a, b are scaled by Î± = Ï‰(1), setting
5
Î´ = 1/ log logÎ± allows removal of the knowledge requirement on Î´. In addition, playing with r, râ€²
to take different allows us to reduce the complexity of the algorithm.
One alternative to our approach could be to count the non-backtracking walks of a given length
between v and vâ€², like in [4,29], instead of using Nr,râ€²[E](v Â· vâ€²). However, proving that the number
of non-backtracking walks is close to its expected value is difficult. Proving that Nr,râ€²[E](v Â· vâ€²)
is within a desired range is substantially easier because for any v1 and v2, whether or not there is
an edge between v1 and v2 directly effects Nr(v) for at most one value of r. Algorithms based on
shortest path have also been studied in [30].
3.1.2 The general case
In the general case, define Nr(v), NÌ„r(v) and Nr,râ€²[E](v Â· vâ€²) as in the previous section. Now, for
any v1 âˆˆ Nr[G/E](v) and v2 âˆˆ Nrâ€²[G/E](vâ€²), (v1, v2) âˆˆ E with a probability of approximately
cQÏƒv1 ,Ïƒv2/n. As a result,
Nr,râ€² [E](v Â· vâ€²) â‰ˆ NÌ„r[G\E](v) Â·
cQ
n
NÌ„râ€²[G\E](v
â€²) â‰ˆ ((1âˆ’ c)PQ)reÏƒv Â·
cQ
n
((1âˆ’ c)PQ)r
â€²
eÏƒvâ€²
= c(1âˆ’ c)r+r
â€²
eÏƒv Â·Q(PQ)r+r
â€²
eÏƒvâ€²/n.
E
Nr[G\E](v) Nr0[G\E](v
0)
... . . .v v0
Figure 1: The purple edges represent the edges counted by Nr,râ€² [E](v Â· vâ€²).
Let Î»1, ..., Î»h be the distinct eigenvalues of PQ, ordered so that |Î»1| â‰¥ |Î»2| â‰¥ ... â‰¥ |Î»h| â‰¥ 0.
Also define hâ€² so that hâ€² = h if Î»h 6= 0 and hâ€² = h âˆ’ 1 if Î»h = 0. If Wi is the eigenspace of PQ
corresponding to the eigenvalue Î»i, and PWi is the projection operator on to Wi, then
Nr,râ€²[E](v Â· vâ€²) â‰ˆ c(1âˆ’ c)r+r
â€²
eÏƒv Â·Q(PQ)r+r
â€²
eÏƒvâ€²/n (4)
=
c(1âˆ’ c)r+râ€²
n
âˆ‘
i
Î»r+r
â€²+1
i PWi(eÏƒv ) Â· P
âˆ’1PWi(eÏƒvâ€² ) (5)
where the final equality holds because for all i 6= j,
Î»iPWi(eÏƒv ) Â· Pâˆ’1PWj (eÏƒvâ€² ) = PWi(eÏƒv ) Â·QPWj (eÏƒvâ€² ) = PWi(eÏƒv ) Â· P
âˆ’1Î»jPWj (eÏƒvâ€² ),
and since Î»i 6= Î»j , this implies that PWi(eÏƒv ) Â· Pâˆ’1PWj (eÏƒvâ€² ) = 0.
Definition 4. Let Î¶i(v Â· vâ€²) = PWi(eÏƒv ) Â· Pâˆ’1PWi(eÏƒvâ€² ) for all i, v, and v
â€².
Equation (5) is dominated by the Î»r+r
â€²+1
1 term, so getting good estimate of the Î»
r+râ€²+1
2 through
Î»r+r
â€²+1
hâ€² terms requires cancelling it out somehow. As a start, if Î»1 > Î»2 > Î»3 then
Nr+2,râ€²[E](v Â· vâ€²) Â·Nr,râ€²[E](v Â· vâ€²)âˆ’N2r+1,râ€²[E](v Â· v
â€²)
â‰ˆ c
2(1âˆ’ c)2r+2râ€²+2
n2
(Î»21 + Î»
2
2 âˆ’ 2Î»1Î»2)Î»r+r
â€²+1
1 Î»
r+râ€²+1
2 Î¶1(v Â· vâ€²)Î¶2(v Â· vâ€²)
Note that the left hand side of this expression is equal to det
âˆ£âˆ£âˆ£âˆ£ Nr,râ€²[E](v Â· vâ€²) Nr+1,râ€²[E](v Â· vâ€²)Nr+1,râ€²[E](v Â· vâ€²) Nr+2,râ€²[E](v Â· vâ€²)
âˆ£âˆ£âˆ£âˆ£.
Definition 5. Let Mm,r,râ€²[E](v Â· vâ€²) be the m Ã— m matrix such that Mm,r,râ€²[E](v Â· vâ€²)i,j =
Nr+i+j,râ€²[E](v Â· vâ€²) for each i and j.
6
As shown in [28], there exists constant Î³(Î»1, ..., Î»m) such that
det(Mm,r,râ€²[E](v Â· vâ€²)) â‰ˆ
cm(1âˆ’ c)m(r+râ€²)
nm
Î³(Î»1, ..., Î»m)
mâˆ
i=1
Î»r+r
â€²+1
i Î¶i(v Â· v
â€²) (6)
where we assumed that |Î»m| > |Î»m+1| above to simplify the discussion (the case |Î»m| = |Î»m+1| is
similar). This suggests the following plan for estimating the eigenvalues corresponding to a graph.
First, pick several vertices at random. Then, use the fact that |Nr[G\E](v)| â‰ˆ ((1 âˆ’ c)Î»1)r for any
good vertex v to estimate Î»1. Next, take ratios of (6) for m and m âˆ’ 1 (with r = râ€²), and look for
the smallest m making that ratio small enough (this will use the estimate on Î»1), estimating hâ€² by
this value minus one. Then estimate consecutively all of PQâ€™s eigenvalues for each selected vertex
using ratios of (6). Finally, take the median of these estimates.
In general, whether |Î»m| > |Î»m+1| or |Î»m| = |Î»m+1|,
det(Mm,r+1,râ€²[E](v Â· vâ€²))âˆ’ (1âˆ’ c)mÎ»m+1
âˆmâˆ’1
i=1 Î»i det(Mm,r,râ€²[E](v Â· vâ€²))
det(Mmâˆ’1,r+1,râ€²[E](v Â· vâ€²))âˆ’ (1âˆ’ c)mâˆ’1Î»m
âˆmâˆ’2
i=1 Î»i det(Mmâˆ’1,r,râ€²[E](v Â· vâ€²))
â‰ˆ c
n
Î³(Î»1, ..., Î»m)
Î³(Î»1, ..., Î»mâˆ’1)
Î»mâˆ’1(Î»m âˆ’ Î»m+1)
Î»m(Î»mâˆ’1 âˆ’ Î»m)
((1âˆ’ c)Î»m)r+r
â€²+2Î¶m(v Â· vâ€²).
This fact can be used to approximate Î¶i(v Â· vâ€²) for arbitrary v, vâ€², and i. Of course, this requires r
and râ€² to be large enough that c(1âˆ’c)
r+râ€²
n Î»
r+râ€²+1
i Î¶i(v Â· vâ€²) is large relative to the error terms for all
i â‰¤ hâ€². This requires at least |(1 âˆ’ c)Î»i|r+r
â€²+1 = Ï‰(n) for all i â‰¤ hâ€². Moreover, for any v and vâ€²,
0 â‰¤ PWi(eÏƒv âˆ’ eÏƒvâ€² ) Â· P
âˆ’1PWi(eÏƒv âˆ’ eÏƒvâ€² ) = Î¶i(v Â· v)âˆ’ 2Î¶i(v Â· v
â€²) + Î¶i(vâ€² Â· vâ€²) with equality for
all i if and only if Ïƒv = Ïƒvâ€² , so sufficiently good approximations of Î¶i(v Â· v), Î¶i(v Â· vâ€²) and Î¶i(vâ€² Â· vâ€²)
can be used to determine which pairs of vertices are in the same community.
One could generate a reasonable classification based solely on this method of comparing vertices
(with an appropriate choice of the parameters, as later detailed). However, that would require com-
puting Nr,râ€²[E](v Â· v) for every vertex in the graph with fairly large r + râ€², which would be slow.
Instead, we use the fact that for any vertices v, vâ€², and vâ€²â€² with Ïƒv = Ïƒvâ€² 6= Ïƒvâ€²â€² ,
Î¶i(v
â€² Â· vâ€²)âˆ’ 2Î¶i(v Â· vâ€²) + Î¶i(v Â· v) = 0 â‰¤ Î¶i(vâ€²â€² Â· vâ€²â€²)âˆ’ 2Î¶i(v Â· vâ€²â€²) + Î¶i(v Â· v)
for all i, and the inequality is strict for at least one i. So, subtracting Î¶i(v Â· v) from both sides, we
have Î¶i(vâ€² Â· vâ€²)âˆ’ 2Î¶i(v Â· vâ€²) â‰¤ Î¶i(vâ€²â€² Â· vâ€²â€²)âˆ’ 2Î¶i(v Â· vâ€²â€²) for all i, and the inequality is still strict for at
least one i. So, given a representative vertex in each community, we can determine which of them a
given vertex, v, is in the same community as without needing to know the value of Î¶i(v Â· v).
This runs fairly quickly if r is large and râ€² is small because the algorithm only requires focusing
on |Nrâ€²(vâ€²)| vertices. This leads to the following plan for partial recovery. First, randomly select
a set of vertices that is large enough to contain at least one vertex from each community with high
probability. Next, compare all of the selected vertices in an attempt to determine which of them are
in the same communities. Then, pick one in each community. Call these anchor nodes. After that,
use the algorithm referred to above to determine which community each of the remaining vertices
is in. As long as there actually was at least one vertex from each community in the initial set and
none of the approximations were particularly bad, this should give a reasonable classification. The
risk that this randomly gives a bad classification due to a bad set of initial vertices can be mitigated
by repeating the previous classification procedure several times as discussed in [28]. This completes
the Agnostic-sphere-comparison algorithm. We refer to [28] for the details.
3.2 Exact recovery and the Agnostic-degree-profiling algorithm
The exact recovery part is similar to [1] and uses the fact that once a good enough clustering has been
obtained from Agnostic-sphere-comparison, the classification can be finished by making
local improvements based on the nodeâ€™s neighborhoods. Similar techniques have been used in [5,
11, 19, 31, 32]. However, we establish here a sharp characterization of the local procedure error.
The key result is that, when testing between two multivariate Poisson distributions of means
log(n)Î»1 and log(n)Î»2 respectively, where Î»1, Î»2 âˆˆ Zk+, the probability of error (of maximum
7
a posteriori decoding) is
nâˆ’D+(Î»1,Î»2)+o(1). (7)
This is proved in [1]. In the case of unknown parameters, the algorithmic approach is largely un-
changed, adding a step where the best known classification is used to estimate p and Q prior to any
local improvement step. The analysis of the algorithm requires however some careful handling.
First, it is necessary to prove that given a labelling of the graphâ€™s vertices with an error rate of x,
one can compute approximations of p and Q that are within O(x+ log(n)/
âˆš
n) of their true values
with probability 1âˆ’ o(1). Secondly, one needs to modify the above hypothesis testing estimates to
control the error probability. In attempting to determine verticesâ€™ communities based on estimates of
p and Q that are off by at most Î´, say pâ€² and Qâ€², one must show that a classification of its neighbors
that has an error rate of Î´ classifies the vertices with an error rate only eO(Î´ logn) times higher than
it would be if the parameter really were pâ€² and Qâ€² and the verticesâ€™ neighbors were all classified
correctly. Thirdly, one needs to show that since D+((PQ)i, (PQ)j) is differentiable with respect
to any element of PQ, the error rate if the parameters really were pâ€² and Qâ€² is at worst eO(Î´ logn)
as high as the error rate with the actual parameters. Combining these yields the conclusion that any
errors in the estimates of the SBMâ€™s parameters do not disrupt vertex classification any worse than
the errors in the preliminary classifications already were.
The Agnostic-degree-profiling algorithm. The inputs are (G, Î³), where G is a graph,
and Î³ âˆˆ [0, 1] (see [28] for how to set Î³ specifically). The algorithm outputs each nodeâ€™s label.
(1) Define the graph gâ€² on the vertex set [n] by selecting each edge in g independently with proba-
bility Î³, and define the graph gâ€²â€² that contains the edges in g that are not in gâ€².
(2) Run Agnostic-sphere-comparison on gâ€² with Î´ = 1/ log log(n) to obtain the classifi-
cation Ïƒâ€² âˆˆ [k]n.
(3) Determine the size of all alleged communities, and estimate the edge density among these.
(4) For each node v âˆˆ [n], determine the most likely community label of node v based on its degree
profile NÌ„1(v) computed from the preliminary classification Ïƒâ€², and call it Ïƒâ€²â€²v .
(5) Use Ïƒâ€²â€²v to get new estimates of p and Q.
(6) For each node v âˆˆ [n], determine the most likely community label of node v based on its degree
profile NÌ„1(v) computed from Ïƒâ€²â€². Output this labelling.
In step (3) and (6), the most likely label is the one that maximizes the probability that the degree
profile comes from a multivariate distribution of mean ln(n)(PQ)i for i âˆˆ [k]. Note that this
algorithm does not require a lower bound on min pi because setting Î´ to a slowly decreasing function
of n results in Î´ being within an acceptable range for all sufficiently large n.
4 Data implementation and open problems
We tested a simplified version of our algorithm on real data (see [28]), for the blog network of
Adamic and Glance â€™05. We obtained an error rate of about 60/1222 (best trial was 57, worst 67),
achieving the state-of-the-art (as described in [32]). Our extend quite directly to a slowly growing
number of communities (e.g., up to logarithmic). It would be interesting to extend the current
approach to smaller sized, watching the complexity scaling, as well as to corrected-degrees, labeled-
edges, or overlapping communities (though our approach already applies to linear-sized overlaps).
Acknowledgments
This research was partly supported by NSF grant CCF-1319299 and the Bell Labs Prize.
References
[1] E. Abbe and C. Sandon. Community detection in general stochastic block models: fundamental limits
and efficient recovery algorithms. arXiv:1503.00609. To appear in FOCS15., March 2015.
[2] A. Decelle, F. Krzakala, C. Moore, and L. ZdeborovaÌ. Asymptotic analysis of the stochastic block model
for modular networks and its algorithmic applications. Phys. Rev. E, 84:066106, December 2011.
[3] L. MassoulieÌ. Community detection thresholds and the weak Ramanujan property. In STOC 2014: 46th
Annual Symposium on the Theory of Computing, pages 1â€“10, New York, United States, June 2014.
8
[4] E. Mossel, J. Neeman, and A. Sly. A proof of the block model threshold conjecture. Available online at
arXiv:1311.4115 [math.PR], January 2014.
[5] E. Abbe, A. S. Bandeira, and G. Hall. Exact recovery in the stochastic block model. To appear in IEEE
Transactions on Information Theory. Available at ArXiv:1405.3267, May 2014.
[6] E. Mossel, J. Neeman, and A. Sly. Consistency thresholds for binary symmetric block models.
Arxiv:arXiv:1407.1591. To appear in STOC15., July 2014.
[7] J. Xu Y. Chen. Statistical-computational tradeoffs in planted problems and submatrix localization with a
growing number of clusters and submatrices. arXiv:1402.1267, February 2014.
[8] P. K. Gopalan and D. M. Blei. Efficient discovery of overlapping communities in massive networks.
Proceedings of the National Academy of Sciences, 2013.
[9] P. W. Holland, K. Laskey, and S. Leinhardt. Stochastic blockmodels: First steps. Social Networks,
5(2):109â€“137, 1983.
[10] T.N. Bui, S. Chaudhuri, F.T. Leighton, and M. Sipser. Graph bisection algorithms with good average case
behavior. Combinatorica, 7(2):171â€“191, 1987.
[11] M.E. Dyer and A.M. Frieze. The solution of some random NP-hard problems in polynomial expected
time. Journal of Algorithms, 10(4):451 â€“ 489, 1989.
[12] Mark Jerrum and Gregory B. Sorkin. The metropolis algorithm for graph bisection. Discrete Applied
Mathematics, 82(13):155 â€“ 175, 1998.
[13] A. Condon and R. M. Karp. Algorithms for graph partitioning on the planted partition model. Lecture
Notes in Computer Science, 1671:221â€“232, 1999.
[14] T. A. B. Snijders and K. Nowicki. Estimation and Prediction for Stochastic Blockmodels for Graphs with
Latent Block Structure. Journal of Classification, 14(1):75â€“100, January 1997.
[15] F. McSherry. Spectral partitioning of random graphs. In Foundations of Computer Science, 2001. Pro-
ceedings. 42nd IEEE Symposium on, pages 529â€“537, 2001.
[16] P. J. Bickel and A. Chen. A nonparametric view of network models and newmangirvan and other modu-
larities. Proceedings of the National Academy of Sciences, 2009.
[17] K. Rohe, S. Chatterjee, and B. Yu. Spectral clustering and the high-dimensional stochastic blockmodel.
The Annals of Statistics, 39(4):1878â€“1915, 08 2011.
[18] D. S. Choi, P. J. Wolfe, and E. M. Airoldi. Stochastic blockmodels with a growing number of classes.
Biometrika, pages 1â€“12, 2012.
[19] V. Vu. A simple svd algorithm for finding hidden partitions. Available online at arXiv:1404.3918, 2014.
[20] J. Xu B. Hajek, Y. Wu. Achieving exact cluster recovery threshold via semidefinite programming.
arXiv:1412.6156, November 2014.
[21] A. S. Bandeira. Random laplacian matrices and convex relaxations. arXiv:1504.03987, 2015.
[22] S. Yun and A. Proutiere. Accurate community detection in the stochastic block model via spectral algo-
rithms. arXiv:1412.7335, December 2014.
[23] E. Mossel, J. Neeman, and A. Sly. Belief propagation, robust reconstruction, and optimal recovery of
block models. Arxiv:arXiv:1309.1380, 2013.
[24] O. GueÌdon and R. Vershynin. Community detection in sparse networks via Grothendieckâ€™s inequality.
ArXiv:1411.4686, November 2014.
[25] P. Chin, A. Rao, and V. Vu. Stochastic block model and community detection in the sparse graphs: A
spectral algorithm with optimal rate of recovery. arXiv:1501.05021, January 2015.
[26] E. Mossel, J. Neeman, and A. Sly. Stochastic block models and reconstruction. Available online at
arXiv:1202.1499 [math.PR], 2012.
[27] C. Borgs, J. Chayes, and A. Smith. Private graphon estimation for sparse graphs. In preparation, 2015.
[28] E. Abbe and C. Sandon. Recovering communities in the general stochastic block model without knowing
the parameters. arXiv:1506.03729, June 2015.
[29] C. Bordenave, M. Lelarge, and L. MassoulieÌ. Non-backtracking spectrum of random graphs: community
detection and non-regular ramanujan graphs. Available at arXiv:1501.06087, 2015.
[30] S. Bhattacharyya and P. J. Bickel. Community Detection in Networks using Graph Distance. ArXiv
e-prints, January 2014.
[31] N. Alon and N. Kahale. A spectral technique for coloring random 3-colorable graphs. In SIAM Journal
on Computing, pages 346â€“355, 1994.
[32] A. Y. Zhang H. H. Zhou C. Gao, Z. Ma. Achieving optimal misclassification proportion in stochastic
block model. arXiv:1505.03772, 2015.
9
