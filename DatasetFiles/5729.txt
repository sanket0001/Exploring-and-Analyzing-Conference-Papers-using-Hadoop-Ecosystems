


Paper ID = 5729
Title = Nearly-Optimal Private LASSO‚àó
Kunal Talwar
Google Research
kunal@google.com
Abhradeep Thakurta
(Previously) Yahoo! Labs
guhathakurta.abhradeep@gmail.com
Li Zhang
Google Research
liqzhang@google.com
Abstract
We present a nearly optimal differentially private version of the well known
LASSO estimator. Our algorithm provides privacy protection with respect to each
training example. The excess risk of our algorithm, compared to the non-private
version, is OÃÉ(1/n2/3), assuming all the input data has bounded `‚àû norm. This
is the first differentially private algorithm that achieves such a bound without the
polynomial dependence on p under no additional assumptions on the design ma-
trix. In addition, we show that this error bound is nearly optimal amongst all
differentially private algorithms.
1 Introduction
A common task in supervised learning is to select the model that best fits the data. This is frequently
achieved by selecting a loss function that associates a real-valued loss with each datapoint d and
model Œ∏ and then selecting from a class of admissible models, the model Œ∏ that minimizes the
average loss over all data points in the training set. This procedure is commonly referred to as
Empirical Risk Minimization(ERM).
The availability of large datasets containing sensitive information from individuals has motivated the
study of learning algorithms that guarantee the privacy of individuals contributing to the database. A
rigorous and by-now standard privacy guarantee is via the notion of differential privacy. In this work,
we study the design of differentially private algorithms for Empirical Risk Minimization, continuing
a long line of work. (See [2] for a survey.)
In particular, we study adding privacy protection to the classical LASSO estimator, which has been
widely used and analyzed. We first present a differentially private optimization algorithm for the
LASSO estimator. The algorithm is the combination of the classical Frank-Wolfe algorithm [15]
and the exponential mechanism for guaranteeing the privacy [21]. We then show that our algorithm
achieves nearly optimal risk among all the differentially private algorithms. This lower bound proof
relies on recently developed techniques with roots in Cryptography [4, 14],
Consider the training dataset D consisting of n pairs of data di = (xi, yi) where xi ‚àà Rp, usually
called the feature vector, and yi ‚àà R, the prediction. The LASSO estimator, or the sparse linear
regression, solves for Œ∏‚àó = argminŒ∏ L(Œ∏; di) = 1n
‚àë
i |xi ¬∑ Œ∏‚àí yi|2 subject to ‚ÄñŒ∏‚Äñ1 ‚â§ c. To simplify
presentation, we assume c = 1, but our results directly extend to general c. The `1 constraint tends to
induce sparse Œ∏‚àó so is widely used in the high dimensional setting when p n. Here, we will study
approximating the LASSO estimation with minimum possible error while protecting the privacy of
each individual di. Below we define the setting more formally.
‚àóPart of this work was done at Microsoft Research Silicon Valley Campus.
1
Problem definition: Given a data setD = {d1, ¬∑ ¬∑ ¬∑ , dn} of n samples from a domainD, a constraint
set C ‚äÜ Rp, and a loss function L : C √óD ‚Üí R, for any model Œ∏, define its excess empirical risk as
R(Œ∏;D)
def
=
1
n
n‚àë
i=1
L(Œ∏; di)‚àímin
Œ∏‚ààC
1
n
n‚àë
i=1
L(Œ∏; di). (1)
For LASSO, the constraint set is the `1 ball, and the loss is the quadratic loss function. We define
the risk of a mechanism A on a data set D as R(A;D) = E[R(A(D);D)], where the expectation
is over the internal randomness of A, and the risk R(A) = maxD‚ààDn R(A;D) is the maximum
risk over all the possible data sets. Our objective is then to design a mechanism A which preserves
(, Œ¥)-differential privacy (Definition 1.3) and achieves as low risk as possible. We call the minimum
achievable risk as privacy risk, defined as minAR(A), where the min is over all (, Œ¥)-differentially
private mechanisms A.
There has been much work on studying the privacy risk for the LASSO estimator. However, all the
previous results either need to make strong assumption about the input data or have polynomial de-
pendence on the dimension p. First [20] and then [24] studied the LASSO estimator with differential
privacy guarantee. They showed that one can avoid the polynomial dependence on p in the excess
empirical risk if the data matrix X satisfy the restricted strong convexity and mutual incoherence
properities. While such assumptions seem necessary to prove that LASSO recovers the exact sup-
port in the worst case, they are often violated in practice, where LASSO still leads to useful models.
It is therefore desirable to design and analyze private versions of LASSO in the absence of such as-
sumptions. In this work, we do so by analyzing the loss achieved by the private optimizer, compared
to the true optimizer.
We make primarily two contributions in this paper. First we present an algorithm that achieves
the privacy risk of OÃÉ(1/n2/3) for the LASSO problem1. Compared to the previous work, we only
assume that the input data has bounded `‚àû norm. In addition, the above risk bound only has log-
arithmic dependence on p, which fits particularly well for LASSO as we usually assume n  p
when applying LASSO. This bound is achieved by a private version of the Frank-Wolfe algorithm.
Assuming that each data point di satisfies that ‚Äñdi‚Äñ‚àû ‚â§ 1, we have
Theorem 1.1. There exists an (, Œ¥)-differentially private algorithm A for LASSO such that
R(A) = O
(
log(np)
‚àö
log(1/Œ¥)
(n)2/3
)
.
Our second contribution is to show that, surprisingly, this simple algorithm gives a nearly tight
bound. We show that this rather unusual n‚àí2/3 dependence is not an artifact of the algorithm or the
analysis, but is in fact the right dependence for the LASSO problem: no differentially private algo-
rithm can do better! We prove a lower bound by employing fingerprinting codes based techniques
developed in [4, 14].
Theorem 1.2. For the sparse linear regression problem where ‚Äñxi‚Äñ‚àû ‚â§ 1, for  = 0.1 and Œ¥ =
o(1/n2), any (, Œ¥)-differentially private algorithm A must have
R(A) = ‚Ñ¶(1/(n log n)2/3) .
Our improved privacy risk crucially depends on the fact that the constraint set is a polytope with
few (polynomial in dimensions) vertices. This allows us to use a private version of the Frank-Wolfe
algorithm, where at each step, we use the exponential mechanism to select one of the vertices of
the polytope. We also present a variant of Frank-Wolfe that uses objective perturbation instead of
the exponential mechanism. We show that (Theorem 2.6) we can obtain a risk bound dependent on
the Gaussian width of the constraint set, which often results in tighter bounds compared to bounds
based, e.g., on diameter. While more general, this variant adds much more noise than the Frank-
Wolfe based algorithm, as it is effectively publishing the whole gradient at each step. When C is not
a polytope with a small number of vertices, one can still use the exponential mechanism as long as
one has a small list of candidate points which contains an approximate optimizer for every direction.
For many simple cases, for example the `q ball with 1 < q < 2, the bounds attained in this way have
1Throughout the paper, we use OÃÉ to hide logarithmic factors.
2
an additional polynomial dependence on the dimension p, instead of the logarithmic dependence in
the above result. For example, when q = 1, the upper bound from this variant has an extra factor
of p1/3. Whereas such a dependence is provably needed for q = 2, the upper bound jump rather
abruptly from the logarithmic dependence for q = 1 to a polynomial dependence on p for q > 1.
We leave open the question of resolving this discontinuity and interpolating more smoothly between
the `1 case and the `2 case.
Our results enlarge the set of problems for which privacy comes ‚Äúfor free‚Äù. Given n samples from
a distribution, suppose that Œ∏‚àó is the empirical risk minimizer and Œ∏priv is the differentially private
approximate minimizer. Then the non-private ERM algorithm outputs Œ∏‚àó and incurs expected (on the
distribution) loss equal to the loss(Œ∏‚àó, training-set) + generalization-error, where the generalization
error term depends on the loss function, C and on the number of samples n. The differentially private
algorithm incurs an additional loss of the privacy risk. If the privacy risk is asymptotically no larger
than the generalization error, we can think of privacy as coming for free, since under the assumption
of n being large enough to make the generalization error small, we are also making n large enough
to make the privacy risk small. In the case when C is the `1-ball, and the loss function is the squared
loss with ‚Äñx‚Äñ‚àû ‚â§ 1 and |y| ‚â§ 1, the best known generalization error bounds dominate the privacy
risk when n = œâ(log3 p) [1, Theorem 18].
1.1 Related work
There have been much work on private LASSO or more generally private ERM algorithms. The
error bounds mainly depend on the shape of the constraint set and the Lipschitz condition of the loss
function. Here we will summarize these related results. Related to our results, we distinguish two
settings: i) the constraint set is bounded in the `1-norm and the the loss function is 1-Lipschitz in
the `1-norm. (call it the (`1/`‚àû)-setting). This is directly related to our bounds on LASSO; and
ii) the constraint set has bounded `2 norm and the loss function is 1-Lipschitz in the `2 norm (the
(`2/`2)-setting), which is related to our bounds using Gaussian width.
The (`1/`‚àû)-setting: The results in this setting include [20, 24, 19, 25]. The first two works make
certain assumptions about the instance (restricted strong convexity (RSC) and mutual incoherence).
Under these assumptions, they obtain privacy risk guarantees that depend logarithmically in the di-
mensions p, and thus allowing the guarantees to be meaningful even when p  n. In fact their
bound of O(polylog p/n) can be better than our tight bound of O(polylog p/n2/3). However, these
assumptions on the data are strong and may not hold in practice. Our guarantees do not require
any such data dependent assumptions. The result of [19] captures the scenario when the constraint
set C is the probability simplex and the loss function is a generalized linear model, but provides
a worse bound of O(polylog p/n1/3). For the special case of linear loss functions, which are in-
teresting primarily in the online prediction setting, the techniques of [19, 25] provide a bound of
O(polylog p/n).
The (`2/`2)-setting: In all the works on private convex optimization that we are aware of, either the
excess risk guarantees depend polynomially on the dimensionality of the problem (p), or assumes
special structure to the loss (e.g., generalized linear model [19] or linear losses [25]). Similar de-
pendence is also present in the online version of the problem [18, 26]. [2] recently show that in
the private ERM setting, in general this polynomial dependence on p is unavoidable. In our work
we show that one can replace this dependence on p with the Gaussian width of the constraint set C,
which can be much smaller.
Effect of Gaussian width in risk minimization: Our result on general C has an dependence on
the Gaussian width of C. This geometric concept has previously appeared in other contexts. For
example, [1] bounds the the excess generalization error by the Gaussian width of the constraint set C.
Recently [5] show that the Gaussian width of a constraint set C is very closely related to the number
of generic linear measurements one needs to perform to recover an underlying model Œ∏‚àó ‚àà C. The
notion of Gaussian width has also been used by [22, 11] in the context of differentially private query
release mechanisms but in the very different context of answering multiple linear queries over a
database.
3
1.2 Background
Differential Privacy: The notion of differential privacy (Definition 1.3) is by now a defacto standard
for statistical data privacy [10, 12]. One of the reasons why differential privacy has become so
popular is because it provides meaningful guarantees even in the presence of arbitrary auxiliary
information. At a semantic level, the privacy guarantee ensures that an adversary learns almost
the same thing about an individual independent of his presence or absence in the data set. The
parameters (, Œ¥) quantify the amount of information leakage. For reasons beyond the scope of this
work,  ‚âà 0.1 and Œ¥ = 1/nœâ(1) are a good choice of parameters. Here n refers to the number of
samples in the data set.
Definition 1.3. A randomized algorithmA is (, Œ¥)-differentially private if, for all neighboring data
sets D and D‚Ä≤ (i.e., they differ in one record, or equivalently, dH(D,D‚Ä≤) = 1) and for all events S
in the output space of A, we have
Pr(A(D) ‚àà S) ‚â§ e Pr(A(D‚Ä≤) ‚àà S) + Œ¥ .
Here dH(D,D‚Ä≤) refers to the Hamming distance.
`q-norm, q ‚â• 1: For q ‚â• 1, the `q-norm for any vector v ‚àà Rp is defined as
(
p‚àë
i=1
v(i)q
)1/q
, where
v(i) is the i-th coordinate of the vector v.
L-Lipschitz continuity w.r.t. norm ‚Äñ ¬∑ ‚Äñ: A function Œ® : C ‚Üí R is L-Lispchitz within a set C w.r.t.
a norm ‚Äñ ¬∑ ‚Äñ if the following holds.
‚àÄŒ∏1, Œ∏2 ‚àà C, |Œ®(Œ∏1)‚àíŒ®(Œ∏2)| ‚â§ L ¬∑ ‚ÄñŒ∏1 ‚àí Œ∏2‚Äñ.
Gaussian width of a set C: Let b ‚àº N (0, Ip) be a Gaussian random vector in Rp. The Gaussian
width of a set C is defined as GC
def
= Eb
[
sup
w‚ààC
|„Äàb, w„Äâ|
]
.
2 Private Convex Optimization by Frank-Wolfe algorithm
In this section we analyze a differentially private variant of the classical Frank-Wolfe algorithm [15].
We show that for the setting where the constraint set C is a polytope with k vertices, and the loss
function L(Œ∏; d) is Lipschitz w.r.t. the `1-norm, one can obtain an excess privacy risk of roughly
O(log k/n2/3). This in particular captures the high-dimensional linear regression setting. One such
example is the classical LASSO algorithm[27], which computes argminŒ∏:‚ÄñŒ∏‚Äñ1‚â§1
1
n‚ÄñXŒ∏ ‚àí y‚Äñ
2
2. In
the usual case of |xij |, |yj | = O(1), L(Œ∏) = 1n‚ÄñXŒ∏‚àíy‚Äñ
2
2 isO(1)-Lipschitz with respect to `1-norm,
we show that one can achieve the nearly optimal privacy risk of OÃÉ(1/n2/3).
The Frank-Wolfe algorithm [15] can be regarded as a ‚Äúgreedy‚Äù algorithm which moves towards
the optimum solution in the first order approximation (see Algorithm 1 for the description). How
fast Frank-Wolfe algorithm converges depends on L‚Äôs ‚Äúcurvature‚Äù, defined as follows according
to [8, 17]. We remark that a Œ≤-smooth function on C has curvature constant bounded by Œ≤‚ÄñC‚Äñ2.
Definition 2.1 (Curvature constant). For L : C ‚Üí R, define ŒìL as below.
ŒìL := sup
Œ∏1,Œ∏2,‚ààC,Œ≥‚àà(0,1],Œ∏3=Œ∏1+Œ≥(Œ∏2‚àíŒ∏1)
2
Œ≥2
(L(Œ∏3)‚àí L(Œ∏1)‚àí „ÄàŒ∏3 ‚àí Œ∏1,5L(Œ∏1)„Äâ) .
Remark 1. A useful bound can be derived for a quadratic loss L(Œ∏) = Œ∏ATAŒ∏ + „Äàb, Œ∏„Äâ. In this
case, by [8], ŒìL ‚â§ maxa,b‚ààA¬∑C ‚Äña ‚àí b‚Äñ22. When C is centrally symmetric, we have the bound
ŒìL ‚â§ 4 maxŒ∏‚ààC ‚ÄñAŒ∏‚Äñ22. For LASSO, A = 1‚àönX .
Define Œ∏‚àó = argmin
Œ∏‚ààC
L(Œ∏). The following theorem bounds the convergence rate of Frank-Wolfe
algorithm.
4
Algorithm 1 Frank-Wolfe algorithm
Input: C ‚äÜ Rp, L : C ‚Üí R, ¬µt
1: Choose an arbitrary Œ∏1 from C
2: for t = 1 to T ‚àí 1 do
3: Compute Œ∏ÃÉt = argminŒ∏‚ààC„Äà5L(Œ∏t), (Œ∏ ‚àí Œ∏t)„Äâ
4: Set Œ∏t+1 = Œ∏t + ¬µt(Œ∏ÃÉt ‚àí Œ∏t)
5: return Œ∏T .
Theorem 2.2 ([8, 17]). If we set ¬µt = 2/(t+ 2), then L(Œ∏T )‚àí L(Œ∏‚àó) = O(ŒìL/T ) .
While the Frank-Wolfe algorithm does not necessarily provide faster convergence compared to the
gradient-descent based method, it has two major advantages. First, on Line 3, it reduces the problem
to solving a minimization of linear function. When C is defined by small number of vertices, e.g.
when C is an `1 ball, the minimization can be done by checking „Äà5L(Œ∏t), x„Äâ for each vertex x of
C. This can be done efficiently. Secondly, each step in Frank-Wolfe takes a convex combination
of Œ∏t and Œ∏ÃÉt, which is on the boundary of C. Hence each intermediate solution is always inside C
(sometimes called projection free), and the final outcome Œ∏T is the convex combination of up to T
points on the boundary of C (or vertices of C when C is a polytope). Such outcome might be desired,
for example when C is a polytope, as it corresponds to a sparse solution. Due to these reasons
Frank-Wolfe algorithm has found many applications in machine learning [23, 16, 8]. As we shall
see below, these properties are also useful for obtaining low risk bounds for their private version.
2.1 Private Frank-Wolfe Algorithm
We now present a private version of the Frank-Wolfe algorithm. The algorithm accesses the private
data only through the loss function in step 3 of the algorithm. Thus to achieve privacy, it suffices to
replace this step by a private version.
To do so, we apply the exponential mechanism [21] to select an approximate optimizer. In the case
when the set C is a polytope, it suffices to optimize over the vertices of C due to the following basic
fact:
Fact 2.3. Let C ‚äÜ Rp be the convex hull of a compact set S ‚äÜ Rp. For any vector v ‚àà Rp,
arg min
Œ∏‚ààC
„ÄàŒ∏, v„Äâ ‚à© S 6= ‚àÖ.
Thus it suffices to run the exponential mechanism to select Œ∏t+1 from amongst the vertices of C.
This leads to a differentially private algorithm with risk logarithmically dependent on |S|. When
|S| is polynomial in p, it leads to an error bound with log p dependence. We can bound the error
in terms of the `1-Lipschitz constant, which can be much smaller than the `2-Lipschitz constant. In
particular, as we show in the next section, the private Frank-Wolfe algorithm is nearly optimal for
the important high-dimensional sparse linear regression problem.
Algorithm 2 ANoise‚àíFW(polytope): Differentially Private Frank-Wolfe Algorithm (Polytope Case)
Input: Data set: D = {d1, ¬∑ ¬∑ ¬∑ , dn}, loss function: L(Œ∏;D) = 1n
n‚àë
i=1
L(Œ∏; di) (with `1-Lipschitz
constant L1 for L), privacy parameters: (, Œ¥), convex set: C = conv(S) with ‚ÄñC‚Äñ1 denoting
maxs‚ààS ‚Äñs‚Äñ1.
1: Choose an arbitrary Œ∏1 from C
2: for t = 1 to T ‚àí 1 do
3: ‚àÄs ‚àà S, Œ±s ‚Üê „Äàs,5L(Œ∏t;D)„Äâ+ Lap
(
L1‚ÄñC‚Äñ1
‚àö
8T log(1/Œ¥)
n
)
, where Lap(Œª) ‚àº 12Œªe
‚àí|x|/Œª.
4: Œ∏ÃÉt ‚Üê arg min
s‚ààS
Œ±s.
5: Œ∏t+1 ‚Üê (1‚àí ¬µt)Œ∏t + ¬µtŒ∏ÃÉt, where ¬µt = 2t+2 .
6: Output Œ∏priv = Œ∏T .
Theorem 2.4 (Privacy guarantee). Algorithm 2 is (, Œ¥)-differentially private.
5
Since each data item is assumed to have bounded `‚àû norm, for two neighboring databases D and
D‚Ä≤ and any Œ∏ ‚àà C, s ‚àà S, we have that
|„Äàs,5L(Œ∏;D)„Äâ ‚àí „Äàs,5L(Œ∏;D)„Äâ| = O(L1‚ÄñC‚Äñ1/n) .
The proof of privacy then follows from a straight-forward application of the exponential mechanism
[21] or its noisy maximum version [3, Theorem 5]) and the strong composition theorem [13]. In
Theorem 2.5 we prove the utility guarantee for the private Frank-Wolfe algorithm for the convex
polytope case. Define ŒìL = max
D‚ààD
CL over all the possible data sets in D.
Theorem 2.5 (Utility guarantee). Let L1, S and ‚ÄñC‚Äñ1 be defined as in Algorithms 2 (Algorithm
ANoise‚àíFW(polytope)). Let ŒìL be an upper bound on the curvature constant (defined in Definition 2.1)
for the loss function L(¬∑; d) that holds for all d ‚àà D. In Algorithm ANoise‚àíFW(polytope), if we set
T = ŒìL
2/3(n)2/3
(L1‚ÄñC‚Äñ1)2/3
, then
E
[
L(Œ∏priv;D)
]
‚àímin
Œ∏‚ààC
L(Œ∏;D) = O
(
ŒìL
1/3 (L1‚ÄñC‚Äñ1)2/3 log(n|S|)
‚àö
log(1/Œ¥)
(n)2/3
)
.
Here the expectation is over the randomness of the algorithm.
The proof of utility uses known bounds on noisy Frank-Wolfe [17], along with error bounds for the
exponential mechanism. The details can be found in the full version.
General C While a variant of this mechanism can be applied to the case when C is not a polytope,
its error would depend on the size of a cover of the boundary of C, which can be exponential in p,
leading to an error bound with polynomial dependence on p. In the full version, we analyze another
variant of private Frank-Wolfe that uses objective perturbation to ensure privacy. This variant is
well-suited for a general convex set C and the following result, proven in the Appendix, bounds its
excess risk in terms of the Gaussian Width of C. For this mechanism, we only need C to be bounded
in `2 diameter, but our error now depends on the `2-Lipschitz constant of the loss functions.
Theorem 2.6. Suppose that each loss function is L2-Lipschitz with respect to the `2 norm, and that
C has `2 diameter at most ‚ÄñC‚Äñ2. Let GC the Gaussian width of the convex set C ‚äÜ Rp, and let ŒìL
be the curvature constant (defined in Definition 2.1) for the loss function `(Œ∏; d) for all Œ∏ ‚àà C and
d ‚àà D. Then there is an (, Œ¥)-differentially private algorithmANoise‚àíFW with excess empirical risk:
E
[
L(Œ∏priv;D)
]
‚àímin
Œ∏‚ààC
L(Œ∏;D) = O
(
ŒìL
1/3 (L2GC)
2/3
log2(n/Œ¥)
(n)2/3
)
.
Here the expectation is over the randomness of the algorithm.
2.2 Private LASSO algorithm
We now apply the private Frank-Wolfe algorithm ANoise‚àíFW(polytope) to the important case of the
sparse linear regression (or LASSO) problem.
Problem definition: Given a data set D = {(x1, y1), ¬∑ ¬∑ ¬∑ , (xn, yn)} of n-samples from the domain
D = {(x, y) : x ‚àà Rp, y ‚àà [‚àí1, 1], ‚Äñx‚Äñ‚àû ‚â§ 1}, and the convex set C = `p1. Define the mean
squared loss,
L(Œ∏;D) = 1
n
‚àë
i‚àà[n]
(„Äàxi, Œ∏„Äâ ‚àí yi)2 . (2)
The objective is to compute Œ∏priv ‚àà C to minimize L(Œ∏;D) while preserving privacy with respect to
any change of individual (xi, yi) pair. The non-private setting of the above problem is a variant of
the least squares problem with `1 regularization, which was started by the work of LASSO [27, 28]
and intensively studied in the past years.
Since the `1 ball is the convex hull of 2p vertices, we can apply the private Frank-Wolfe algo-
rithm ANoise‚àíFW(polytope). For the above setting, it is easy to check that the `1-Lipschitz constant is
bounded by O(1). Further, by applying the bound on quadratic programming Remark 1, we have
that CL ‚â§ 4 maxŒ∏‚ààC 1n‚ÄñXŒ∏‚Äñ
2
2 = O(1) since C is the unit `1 ball, and |xij | ‚â§ 1. Hence Œì = O(1).
Now applying Theorem 2.5, we have
6
Corollary 2.7. Let D = {(x1, y1), ¬∑ ¬∑ ¬∑ , (xn, yn)} of n samples from the domain D = {(x, y) :
‚Äñx‚Äñ‚àû ‚â§ 1, |y| ‚â§ 1}, and the convex set C equal to the `1-ball. The output Œ∏priv of Algorithm
ANoise‚àíFW(polytope) ensures the following.
E[L(Œ∏priv;D)‚àímin
Œ∏‚ààC
L(Œ∏;D)] = O
(
log(np/Œ¥)
(n)2/3
)
.
Remark 2. Compared to the previous work [20, 24], the above upper bound makes no assumption of
restricted strong convexity or mutual incoherence, which might be too strong for realistic settings.
Also our results significantly improve bounds of [19], from OÃÉ(1/n1/3) to OÃÉ(1/n2/3), which con-
sidered the case of the set C being the probability simplex and the loss being a generalized linear
model.
3 Optimality of Private LASSO
In the following, we shall show that to ensure privacy, the error bound in Corollary 2.7 is nearly
optimal in terms of the dominant factor of 1/n2/3.
Theorem 3.1 (Optimality of private Frank-Wolfe). Let C be the `1-ball and L be the mean squared
loss in equation (2). For every sufficiently large n, for every (, Œ¥)-differentially private algorithm
A, with  ‚â§ 0.1 and Œ¥ = o(1/n2), there exists a data setD = {(x1, y1), ¬∑ ¬∑ ¬∑ , (xn, yn)} of n samples
from the domain D = {(x, y) : ‚Äñx‚Äñ‚àû ‚â§ 1, |y| ‚â§ 1} such that
E[L(A(D);D)‚àímin
Œ∏‚ààC
L(Œ∏;D)] = ‚Ñ¶ÃÉ
(
1
n2/3
)
.
We prove the lower bound by following the fingerprinting codes argument of [4] for lowerbound-
ing the error of (, Œ¥)-differentially private algorithms. Similar to [4] and [14], we start with the
following lemma which is implicit in [4].The matrix X in Theorem 3.2 is the padded Tardos code
used in [14, Section 5]. For any matrix X , denote by X(i) the matrix obtained by removing the i-th
row of X . Call a column of a matrix a consensus column if the entries in the column are either all
1 or all ‚àí1. The sign of a consensus column is simply the consensus value of the column. Write
w = m/ logm and p = 1000m2. The following theorem follows immediately from the proof of
Corollary 16 in [14].
Theorem 3.2. [Corollary 16 from [14], restated] Letm be a sufficiently large positive integer. There
exists a matrix X ‚àà {‚àí1, 1}(w+1)√óp with the following property. For each i ‚àà [1, w + 1], there are
at least 0.999p consensus columns Wi in each X(i). In addition, for algorithm A on input matrix
X(i) where i ‚àà [1, w + 1], if with probability at least 2/3, A(X(i)) produces a p-dimensional sign
vector which agrees with at least 34p columns in Wi, then A is not (Œµ, Œ¥) differentially private with
respect to single row change (to some other row in X).
Write œÑ = 0.001. Let k = œÑwp. We first form an k √ó p matrix Y where the column vectors of
Y are mutually orthogonal {1,‚àí1} vectors. This is possible as k  p. Now we construct w + 1
databases Di for 1 ‚â§ i ‚â§ w + 1 as follows. For all the databases, they contain the common set of
examples (zj , 0) (i.e. vector zj with label 0) for 1 ‚â§ j ‚â§ k where zj = (Yj1, . . . , Yjp) is the j-th
row vector of Y . In addition, each Di contains w examples (xj , 1) for xj = (Xj1, . . . , Xjk) for
j 6= i. Then L(Œ∏;Di) is defined as follows (for the ease of notation in this proof, we work with the
un-normalized loss. This does not affect the generality of the arguments in any way.)
L(Œ∏;Di) =
‚àë
j 6=i
(xj ¬∑ Œ∏ ‚àí 1)2 +
k‚àë
j=1
(yj ¬∑ Œ∏)2 =
‚àë
j 6=i
(xj ¬∑ Œ∏ ‚àí 1)2 + k‚ÄñŒ∏‚Äñ22 .
The last equality is due to that the columns of Y are mutually orthogonal {‚àí1, 1} vectors. For each
Di, consider Œ∏‚àó ‚àà
{
‚àí 1p ,
1
p
}p
such that the sign of the coordinates of Œ∏‚àó matches the sign for the
consensus columns of X(i). Plugging Œ∏‚àó in L(Œ∏‚àó; DÃÇ) we have the following,
L(Œ∏‚àó; DÃÇ) ‚â§
w‚àë
i=1
(2œÑ)2 +
k
p
[since the number of consensus columns is at least (1‚àí œÑ)p]
= (œÑ + 4œÑ2)w . (3)
7
We now prove the crucial lemma, which states that if Œ∏ is such that ‚ÄñŒ∏‚Äñ1 ‚â§ 1 and L(Œ∏;Di) is small,
then Œ∏ has to agree with the sign of most of the consensus columns of X(i).
Lemma 3.3. Suppose that ‚ÄñŒ∏‚Äñ1 ‚â§ 1, and L(Œ∏;Di) < 1.1œÑw. For j ‚àà Wi, denote by sj the sign of
the consensus column j. Then we have
|{j ‚ààWi : sign(Œ∏j) = sj}| ‚â•
3
4
p .
Proof. For any S ‚äÜ {1, . . . , p}, denote by Œ∏|S the projection of Œ∏ to the coordinate subset S. Con-
sider three subsets S1, S2, S3, where
S1 = {j ‚ààWi : sign(Œ∏j) = sj} ,
S2 = {j ‚ààWi : sign(Œ∏j) 6= sj} ,
S3 = {1, . . . , p} \Wi .
The proof is by contradiction. Assume that |S1| < 34p.
Further denote Œ∏i = Œ∏|Si for i = 1, 2, 3. Now we will bound ‚ÄñŒ∏1‚Äñ1 and ‚ÄñŒ∏3‚Äñ1 using the inequality
‚Äñx‚Äñ2 ‚â• ‚Äñx‚Äñ1/
‚àö
d for any d-dimensional vector.
‚ÄñŒ∏3‚Äñ22 ‚â• ‚ÄñŒ∏3‚Äñ21/|S3| ‚â• ‚ÄñŒ∏3‚Äñ21/(œÑp) .
Hence k‚ÄñŒ∏3‚Äñ22 ‚â• w‚ÄñŒ∏3‚Äñ21. But k‚ÄñŒ∏3‚Äñ22 ‚â§ k‚ÄñŒ∏‚Äñ22 ‚â§ 1.1œÑw, so that ‚ÄñŒ∏3‚Äñ1 ‚â§
‚àö
1.1œÑ ‚â§ 0.04.
Similarly by the assumption of |S1| < 34p,
‚ÄñŒ∏1‚Äñ22 ‚â• ‚ÄñŒ∏1‚Äñ21/|S1| ‚â• 4‚ÄñŒ∏1‚Äñ21/(3p) .
Again using k‚ÄñŒ∏‚Äñ22 < 1.1œÑw, we have that ‚ÄñŒ∏1‚Äñ1 ‚â§
‚àö
1.1 ‚àó 3/4 ‚â§ 0.91.
Now we have „Äàxi, Œ∏„Äâ ‚àí 1 = ‚ÄñŒ∏1‚Äñ1 ‚àí ‚ÄñŒ∏2‚Äñ1 + Œ≤i ‚àí 1 where |Œ≤i| ‚â§ ‚ÄñŒ∏3‚Äñ1 ‚â§ 0.04. By ‚ÄñŒ∏1‚Äñ1 +
‚ÄñŒ∏2‚Äñ1 + ‚ÄñŒ∏3‚Äñ1 ‚â§ 1, we have
|„Äàxi, Œ∏„Äâ ‚àí 1| ‚â• 1‚àí ‚ÄñŒ∏1‚Äñ ‚àí |Œ≤i| ‚â• 1‚àí 0.91‚àí 0.04 = 0.05 .
Hence we have that L(Œ∏;Di) ‚â• (0.05)2w ‚â• 1.1œÑw. This leads to a contradiction. Hence we must
have |S1| ‚â• 34p.
With Theorem 3.2 and Lemma 3.3, we can now prove Theorem 3.1.
Proof. Suppose that A is private. And for the datasets we constructed above,
E[L(A(Di);Di)‚àímin
Œ∏
L(Œ∏;Di)] ‚â§ cw ,
for sufficiently small constant c. By Markov inequality, we have with probability at least 2/3,
L(A(Di);Di)‚àíminŒ∏ L(Œ∏;Di) ‚â§ 3cw. By (3), we have min
Œ∏
L(Œ∏;Di) ‚â§ (œÑ + 4œÑ2)w. Hence if we
choose c a constant small enough, we have with probability 2/3,
L(A(Di);Di) < (œÑ + 4œÑ2 + 3c)w ‚â§ 1.1œÑw . (4)
By Lemma 3.3, (4) implies thatA(Di) agrees with at least 34p consensus columns in X(i). However
by Theorem 3.2, this violates the privacy of A. Hence we have that there exists i, such that
E[L(A(Di);Di)‚àímin
Œ∏
L(Œ∏;Di)] > cw .
Recall that w = m/ logm and n = w + wp = O(m3/ logm). Hence we have that
E[L(A(Di);Di)‚àímin
Œ∏
L(Œ∏;Di)] = ‚Ñ¶(n1/3/ log2/3 n) .
The proof is completed by converting the above bound to the normalized version of
‚Ñ¶(1/(n log n)2/3).
8
References
[1] P. L. Bartlett and S. Mendelson. Rademacher and gaussian complexities: Risk bounds and structural
results. The Journal of Machine Learning Research, 3:463‚Äì482, 2003.
[2] R. Bassily, A. Smith, and A. Thakurta. Private empirical risk minimization, revisited. In FOCS, 2014.
[3] R. Bhaskar, S. Laxman, A. Smith, and A. Thakurta. Discovering frequent patterns in sensitive data. In
KDD, New York, NY, USA, 2010.
[4] M. Bun, J. Ullman, and S. Vadhan. Fingerprinting codes and the price of approximate differential privacy.
In STOC, 2014.
[5] V. Chandrasekaran, B. Recht, P. A. Parrilo, and A. S. Willsky. The convex geometry of linear inverse
problems. Foundations of Computational Mathematics, 12(6):805‚Äì849, 2012.
[6] K. Chaudhuri and C. Monteleoni. Privacy-preserving logistic regression. In NIPS, 2008.
[7] K. Chaudhuri, C. Monteleoni, and A. D. Sarwate. Differentially private empirical risk minimization.
JMLR, 12:1069‚Äì1109, 2011.
[8] K. L. Clarkson. Coresets, sparse greedy approximation, and the Frank-Wolfe algorithm. ACM Transations
on Algorithms, 2010.
[9] J. C. Duchi, M. I. Jordan, and M. J. Wainwright. Local privacy and statistical minimax rates. In FOCS,
2013.
[10] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise to sensitivity in private data analysis.
In Theory of Cryptography Conference, pages 265‚Äì284. Springer, 2006.
[11] C. Dwork, A. Nikolov, and K. Talwar. Efficient algorithms for privately releasing marginals via convex
relaxations. arXiv preprint arXiv:1308.1385, 2013.
[12] C. Dwork and A. Roth. The Algorithmic Foundations of Differential Privacy. Foundations and Trends in
Theoretical Computer Science. NOW Publishers, 2014.
[13] C. Dwork, G. N. Rothblum, and S. P. Vadhan. Boosting and differential privacy. In FOCS, 2010.
[14] C. Dwork, K. Talwar, A. Thakurta, and L. Zhang. Analyze gauss: optimal bounds for privacy-preserving
principal component analysis. In STOC, 2014.
[15] M. Frank and P. Wolfe. An algorithm for quadratic programming. Naval research logistics quarterly,
3(1-2):95‚Äì110, 1956.
[16] E. Hazan and S. Kale. Projection-free online learning. In ICML, 2012.
[17] M. Jaggi. Revisiting {Frank-Wolfe}: Projection-free sparse convex optimization. In ICML, 2013.
[18] P. Jain, P. Kothari, and A. Thakurta. Differentially private online learning. In COLT, pages 24.1‚Äì24.34,
2012.
[19] P. Jain and A. Thakurta. (near) dimension independent risk bounds for differentially private learning. In
International Conference on Machine Learning (ICML), 2014.
[20] D. Kifer, A. Smith, and A. Thakurta. Private convex empirical risk minimization and high-dimensional
regression. In COLT, pages 25.1‚Äì25.40, 2012.
[21] F. McSherry and K. Talwar. Mechanism design via differential privacy. In FOCS, pages 94‚Äì103. IEEE,
2007.
[22] A. Nikolov, K. Talwar, and L. Zhang. The geometry of differential privacy: The sparse and approximate
cases. In STOC, 2013.
[23] S. Shalev-Shwartz, N. Srebro, and T. Zhang. Trading accuracy for sparsity in optimization problems with
sparsity constraints. SIAM Journal on Optimization, 2010.
[24] A. Smith and A. Thakurta. Differentially private feature selection via stability arguments, and the robust-
ness of the Lasso. In COLT, 2013.
[25] A. Smith and A. Thakurta. Follow the perturbed leader is differentially private with optimal regret guar-
antees. Manuscript in preparation, 2013.
[26] A. Smith and A. Thakurta. Nearly optimal algorithms for private online learning in full-information and
bandit settings. In NIPS, 2013.
[27] R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society.
Series B (Methodological), 1996.
[28] R. Tibshirani et al. The Lasso method for variable selection in the cox model. Statistics in medicine,
16(4):385‚Äì395, 1997.
[29] J. Ullman. Private multiplicative weights beyond linear queries. CoRR, abs/1407.1571, 2014.
9
