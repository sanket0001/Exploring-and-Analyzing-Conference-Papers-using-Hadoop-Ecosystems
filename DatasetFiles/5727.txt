


Paper ID = 5727
Title = Convergence Analysis of Prediction Markets via
Randomized Subspace Descent
Rafael Frongillo
Department of Computer Science
University of Colorado, Boulder
raf@colorado.edu
Mark D. Reid
Research School of Computer Science
The Australian National University & NICTA
mark.reid@anu.edu.au
Abstract
Prediction markets are economic mechanisms for aggregating information about
future events through sequential interactions with traders. The pricing mecha-
nisms in these markets are known to be related to optimization algorithms in ma-
chine learning and through these connections we have some understanding of how
equilibrium market prices relate to the beliefs of the traders in a market. However,
little is known about rates and guarantees for the convergence of these sequential
mechanisms, and two recent papers cite this as an important open question.
In this paper we show how some previously studied prediction market trading
models can be understood as a natural generalization of randomized coordinate
descent which we call randomized subspace descent (RSD). We establish con-
vergence rates for RSD and leverage them to prove rates for the two prediction
market models above, answering the open questions. Our results extend beyond
standard centralized markets to arbitrary trade networks.
1 Introduction
In recent years, there has been an increasing appreciation of the shared mathematical foundations
between prediction markets and a variety of techniques in machine learning. Prediction markets
consist of agents who trade securities that pay out depending on the outcome of some uncertain,
future event. As trading takes place, the prices of these securities reflect an aggregation of the
beliefs the traders have about the future event. A popular class of mechanisms for updating these
prices as trading occurs has been shown to be closely related to techniques from online learning [7,
1, 21], convex optimization [10, 19, 13], probabilistic aggregation [24, 14], and crowdsourcing [3].
Building these connections serve several purposes, however one important line of research has been
to use insights from machine learning to better understand how to interpret prices in a prediction
market as aggregations of trader beliefs, and moreover, how the market together with the traders can
be viewed as something akin to a distributed machine learning algorithm [24].
The analysis in this paper was motivated in part by two pieces of work that considered the equilib-
ria of prediction markets with specific models of trader behavior: traders as risk minimizers [13];
and traders who maximize expected exponential utility using beliefs from exponential families [2].
In both cases, the focus was on understanding the properties of the market at convergence, and
questions concerning whether and how convergence happened were left as future work. In [2], the
authors note that â€œwe have not considered the dynamics by which such an equilibrium would be
reached, nor the rate of convergence etc., yet we think such questions provide fruitful directions
for future research.â€ In [13], â€œOne area of future work would be conducting a detailed analysis of
this framework using the tools of convex optimisation. A particularly interesting topic is to find the
conditions under which the market will converge.â€
1
The main contribution of this paper is to answer these questions of convergence. We do so by first
proposing a new and very general model of trading networks and dynamics (Â§3) that subsumes the
models used in [2] and [13] and provide a key structural result for what we call efficient trades in
these networks (Theorem 2). As an aside, this structural result provides an immediate generalization
of an existing aggregation result in [2] to trade networks of â€œcompatibleâ€ agents (Theorem 8). In
Â§4, we argue that efficient trades in our networks model can be viewed as steps of what we call
Random Subspace Descent (RSD) algorithm (Algorithm 1). This novel generalization of coordinate
descent allows an objective to be minimized by taking steps along affinely constrained subspaces,
and maybe be of independent interest beyond prediction market analysis. We provide a convergence
analysis of RSD under two sets of regularity constraints (Theorems 3 & 9) and show how these can
be used to derive (slow & fast) convergence rates in trade networks (Theorems 4 & 5).
Before introducing our general trading networks and convergence rate results, we first introduce the
now standard presentation of potential-based prediction markets [1] and the recent variant in which
all agents determine their trades using risk measures [13]. We will then state informal versions of
our main results so as to highlight how we address issues of convergence in existing frameworks.
2 Background and Informal Results
Prediction markets are mechanisms for eliciting and aggregating distributed information or beliefs
about uncertain future events. The set of events or outcomes under consideration in the market will
be denoted â„¦ and may be finite or infinite. For example, each outcome Ï‰ âˆˆ â„¦ might represent
a certain presidential candidate winning an election, the location of a missing submarine, or an
unknown label for an item in a data set. Following [1], the goods that are traded in a prediction
market are k outcome-dependent securities {Ï†(Â·)i}ki=1 that pay Ï†(Ï‰)i dollars should the outcome
Ï‰ âˆˆ â„¦ occur. We denote the set of distributions over â„¦ by âˆ†â„¦ and note, for any p âˆˆ âˆ†â„¦, that the
expected pay off for the securities under p is EÏ‰âˆ¼p [Ï†(Ï‰)] and the set of all expected pay offs is just
the convex hull, denoted Î  := conv(Ï†(â„¦)). A simple and commonly studied case is when â„¦ =
[k] := {1, . . . , k} (i.e., when there are exactly k outcomes) and the securities are the Arrow-Debreu
securities that pay out $1 should a specific outcome occur and nothing otherwise (i.e., Ï†(Ï‰)i = 1 if
Ï‰ = i and Ï†(Ï‰)i = 0 for Ï‰ 6= i). Here, the securities are just basis vectors for Rk and Î  = âˆ†â„¦.
Traders in a prediction market hold portfolios of securities r âˆˆ Rk called positions that pay out a
total of r Â· Ï†(Ï‰) =
âˆ‘k
i=1 riÏ†(Ï‰)i dollars should outcome Ï‰ occur. We denote the set of positions
byR = Rk. We will assume thatR always contains a position r$ that returns a dollar regardless of
which outcome occurs, meaning r$ Â· Ï†(Ï‰) = 1 for all Ï‰ âˆˆ â„¦. We therefore interpret r$ as â€œcashâ€
within the market in the sense that buying or selling r$ guarantees a fixed change in wealth.
In order to address the questions about convergence in [2, 13] we will consider a common form of
prediction market that is run through a market maker. This is an automated agent that is willing to
buy or sell securities in return for cash. The specific and well-studied prediction market mechanism
we consider is the potential-based market maker [1]. Here, traders interact with the market maker
sequentially, and the cost for each trade is determined by a convex potential function C : R â†’ R
applied to the market makerâ€™s state s âˆˆ R. Specifically, the cost for a trade dr when the market
maker has state s is given by cost(dr; s) = C(sâˆ’dr)âˆ’C(s), i.e., the change in potential value of the
market makerâ€™s position due to the market maker accepting the trade. After a trade, the market maker
updates the state to sâ† sâˆ’ dr.1 As noted in the next section, the usual axiomatic requirements for
a cost function (e.g., in [1]) specify a function that is effectively a risk measure, commonly studied
in mathematical finance (see, e.g., [9]).
2.1 Risk Measures
As in [13], agents in our framework will each quantify their uncertainty in positions using what is
known as risk measure. This is a function that assigns dollar values to positions. As Example 1
below shows, this assumption will also cover the case of agents maximizing exponential utility, as
considered in [2].
1It is more common in the prediction market literature for s to be a liability vector, tracking what the market
maker stands to lose instead of gain. Here we adopt positive positions to match the convention for risk measures.
2
A (convex monetary) risk measure is a function Ï : R â†’ R satisfying, for all r, râ€² âˆˆ R:
â€¢ Monotonicity: âˆ€Ï‰ r Â· Ï†(Ï‰) â‰¤ râ€² Â· Ï†(Ï‰) =â‡’ Ï(r) â‰¥ Ï(râ€²).
â€¢ Cash invariance: Ï(r + c r$) = Ï(r)âˆ’ c for all c âˆˆ R.
â€¢ Convexity: Ï
(
Î»r + (1âˆ’ Î»)râ€²
)
â‰¤ Î»Ï(r) + (1âˆ’ Î»)Ï(râ€²) for all Î» âˆˆ (0, 1).
â€¢ Normalization: Ï(0) = 0.
The reasonableness of these properties is usually argued as follows (see, e.g., [9]). Monotonicity
ensures that positions that result in strictly smaller payoffs regardless of the outcome are considered
more risky. Cash invariance captures the idea that if a guaranteed payment of $c is added to the
payment on each outcome then the risk will decrease by $c. Convexity states that merging positions
results in lower risk. Finally, normalization requires that holding no securities should carry no risk.
This last condition is only for convenience since any risk without this condition can trivially have its
argument translated so it holds without affecting the other three properties. A key result concerning
convex risk measures is the following representation theorem (cf. [9, Theorem 4.15], ).
Theorem 1 (Risk Representation). A functional Ï : R â†’ R is a convex risk measure if and only if
there is a closed convex function Î± : Î â†’ Râˆª{âˆ} such that Ï(r) = supÏ€âˆˆrelint(Î ) ã€ˆÏ€,âˆ’rã€‰âˆ’Î±(Ï€).
Here relint(Î ) denotes the relative interior of Î , the interior relative to the affine hull of Î . Notice
that if fâˆ— denotes the convex conjugate fâˆ—(y) := supx ã€ˆy, xã€‰ âˆ’ f(x), then this theorem states that
Ï(r) = Î±âˆ—(âˆ’r), that is, Ï and Î± are â€œdualâ€ in the same way prices and positions are dual [5, Â§5.4.4].
This suggests that the function Î± can be interpreted as a penalty function, assigning a measure of
â€œunlikelinessâ€ Î±(Ï€) to each expected value Ï€ of the securities defined above. Equivalently, Î±(Ep [Ï†])
measures the unlikeliness of distribution p over the outcomes. We can then see that the risk is the
greatest expected loss under each distribution, taking into account the penalties assigned by Î±.
Example 1. A well-studied risk measure is the entropic risk relative to a reference distribution
q âˆˆ âˆ†â„¦ [9]. This is defined on positions r âˆˆ R by ÏÎ²(r) := Î² logEÏ‰âˆ¼q [exp(âˆ’r Â· Ï†(Ï‰)/Î²)]. The
cost function C(r) = ÏÎ²(âˆ’r) associated with this risk exactly corresponds to the logarithmic mar-
ket scoring rule (LMSR). Its associated convex function Î±Î² over distributions is the scaled relative
entropy Î±Î²(p) = Î²KL(p | q). As discussed in [2, 13], the entropic risk is closely related to expo-
nential utility UÎ²(w) := âˆ’ 1Î² exp(âˆ’Î²w). Indeed, Ï
Î²(r) = âˆ’UÎ² (EÏ‰âˆ¼q [UÎ²(r Â· Ï†(Ï‰))]) which is just
the negative certainty equivalent of the position r â€” i.e., the amount of cash an agent with utility
UÎ² and belief q would be willing to trade for the uncertain position r. Due to the monotonicity of
Uâˆ’1Î² , it follows that a trader maximizing expected utility EÏ‰âˆ¼q [UÎ²(r Â· Ï†(Ï‰))] of holding position r
is equivalent to minimizing the entropic risk ÏÎ²(r).
For technical reasons, in addition to the standard assumptions for convex risk measures, we will also
make two weak regularity assumptions. These are similar to properties required of cost functions in
the prediction market literature (cf. [1, Theorem 3.2]):
â€¢ Expressiveness: Ï is everywhere differentiable, and closure{âˆ‡Ï(r) : r âˆˆ R} = Î .
â€¢ Strict risk aversion: the Convexity inequality is strict unless râˆ’ râ€² = c r$ for some c âˆˆ R.
As discussed in [1], expressiveness is related to the dual formulation given above; roughly, it says
that the agent must take into account every possible expected value of the securities when calculating
the risk. Strict risk aversion says that an agent should strictly prefer a mixture of positions, unless
of course the difference is outcome-independent.
Under these assumptions, the representation result of Theorem 1 and a similar result for cost func-
tions [1, Theorem 3.2]) coincide and we are able to show that cost functions and risk measures
are exactly the same object; we write ÏC(r) = C(r) when we think of C as a risk measure. Un-
folding the definition of cost now using cash invariance, we have ÏC(s âˆ’ dr + cost(dr; s)r$) =
ÏC(s âˆ’ dr) âˆ’ cost(dr; s) = C(s âˆ’ dr) âˆ’ C(s âˆ’ dr) + C(s) = ÏC(s). Thus, we may view a
potential-based market maker as a constant-risk agent.
2.2 Trading Dynamics and Aggregation
As described above, we consider traders who approach the market maker sequentially and at random,
and select the optimal trade based on their current position, the market state, and the cost functionC.
3
As we just observed, we may think of the market maker as a constant-risk agent with ÏC = C. Let
us examine the optimization problem faced by the trader with position r when the current market
state is s. This trader will choose a portfolio drâˆ— from the market maker so as to minimise her risk:
drâˆ— âˆˆ arg min
drâˆˆRk
Ï (r + dr âˆ’ cost(dr)r$) = arg min
drâˆˆRk
Ï(r + dr) + ÏC(sâˆ’ dr) . (1)
Since, by the cash invariance of Ï and the definition of cost, the objective is Ï(r + dr) + ÏC(s âˆ’
dr) âˆ’ ÏC(s), and ÏC(s) does not depend on dr. Thus, if we think of F (r, s) = Ï(r) + ÏC(s) as
a kind of â€œsocial riskâ€, we can define the surplus as simply the net risk taken away by an optimal
trade, namely F (r, s)âˆ’ F (r + drâˆ—, sâˆ’ drâˆ—).
We can now state our central question: if a set of N such traders arrive at random and execute
optimal (or perhaps near-optimal) trades with the market maker, will the market state converge to
the optimal risk, and if so how fast? As discussed in the introduction, this is precisely the question
asked in [2, 13] that we set out to answer. To do so we will draw a close connection to the literature
on distributed optimization algorithms for machine learning. Specifically, if we encode the entire
state of our system in the positions R = (r0 = s, r1, . . . , rn) of the market maker and each of the
n traders, we may view the optimal trade in eq. (1) as performing a coordinate descent step, by
optimizing only with respect to coordinates 0 and i. We build on this connection in Section 4 and
leverage a generalization of coordinate descent methods to show the following in Theorem 4: If a
set of risk-based traders is sampled at random to sequentially trade in the market, the market state
and prices converge to within  of the optimal total risk in O(1/) rounds.
In fact, under mild smoothness assumptions on the cost potential function C, we can improve this
rate to O(log(1/)). We can also relax the optimality of the trader behavior; as long as traders find
a trade dr which extracts at least a constant fraction of the surplus, the rate remains intact.
With convergence rates in hand, the next natural question might be: to what does the market con-
verge? Abernethy et al. [2] show that when traders minimize expected exponential utility and have
exponential family beliefs, the market equilibrium price can be thought of as a weighted average of
the parameters of the traders, with the weights being a measure of their risk tolerance. Even though
our setting is far more general than exponential utility and exponential families, the framework we
develop can also be used to show that their results can be extended to interactions between traders
who have what we call â€œcompatibleâ€ risks and beliefs. Specifically, for any risk-based trader pos-
sessing a risk Ï with dual Î±, we can think of that traderâ€™s â€œbeliefâ€ as the least surprising distribution
p according to Î±. This view induces a family of distributions (which happen to be generalized ex-
ponential families [11]) that are parameterized by the initial positions of the traders. Furthermore,
the risk tolerance b is given by how sensitive this belief is to small changes of an agentâ€™s position.
The results of [2] are then a special case of our Theorem 8 for agents with Ï being entropic risk (cf.
Example 1): If each trader i has risk tolerance bi and a belief parameterized by Î¸i, and the initial
market state is Î¸0, then the equilibrium state of the market, to which the market converges, is given
by Î¸âˆ— = Î¸0+
âˆ‘
i biÎ¸i
1+
âˆ‘
i bi
.
As the focus of this paper is on the convergence, the details for this result are given in Appendix C.
The main insight that drives the above analysis of the interaction between a risk-based trader and a
market maker is that each trade minimizes a global objective for the market that is the infimal convo-
lution [6] of the tradersâ€™ and market makerâ€™s risks. In fact, this observation naturally generalizes to
trades between three or more agents and the same convergence analysis applies. In other words, our
analysis also holds when bilateral trade with a fixed market maker is replaced by multilateral trade
among arbitrarily overlapping subsets of agents. Viewed as a graph with agents as nodes, the stan-
dard prediction market framework is represented by the star graph, where the central market market
interacts with traders sequentially and individually. More generally we have what we call a trading
network, in which the structure of trades can form arbitrary connected graphs or even hypergraphs.
An obvious choice is the complete graph, which can model a decentralized market, and in fact we
can even compare the convergence rate of our dynamics between the centralized and decentralized
models; see Appendix D.2 and the discussion in Â§ 5.
4
3 General Trading Dynamics
The previous section described the two agent case of what is more generally known as the optimal
risk allocation problem [6] where two or more agents express their preferences for positions via
risk measures. This is formalized by considering N agents with risk measures Ïi : R â†’ R for
i âˆˆ [N ] := {1, . . . , N} who are asked to split a position r âˆˆ R in to per-agent positions ri âˆˆ R
satisfying
âˆ‘
i ri = r so as to minimise the total risk
âˆ‘
i Ïi(ri). They note that the value of the total
risk is given by the infimal convolution âˆ§iÏi of the individual agent risks â€” that is,
(âˆ§iÏi)(r) := inf
{âˆ‘
i
Ïi(ri) :
âˆ‘
i
ri = r , ri âˆˆ R
}
. (2)
A key property of the infimal convolution, which will underly much of our analysis, is that its convex
conjugate is the sum of the conjugates of its constituent functions. See e.g. [23] for a proof.
(âˆ§iÏi)âˆ— =
âˆ‘
iâˆˆ[N ]
Ïâˆ—i . (3)
One can think of âˆ§iÏi as the â€œmarket riskâ€, which captures the risk of the entire market (i.e., as
if it were a single risk-based agent) as a function of the net position
âˆ‘
i ri of its constituents. By
definition, eq. (2) says that the market is trying to reallocate the risk so as to minimize this net risk.
This interpretation is confirmed by eq. (3) when we interpret the duals as penalty functions as above:
the penalty of Ï€ is the sum of the penalties of the market participants.
As alluded to above, we allow our agents to interact round by round by conducting trades, which are
simply the exchange of outcome-contingent securities. Since by assumption our position spaceR is
closed under linear combinations, a trade between two agents is simply a position which is added to
one agent and subtracted from another. Generalizing from this two agent interaction, a trade among
a set of agents S âŠ† [N ] is just a collection of trade vectors, one for each agent, which sum to 0.
Formally, let S âŠ† [N ] be a subset of agents. A trade on S is then a vector of positions dr âˆˆ RN
(i.e., a matrix in RNÃ—k) such that
âˆ‘
iâˆˆS dri = 0 âˆˆ R and dri = 0 for all i /âˆˆ S. This last condition
specifies that agents not in S do not change their position.
A key quantity in our analysis is a measure of how much the total risk of a collection of traders drops
due to trading. Given some subset of traders S, the S-surplus is a function Î¦S : RN â†’ R defined
by Î¦S(r) =
âˆ‘
iâˆˆS Ïi(ri)âˆ’ (âˆ§iÏi)(
âˆ‘
iâˆˆS ri) which measures the maximum achievable drop in risk
(since âˆ§iÏi is an infimum). In particular, Î¦(r) := Î¦[N ](r) is the surplus function. The trades that
achieve this optimal drop in risk are called efficient: given current state r âˆˆ RN , a trade dr âˆˆ RN
on S âŠ† [N ] is efficient if Î¦S(r + dr) = 0.
Our following key result shows that efficient trades have remarkable structure: once the state r and
subset S is specified, there is a unique efficient trade, up to cash transfers. In other words, the
surplus is removed from the position vectors and then redistributed as cash to the traders; the choice
of trade is merely in how this redistribution takes place. The fact that the derivatives match has strong
intuition from prediction markets: agents must agree on the price.2 The proof is in Appendix A.1.
Theorem 2. Let r âˆˆ RN and S âŠ† [N ] be given.
i. The surplus is always finite: 0 â‰¤ Î¦S(r) <âˆ.
ii. The set of efficient trades on S is nonempty.
iii. Efficient trades are unique up to zero-sum cash transfers: Given efficient trades drâˆ—, dr âˆˆ RN
on S, we have dr = drâˆ— + (z1r$ , . . . , zNr$) for some z âˆˆ RN with
âˆ‘
i zi = 0.
iv. Traders agree on â€œpricesâ€: A trade dr on S is efficient if and only if for all i, j âˆˆ S,
âˆ‡Ïi(ri + dri) = âˆ‡Ïj(rj + drj).
v. There is a unique â€œefficient priceâ€: If dr is an efficient trade on S, for all i âˆˆ S we have
âˆ‡Ïi(ri + dri) = âˆ’Ï€âˆ—S , where Ï€âˆ—S = arg min
Ï€âˆˆÎ 
âˆ‘
iâˆˆS Î±i(Ï€)âˆ’
âŒ©
Ï€,
âˆ‘
iâˆˆS ri
âŒª
.
2As intuition for the term â€œpriceâ€, consider that the highest price-per-unit agent i would be willing to pay
for an infinitesimal quantity of a position dri is dri Â· (âˆ’âˆ‡Ïi(ri)), and likewise the lowest price-per-unit to sell.
Thus, the entries of âˆ’âˆ‡Ïi(ri) act as the â€œfairâ€ prices for their corresponding basis positions/securities.
5
The above properties of efficient trades drive the remainder of our convergence analysis of network
dynamics. It also allows us to write a simple closed form for the market price when traders share
a common risk profile (Theorem 8). Details are in Appendix C. Beyond our current focus on rates,
Theorem 2 has implications for a variety of other economic properties of trade networks. For ex-
ample, in Appendix B we show that efficient trades correspond to fixed points for more general
dynamics, market clearing equilibria, and equilibria of natural bargaining games among the traders.
Recall that in the prediction market framework of [13], each round has a single trader, say i > 1,
interacting with the market maker who we will assume has index 1. In the notation just defined this
corresponds to choosing S = {1, i}. We now wish to consider richer dynamics where groups of two
or more agents trade efficiently each round. To this end will we call a collection S = {Sj âŠ† [N ]}mj=1
of groups of traders a trading network and assume there is some fixed distribution D over S with
full support. A trade dynamic over S is a process that begins at t = 0 with some initial positions
r0 âˆˆ RN for the N traders, and at each round t, draws a random group of traders St âˆˆ S according
to D, selects some efficient trade drt on S, then updates the trader positions using rt+1 = rt + drt.
For the purposes of proving the convergence of trade dynamics, a crucial property is whether all
traders can directly or indirectly affect the others. To capture this we will say a trade network
is connected if the hypergraph on [N ] with edges given by S is connected; i.e., information can
propagate throughout the entire network. Dynamics over classical prediction markets are always
connected since any pair of groups from its network will always contain the market maker.
4 Convergence Analysis of Randomized Subspace Descent
Before briefly reviewing the literature on coordinate descent, let us see why this might be a useful
way to think of our dynamics. Recall that we have a set S of subsets of agents, and that in each step,
an efficient trade dr is chosen which only modifies the positions of agents in the sampled S âˆˆ S.
Thinking of (r1, . . . , rN ) as a vector of dimension N Â· k vector (recall R = Rk), changing rt to
rt+1 = rt + dr thus only modifies |S| blocks of k entries. Moreover, efficiency ensures that dr
minimizes the sum of the risks of agents in S. Hence, ignoring for now the constraint that the sum
of the positions must remain constant, the trade dynamic seems to be performing a kind of block
coordinate descent of the surplus function Î¦.
4.1 Randomized Subspace Descent
Several randomized coordinate descent methods have appeared in the literature recently, with in-
creasing levels of sophistication. While earlier methods focused on updates which only modified
disjoint blocks of coordinates [18, 22], more recent methods allow for more general configurations,
such as overlapping blocks [17, 16, 20]. In fact, these last three methods are closest to what we study
here; the authors consider an objective which decomposes as the sum of convex functions on each
coordinate, and study coordinate updates which follow a graph structure, all under the constraint
that coordinates sum to 0. Despite the similarity of these methods to our trade dynamics, we require
even more general updates, as we allow coordinate i to correspond to arbitrary subsets Si âˆˆ S.
Instead, we establish a unification of these methods which we call randomized subspace descent
(RSD), listed in Algorithm 1. Rather than blocks of coordinates or specific linear constraints, RSD
abstracts away these constructs by simply specifying â€œcoordinate subspacesâ€ in which the optimiza-
tion is to be performed. Specifically, the algorithm takes a list of projection matrices {Î i}ni=1 which
define the subspaces, and at each step t selects a Î i at random and tries to optimize the objective
under the constraint that it may only move within the image space of Î i; that is, if the current point
is xt, then xt+1 âˆ’ xt âˆˆ im(Î i).
Before stating our convergence results for Algorithm 1, we will need a notion of smoothness relative
to our subspaces. Specifically, we say F is Li-Î i-smooth if for all i there are constants Li > 0 such
that for all y âˆˆ im(Î i),
F (x+ y) â‰¤ F (x) + ã€ˆâˆ‡F (x), yã€‰+ Li2 â€–yâ€–
2
2 . (4)
Finally, let Fmin := minyâˆˆspan{im(Î i)}i F (x
0 + y) be the global minimizer of F subject to the
constraints from the Î i. Then we have the following result for a constantR(x0) which increases in:
6
ALGORITHM 1: Randomized Subspace Descent
Input: Smooth convex function F : Rn â†’ R, initial point x0 âˆˆ Rn, matrices {Î i âˆˆ RnÃ—n}mi=1,
smoothness parameters {Li}mi=1, distribution p âˆˆ âˆ†m
for iteration t in {0, 1, 2, Â· Â· Â· } do
sample i from p
xt+1â† xt âˆ’ 1Li Î iâˆ‡F (x
t)
end
(1) the distance from the point x0 to furthest minimizer of F , (2) the Lipschitz constants of F w.r.t.
the Î i, and (3) the connectivity of the hypergraph induced by the projections.
Theorem 3. Let F , {Î i}i, {Li}i, x0, and p be given as in Algorithm 1, with the condition that F is
Li-Î i-smooth for all i. Then E
[
F (xt)âˆ’ Fmin
]
â‰¤ 2R2(x0) / t.
The proof is in Appendix D. Additionally, when F is strongly convex, meaning it has a uniform local
quadratic lower bound, RSD enjoys faster, linear convergence. Formally, this condition requires F
to be Âµ-strongly convex for some constant Âµ > 0, that is, for all x, y âˆˆ domF we require
F (y) â‰¥ F (x) +âˆ‡F (x) Â· (y âˆ’ x) + Âµ2 â€–y âˆ’ xâ€–
2 . (5)
The statement and details of this stronger result is given in Appendix D.1.
Importantly for our setting these results only track the progress per iteration. Thus, they apply to
more sophisticated update steps than a simple gradient step as long as they improve the objective
by at least as much. For example, if in each step the algorithm computed the exact minimizer
xt+1 = arg minyâˆˆim(Î i) F (x
t + y), both theorems would still hold.
4.2 Convergence Rates for Trade Dynamics
To apply Theorem 3 to the convergence of trading dynamics, we let F = Î¦ and x = (r1, . . . , rN ) âˆˆ
RN âˆ¼= RNk be the joint position of all agents. For each subset S âˆˆ S of agents, we have a subspace
of RN consisting of all possible trades on S, namely {dr âˆˆ RN : dri = 0 for i 6= S,
âˆ‘
iâˆˆS dri =
0}, with corresponding projection matrix Î S . For the special case of prediction markets with a
centralized market maker, we have N âˆ’ 1 subspaces S = {{1, i} : i âˆˆ {2, . . . , N}} and Î 1,i
projects onto {dr âˆˆ RN : dri = âˆ’dr1, drj = 0 for j 6= 1, i}. The intuition of coordinate descent is
clear now: the subset S of agents seek to minimize the total surplus within the subspace of trades on
S, and thus the coordinate descent steps of Algorithm 1 will correspond to roughly efficient trades.
We now apply Theorem 3 to show that trade dynamics achieve surplus  > 0 in time O(1/). Note
that we will have to assume the risk measure Ïi of agent i is Li-smooth for some Li > 0. This is a
very loose restriction, as our risk measures are all differentiable by the expressiveness condition.
Theorem 4. Let Ïi be an Li-smooth risk measure for all i. Then for any connected trade dynamic,
we have E [Î¦(rt)] = O(1/t).
Proof. Taking LS = maxiâˆˆS Li, one can check that F is LS-Î S-smooth for all S âˆˆ S by eq. (4).
Since Algorithm 1 has no state aside from xt, and the proof of Theorem 3 depends only the drop
in F per step, any algorithm selecting the sets S âˆˆ S with the same distribution and satisfying
F (xt+1) â‰¤ F (xt âˆ’ 1Li Î iâˆ‡F (x
t)) will yield the same convergence rate. As trade dynamics satisfy
F (xt+1) = minyâˆˆRNk F (x
t âˆ’Î iy), this property trivially holds, and so Theorem 3 applies.
If we assume slightly more, that our risk measures have local quadratic lower bounds, then we can
obtain linear convergence. Note that this is also a relatively weak assumption, and holds whenever
the risk measure has a Hessian with only one zero eigenvalue (for r$ ) at each point. This is satisfied,
for example, by all the variants of entropic risk we discuss in the paper. The proof is in Appendix D.
Theorem 5. Suppose for each i we have a continuous function Âµi : R â†’ R+ such that for all r,
risk Ïi is Âµi(r)-strongly convex with respect to r$
âŠ¥ in a neighborhood of r; in other words, eq. (5)
holds for F = Ïi, Âµ = Âµi(r), and all y in a neighborhood of r such that (r âˆ’ y) Â· r$ = 0. Then for
all connected trade dynamics, E [Î¦(rt)] = O(2âˆ’t).
7
Graph |V (G)| |E(G)| Î»2(G)
Kn n n(nâˆ’ 1)/2 n
Pn n nâˆ’ 1 2(1âˆ’cosÏ€n )
Cn n n 2(1âˆ’cos 2Ï€n )
K`,k `+ k `k k
Bk 2
k k2kâˆ’1 2
Table 1: Algebraic connectivities for common graphs.
Figure 1: Average (in bold) of 30 market simulations
for the complete and star graphs. The empirical gap in
iteration complexity is just under 2 (cf. Fig. 3).
Amazingly, the convergence rates in Theorem 4 and Theorem 5 hold for all connected trade dy-
namics. The constant hidden in the O(Â·) does depend on the structure of the network but can be
explicitly determined in terms its algebraic connectivity. This is discussed further in Appendix D.2.
The intuition behind these convergence rates given here is that agents in whichever group S is chosen
always trade to fully minimize their surplus. Because the proofs (in Appendix D) of these methods
merely track the reduction in surplus per trading round, the bounds apply as long as the update is at
least as good as a gradient step. In fact, we can say even more: if only an  fraction of the surplus is
taken at each round, the rates are still O(1/(t)) and O((1âˆ’ Âµ)t), respectively. This suggests that
our convergence results are robust with respect to the model of rationality one employs; if agents
have bounded rationality and can only compute positions which approximately minimize their risk,
the rates remain intact (up to constant factors) as long as the inefficiency is bounded.
5 Conclusions & Future Work
Using the tools of convex analysis to analyse the behavior of markets allows us to make precise,
quantitative statements about their global behavior. In this paper we have seen that, with appropriate
assumptions on trader behaviour, we can determine the rate at which the market will converge to
equilibrium prices, thereby closing some open questions raised in [2] and [13].
In addition, our newly proposed trading networks model allow us to consider a variety of prediction
market structures. As discussed in Â§3, the usual prediction market setting is centralized, and corre-
sponds to a star graph with the market maker at the center. A decentralized market where any trader
can trade with any other corresponds to a complete graph over the traders. We can also model more
exotic networks, such as two or more market maker-based prediction markets with a risk minimizing
arbitrageur or small-world networks where agents only trade with a limited number of â€œneighboursâ€.
Furthermore, because these arrangements are all instances of trade networks, we can immediately
compare the convergence rates across various constraints on how traders may interact. For example,
in Appendix D.2, we show that a market that trades through a centralized market maker incurs an
quantifiable efficiency overhead: convergence takes twice as long (see Figure 1). More generally,
we show that the rates scale as Î»2(G)/|E(G)|, allowing us to make similar comparisons between
arbitrary networks; see Table 1. This raises an interesting question for future work: given some
constraints such as a bound on how many traders a single agent can trade with, the total number of
edges, etc, which network optimizes the convergence rate of the market? These new models and
the analysis of their convergence may provide new principles for building and analyzing distributed
systems of heterogeneous and self-interested learning agents.
Acknowledgments
We would like to thank Matus Telgarsky for his generous help, as well as the lively discussions with,
and helpful comments of, SeÌbastien Lahaie, Miro DudÄ±Ìk, Jenn Wortman Vaughan, Yiling Chen,
David Parkes, and Nageeb Ali. MDR is supported by an ARC Discovery Early Career Research
Award (DE130101605). Part of this work was developed while he was visiting Microsoft Research.
8
References
[1] Jacob Abernethy, Yiling Chen, and Jennifer Wortman Vaughan. Efficient market making via convex
optimization, and a connection to online learning. ACM Transactions on Economics and Computation,
1(2):12, 2013.
[2] Jacob Abernethy, Sindhu Kutty, SeÌbastien Lahaie, and Rahul Sami. Information aggregation in expo-
nential family markets. In Proceedings of the fifteenth ACM conference on Economics and computation,
pages 395â€“412. ACM, 2014.
[3] Jacob D Abernethy and Rafael M Frongillo. A collaborative mechanism for crowdsourcing prediction
problems. In Advances in Neural Information Processing Systems, pages 2600â€“2608, 2011.
[4] Aharon Ben-Tal and Marc Teboulle. An old-new concept of convex risk measures: The optimized cer-
tainty equivalent. Mathematical Finance, 17(3):449â€“476, 2007.
[5] Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004.
[6] Christian Burgert and Ludger RuÌˆschendorf. On the optimal risk allocation problem. Statistics & decisions,
24(1/2006):153â€“171, 2006.
[7] Yiling Chen and Jennifer Wortman Vaughan. A new understanding of prediction markets via no-regret
learning. In Proceedings of the 11th ACM conference on Electronic commerce, pages 189â€“198. ACM,
2010.
[8] Nair Maria Maia de Abreu. Old and new results on algebraic connectivity of graphs. Linear algebra and
its applications, 423(1):53â€“73, 2007.
[9] Hans FoÌˆllmer and Alexander Schied. Stochastic Finance: An Introduction in Discrete Time, volume 27
of de Gruyter Studies in Mathematics. Walter de Gruyter & Co., Berlin, 2nd edition, 2004.
[10] Rafael M Frongillo, NicolaÌs Della Penna, and Mark D Reid. Interpreting prediction markets: a stochastic
approach. In Proceedings of Neural Information Processing Systems, 2012.
[11] P.D. GruÌˆnwald and A.P. Dawid. Game theory, maximum entropy, minimum discrepancy and robust
Bayesian decision theory. The Annals of Statistics, 32(4):1367â€“1433, 2004.
[12] JB Hiriart-Urruty and C LemareÌchal. Grundlehren der mathematischen wissenschaften. Convex Analysis
and Minimization Algorithms II, 306, 1993.
[13] Jinli Hu and Amos Storkey. Multi-period trading prediction markets with connections to machine learn-
ing. In Proceedings of the 31st International Conference on Machine Learning (ICML), 2014.
[14] Jono Millin, Krzysztof Geras, and Amos J Storkey. Isoelastic agents and wealth updates in machine
learning markets. In Proceedings of the 29th International Conference on Machine Learning (ICML-12),
pages 1815â€“1822, 2012.
[15] Bojan Mohar. The Laplacian spectrum of graphs. In Graph Theory, Combinatorics, and Applications,
1991.
[16] I Necoara, Y Nesterov, and F Glineur. A random coordinate descent method on large-scale optimization
problems with linear constraints. Technical Report, 2014.
[17] Ion Necoara. Random coordinate descent algorithms for multi-agent convex optimization over networks.
Automatic Control, IEEE Transactions on, 58(8):2001â€“2012, 2013.
[18] Yurii Nesterov. Efficiency of coordinate descent methods on huge-scale optimization problems. SIAM
Journal on Optimization, 22(2):341â€“362, 2012.
[19] Mindika Premachandra and Mark Reid. Aggregating predictions via sequential mini-trading. In Asian
Conference on Machine Learning, pages 373â€“387, 2013.
[20] Sashank Reddi, Ahmed Hefny, Carlton Downey, Avinava Dubey, and Suvrit Sra. Large-scale randomized-
coordinate descent methods with non-separable linear constraints. arXiv preprint arXiv:1409.2617, 2014.
[21] Mark D Reid, Rafael M Frongillo, Robert C Williamson, and Nishant Mehta. Generalized mixability via
entropic duality. In Proc. of Conference on Learning Theory (COLT), 2015.
[22] Peter RichtaÌrik and Martin TakaÌcÌŒ. Iteration complexity of randomized block-coordinate descent methods
for minimizing a composite function. Mathematical Programming, 144(1-2):1â€“38, 2014.
[23] R.T. Rockafellar. Convex analysis. Princeton University Press, 1997.
[24] Amos J Storkey. Machine learning markets. In International Conference on Artificial Intelligence and
Statistics, pages 716â€“724, 2011.
9
