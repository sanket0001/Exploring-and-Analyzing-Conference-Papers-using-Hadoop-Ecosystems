


Paper ID = 5843
Title = Accelerated Mirror Descent
in Continuous and Discrete Time
Walid Krichene
UC Berkeley
walid@eecs.berkeley.edu
Alexandre M. Bayen
UC Berkeley
bayen@berkeley.edu
Peter L. Bartlett
UC Berkeley and QUT
bartlett@berkeley.edu
Abstract
We study accelerated mirror descent dynamics in continuous and discrete time.
Combining the original continuous-time motivation of mirror descent with a re-
cent ODE interpretation of Nesterovâ€™s accelerated method, we propose a family of
continuous-time descent dynamics for convex functions with Lipschitz gradients,
such that the solution trajectories converge to the optimum at a O(1/t2) rate. We
then show that a large family of first-order accelerated methods can be obtained as
a discretization of the ODE, and these methods converge at a O(1/k2) rate. This
connection between accelerated mirror descent and the ODE provides an intuitive
approach to the design and analysis of accelerated first-order algorithms.
1 Introduction
We consider a convex optimization problem, minimizexâˆˆX f(x), where X âŠ† Rn is convex and
closed, f is a C1 convex function, and âˆ‡f is assumed to be Lf -Lipschitz. Let f? be the minimum
of f onX . Many convex optimization methods can be interpreted as the discretization of an ordinary
differential equation, the solutions of which are guaranteed to converge to the set of minimizers. Per-
haps the simplest such method is gradient descent, given by the iteration x(k+1) = x(k)âˆ’sâˆ‡f(x(k))
for some step size s, which can be interpreted as the discretization of the ODE XÌ‡(t) = âˆ’âˆ‡f(X(t)),
with discretization step s. The well-established theory of ordinary differential equations can provide
guidance in the design and analysis of optimization algorithms, and has been used for unconstrained
optimization [8, 7, 13], constrained optimization [27] and stochastic optimization [25]. In particular,
proving convergence of the solution trajectories of an ODE can often be achieved using simple and
elegant Lyapunov arguments. The ODE can then be carefully discretized to obtain an optimiza-
tion algorithm for which the convergence rate can be analyzed by using an analogous Lyapunov
argument in discrete time.
In this article, we focus on two families of first-order methods: Nesterovâ€™s accelerated method [22],
and Nemirovskiâ€™s mirror descent method [19]. First-order methods have become increasingly im-
portant for large-scale optimization problems that arise in machine learning applications. Nesterovâ€™s
accelerated method [22] has been applied to many problems and extended in a number of ways, see
for example [23, 20, 21, 4]. The mirror descent method also provides an important generaliza-
tion of the gradient descent method to non-Euclidean geometries, as discussed in [19, 3], and has
many applications in convex optimization [6, 5, 12, 15], as well as online learning [9, 11]. An in-
tuitive understanding of these methods is of particular importance for the design and analysis of
new algorithms. Although Nesterovâ€™s method has been notoriously hard to explain intuitively [14],
progress has been made recently: in [28], Su et al. give an ODE interpretation of Nesterovâ€™s method.
However, this interpretation is restricted to the original method [22], and does not apply to its ex-
tensions to non-Euclidean geometries. In [1], Allen-Zhu and Orecchia give another interpretation
of Nesterovâ€™s method, as performing, at each iteration, a convex combination of a mirror step and a
gradient step. Although it covers a broader family of algorithms (including non-Euclidean geome-
tries), this interpretation still requires an involved analysis, and lacks the simplicity and elegance of
1
ODEs. We provide a new interpretation which has the benefits of both approaches: we show that a
broad family of accelerated methods (which includes those studied in [28] and [1]) can be obtained
as a discretization of a simple ODE, which converges at a O(1/t2) rate. This provides a unified
interpretation, which could potentially simplify the design and analysis of first-order accelerated
methods.
The continuous-time interpretation [28] of Nesterovâ€™s method and the continuous-time motivation
of mirror descent [19] both rely on a Lyapunov argument. They are reviewed in Section 2. By
combining these ideas, we propose, in Section 3, a candidate Lyapunov function V (X(t), Z(t), t)
that depends on two state variables: X(t), which evolves in the primal space E = Rn, and Z(t),
which evolves in the dual space Eâˆ—, and we design coupled dynamics of (X,Z) to guarantee that
d
dtV (X(t), Z(t), t) â‰¤ 0. Such a function is said to be a Lyapunov function, in reference to [18];
see also [16]. This leads to a new family of ODE systems, given in Equation (5). We prove the
existence and uniqueness of the solution to (5) in Theorem 1. Then we prove in Thereom 2, using
the Lyapunov function V , that the solution trajectories are such that f(X(t)) âˆ’ f? = O(1/t2). In
Section 4, we give a discretization of these continuous-time dynamics, and obtain a family of accel-
erated mirror descent methods, for which we prove the sameO(1/k2) convergence rate (Theorem 3)
using a Lyapunov argument analogous to (though more involved than) the continuous-time case. We
give, as an example, a new accelerated method on the simplex, which can be viewed as performing,
at each step, a convex combination of two entropic projections with different step sizes. This ODE
interpretation of accelerated mirror descent gives new insights and allows us to extend recent results
such as the adaptive restarting heuristics proposed by Oâ€™Donoghue and CandeÌ€s in [24], which are
known to empirically improve the convergence rate. We test these methods on numerical examples
in Section 5 and comment on their performance.
2 ODE interpretations of Nemirovskiâ€™s mirror descent method and
Nesterovâ€™s accelerated method
Proving convergence of the solution trajectories of an ODE often involves a Lyapunov argument. For
example, to prove convergence of the solutions to the gradient descent ODE XÌ‡(t) = âˆ’âˆ‡f(X(t)),
consider the Lyapunov function V (X(t)) = 12â€–X(t)âˆ’ x?â€–2 for some minimizer x?. Then the time
derivative of V (X(t)) is given by
d
dt
V (X(t)) =
âŒ©
XÌ‡(t), X(t)âˆ’ x?
âŒª
= ã€ˆâˆ’âˆ‡f(X(t)), X(t)âˆ’ x?ã€‰ â‰¤ âˆ’(f(X(t))âˆ’ f?),
where the last inequality is by convexity of f . Integrating, we have V (X(t)) âˆ’ V (x0) â‰¤ tf? âˆ’âˆ« t
0
f(X(Ï„))dÏ„ , thus by Jensenâ€™s inequality, f
(
1
t
âˆ« t
0
X(Ï„)dÏ„
)
âˆ’ f? â‰¤ 1t
âˆ« t
0
f(X(Ï„))dÏ„ âˆ’ f? â‰¤
V (x0)
t , which proves that f
(
1
t
âˆ« t
0
X(Ï„)dÏ„
)
converges to f? at a O(1/t) rate.
2.1 Mirror descent ODE
The previous argument was extended by Nemirovski and Yudin in [19] to a family of methods
called mirror descent. The idea is to start from a non-negative function V , then to design dynamics
for which V is a Lyapunov function. Nemirovski and Yudin argue that one can replace the Lyapunov
function V (X(t)) = 12â€–X(t) âˆ’ x?â€–2 by a function on the dual space, V (Z(t)) = DÏˆâˆ—(Z(t), z?),
where Z(t) âˆˆ Eâˆ— is a dual variable for which we will design the dynamics (z? is the value of Z at
equilibrium), and the corresponding trajectory in the primal space isX(t) = âˆ‡Ïˆâˆ—(Z(t)). Here Ïˆâˆ— is
a convex function defined on Eâˆ—, such thatâˆ‡Ïˆâˆ— maps Eâˆ— to X , and DÏˆâˆ—(Z(t), z?) is the Bregman
divergence associated with Ïˆâˆ—, defined as DÏˆâˆ—(z, y) = Ïˆâˆ—(z) âˆ’ Ïˆâˆ—(y) âˆ’ ã€ˆâˆ‡Ïˆâˆ—(y), z âˆ’ yã€‰. The
function Ïˆâˆ— is said to be `-strongly convex w.r.t. a reference norm â€– Â· â€–âˆ— if Dâˆ—Ïˆ(z, y) â‰¥ `2â€–z âˆ’ yâ€–2âˆ—
for all y, z, and it is said to be L-smooth w.r.t. â€– Â· â€–âˆ— if DÏˆâˆ—(z, y) â‰¤ L2 â€–z âˆ’ yâ€–2âˆ—. For a review of
properties of Bregman divergences, see Chapter 11.2 in [11], or Appendix A in [2].
By definition of the Bregman divergence, we have
d
dt
V (Z(t)) =
d
dt
DÏˆâˆ—(Z(t), z
?) =
d
dt
(Ïˆâˆ—(Z(t))âˆ’ Ïˆâˆ—(z?)âˆ’ ã€ˆâˆ‡Ïˆâˆ—(zâˆ—), Z(t)âˆ’ z?ã€‰)
=
âŒ©
âˆ‡Ïˆâˆ—(Z(t))âˆ’âˆ‡Ïˆâˆ—(z?), ZÌ‡(t)
âŒª
=
âŒ©
X(t)âˆ’ x?, ZÌ‡(t)
âŒª
.
2
Therefore, if the dual variable Z obeys the dynamics ZÌ‡ = âˆ’âˆ‡f(X), then
d
dt
V (Z(t)) = âˆ’ã€ˆâˆ‡f(X(t)), X(t)âˆ’ x?ã€‰ â‰¤ âˆ’(f(X(t))âˆ’ f?)
and by the same argument as in the gradient descent ODE, V is a Lyapunov function and
f
(
1
t
âˆ« t
0
X(Ï„)dÏ„
)
âˆ’ f? converges to 0 at a O(1/t) rate. The mirror descent ODE system can be
summarized by ï£±ï£´ï£²ï£´ï£³
X = âˆ‡Ïˆâˆ—(Z)
ZÌ‡ = âˆ’âˆ‡f(X)
X(0) = x0, Z(0) = z0 withâˆ‡Ïˆâˆ—(z0) = x0
(1)
Note that since âˆ‡Ïˆâˆ— maps into X , X(t) = âˆ‡Ïˆâˆ—(Z(t)) remains in X . Finally, the unconstrained
gradient descent ODE can be obtained as a special case of the mirror descent ODE (1) by taking
Ïˆâˆ—(z) = 12â€–zâ€–2, for which âˆ‡Ïˆâˆ— is the identity, in which case X and Z coincide.
2.2 ODE interpretation of Nesterovâ€™s accelerated method
In [28], Su et al. show that Nesterovâ€™s accelerated method [22] can be interpreted as a discretization
of a second-order differential equation, given by{
XÌˆ + r+1
t
XÌ‡ +âˆ‡f(X) = 0
X(0) = x0, XÌ‡(0) = 0
(2)
The argument uses the following Lyapunov function (up to reparameterization), E(t) = t2r (f(X)âˆ’
f?) + r2â€–X + tr XÌ‡ âˆ’ x?â€–2, which is proved to be a Lyapunov function for the ODE (2) whenever
r â‰¥ 2. Since E is decreasing along trajectories of the system, it follows that for all t > 0, E(t) â‰¤
E(0) = r2â€–x0 âˆ’ x?â€–2, therefore f(X(t)) âˆ’ f? â‰¤ rt2 E(t) â‰¤ rt2 E(0) â‰¤ r
2
t2
â€–x0âˆ’x?â€–2
2 , which proves
that f(X(t)) converges to f? at a O(1/t2) rate. One should note in particular that the squared
Euclidean norm is used in the definition of E(t) and, as a consequence, discretizing the ODE (2)
leads to a family of unconstrained, Euclidean accelerated methods. In the next section, we show
that by combining this argument with Nemirovskiâ€™s idea of using a general Bregman divergence
as a Lyapunov function, we can construct a much more general family of ODE systems which
have the same O(1/t2) convergence guarantee. And by discretizing the resulting dynamics, we
obtain a general family of accelerated methods that are not restricted to the unconstrained Euclidean
geometry.
3 Continuous-time Accelerated Mirror Descent
3.1 Derivation of the accelerated mirror descent ODE
We consider a pair of dual convex functions, Ïˆ defined on X and Ïˆâˆ— defined on Eâˆ—, such that
âˆ‡Ïˆâˆ— : Eâˆ— â†’ X . We assume that Ïˆâˆ— is LÏˆâˆ— -smooth with respect to â€– Â· â€–âˆ—, a reference norm on the
dual space. Consider the function
V (X(t), Z(t), t) =
t2
r
(f(X(t))âˆ’ f?) + rDÏˆâˆ—(Z(t), z?) (3)
where Z is a dual variable for which we will design the dynamics, and z? is its value at equilibrium.
Taking the time-derivative of V , we have
d
dt
V (X(t), Z(t), t) =
2t
r
(f(X)âˆ’ f?) + t
2
r
âŒ©
âˆ‡f(X), XÌ‡
âŒª
+ r
âŒ©
ZÌ‡,âˆ‡Ïˆâˆ—(Z)âˆ’âˆ‡Ïˆâˆ—(z?)
âŒª
.
Assume that ZÌ‡ = âˆ’ trâˆ‡f(X). Then, the time-derivative of V becomes
d
dt
V (X(t), Z(t), t) =
2t
r
(f(X)âˆ’ f?)âˆ’ t
âŒ©
âˆ‡f(X),âˆ’ t
r
XÌ‡ +âˆ‡Ïˆâˆ—(Z)âˆ’âˆ‡Ïˆâˆ—(z?)
âŒª
.
Therefore, if Z is such thatâˆ‡Ïˆâˆ—(Z) = X + tr XÌ‡ , and âˆ‡Ïˆâˆ—(z?) = x?, then,
d
dt
V (X(t), Z(t), t) =
2t
r
(f(X)âˆ’ f?)âˆ’ t ã€ˆâˆ‡f(X), X âˆ’ x?ã€‰ â‰¤ 2t
r
(f(X)âˆ’ f?)âˆ’ t(f(X)âˆ’ f?)
â‰¤ âˆ’t r âˆ’ 2
r
(f(X)âˆ’ f?) (4)
3
and it follows that V is a Lyapunov function whenever r â‰¥ 2. The proposed ODE system is thenï£±ï£´ï£²ï£´ï£³
XÌ‡ = r
t
(âˆ‡Ïˆâˆ—(Z)âˆ’X),
ZÌ‡ = âˆ’ t
r
âˆ‡f(X),
X(0) = x0, Z(0) = z0, withâˆ‡Ïˆâˆ—(z0) = x0.
(5)
In the unconstrained Euclidean case, taking Ïˆâˆ—(z) = 12â€–zâ€–2, we have âˆ‡Ïˆâˆ—(z) = z, thus Z =
X + tr XÌ‡ , and the ODE system is equivalent to
d
dt
(
X + tr XÌ‡
)
= âˆ’ trâˆ‡f(X), which is equivalent to
the ODE (2) studied in [28], which we recover as a special case.
We also give another interpretation of ODE (5): the first equation is equivalent to trXÌ‡ + rtrâˆ’1X =
rtrâˆ’1âˆ‡Ïˆâˆ—(Z), or, in integral form, trX(t) = r
âˆ« t
0
Ï„ râˆ’1âˆ‡Ïˆâˆ—(Z(Ï„))dÏ„ , which can be written as
X(t) =
âˆ« t
0
w(Ï„)âˆ‡Ïˆâˆ—(Z(Ï„))dÏ„âˆ« t
0
w(Ï„)dÏ„
, with w(Ï„) = Ï„ râˆ’1. Therefore the coupled dynamics of (X,Z) can
be interpreted as follows: the dual variable Z accumulates gradients with a tr rate, while the primal
variable X is a weighted average of âˆ‡Ïˆâˆ—(Z(Ï„)) (the â€œmirroredâ€ dual trajectory), with weights
proportional to Ï„ râˆ’1. This also gives an interpretation of r as a parameter controlling the weight
distribution. It is also interesting to observe that the weights are increasing if and only if r â‰¥ 2.
Finally, with this averaging interpretation, it becomes clear that the primal trajectory X(t) remains
in X , sinceâˆ‡Ïˆâˆ— maps into X and X is convex.
3.2 Solution of the proposed dynamics
First, we prove existence and uniqueness of a solution to the ODE system (5), defined for all t >
0. By assumption, Ïˆâˆ— is LÏˆâˆ— -smooth w.r.t. â€– Â· â€–âˆ—, which is equivalent (see e.g. [26]) to âˆ‡Ïˆâˆ— is
LÏˆâˆ— -Lipschitz. Unfortunately, due to the rt term in the expression of XÌ‡ , the function (X,Z, t) 7â†’
(XÌ‡, ZÌ‡) is not Lipschitz at t = 0, and we cannot directly apply the Cauchy-Lipschitz existence and
uniqueness theorem. However, one can work around it by considering a sequence of approximating
ODEs, similarly to the argument used in [28].
Theorem 1. Suppose f is C1, and that âˆ‡f is Lf -Lipschitz, and let (x0, z0) âˆˆ X Ã— Eâˆ— such that
âˆ‡Ïˆâˆ—(z0) = x0. Then the accelerated mirror descent ODE system (5) with initial condition (x0, z0)
has a unique solution (X,Z), in C1([0,âˆž),Rn).
We will show existence of a solution on any given interval [0, T ] (uniqueness is proved in the sup-
plementary material). Let Î´ > 0, and consider the smoothed ODE systemï£±ï£´ï£²ï£´ï£³
XÌ‡ = r
max(t,Î´)
(âˆ‡Ïˆâˆ—(Z)âˆ’X),
ZÌ‡ = âˆ’ t
r
âˆ‡f(X),
X(0) = x0, Z(0) = z0 withâˆ‡Ïˆâˆ—(z0) = x0.
(6)
Since the functions (X,Z) 7â†’ âˆ’ trâˆ‡f(X) and (X,Z) 7â†’ rmax(t,Î´) (âˆ‡Ïˆâˆ—(Z)âˆ’X) are Lipschitz for
all t âˆˆ [0, T ], by the Cauchy-Lipschitz theorem (Theorem 2.5 in [29]), the system (6) has a unique
solution (XÎ´, ZÎ´) in C1([0, T ]). In order to show the existence of a solution to the original ODE,
we use the following Lemma (proved in the supplementary material).
Lemma 1. Let t0 = 2âˆš
LfLÏˆâˆ—
. Then the family of solutions
(
(XÎ´, ZÎ´)|[0,t0]
)
Î´â‰¤t0 is equi-Lipschitz-
continuous and uniformly bounded.
Proof of existence. Consider the family of solutions
(
(XÎ´i , ZÎ´i), Î´i = t02
âˆ’i)
iâˆˆN restricted to [0, t0].
By Lemma 1, this family is equi-Lipschitz-continuous and uniformly bounded, thus by the ArzelaÌ€-
Ascoli theorem, there exists a subsequence ((XÎ´i , ZÎ´i))iâˆˆI that converges uniformly on [0, t0]
(where I âŠ‚ N is an infinite set of indices). Let (XÌ„, ZÌ„) be its limit. Then we prove that (XÌ„, ZÌ„)
is a solution to the original ODE (5) on [0, t0].
First, since for all i âˆˆ I, XÎ´i(0) = x0 and ZÎ´i(0) = z0, it follows that XÌ„(0) =
limiâ†’âˆž,iâˆˆI XÎ´i(0) = x0 and ZÌ„(0) = limiâ†’âˆž,iâˆˆI ZÎ´i(0) = z0, thus (XÌ„, ZÌ„) satisfies the initial
conditions. Next, let t1 âˆˆ (0, t0), and let (XÌƒ, ZÌƒ) be the solution of the ODE (5) on t â‰¥ t1, with
initial condition (XÌ„(t1), ZÌ„(t1)). Since (XÎ´i(t1), ZÎ´i(t1))iâˆˆI â†’ (XÌ„(t1), ZÌ„(t1)) as iâ†’âˆž, then by
4
continuity of the solution w.r.t. initial conditions (Theorem 2.8 in [29]), we have that for some  > 0,
XÎ´i â†’ XÌƒ uniformly on [t1, t1 + ). But we also have XÎ´i â†’ XÌ„ uniformly on [0, t0], therefore XÌ„
and XÌƒ coincide on [t1, t1 +), therefore XÌ„ satisfies the ODE on [t1, t1 +). And since t1 is arbitrary
in (0, t0), this concludes the proof of existence.
3.3 Convergence rate
It is now straightforward to establish the convergence rate of the solution.
Theorem 2. Suppose that f has Lipschitz gradient, and that Ïˆâˆ— is a smooth distance generating
function. Let (X(t), Z(t)) be the solution to the accelerated mirror descent ODE (5) with r â‰¥ 2.
Then for all t > 0, f(X(t))âˆ’ f? â‰¤ r
2DÏˆâˆ— (z0,z
?)
t2 .
Proof. By construction of the ODE, V (X(t), Z(t), t) = t
2
r (f(X(t)) âˆ’ f?) + rDÏˆâˆ—(Z(t), z?) is
a Lyapunov function. It follows that for all t > 0, t
2
r (f(X(t)) âˆ’ f?) â‰¤ V (X(t), Z(t), t) â‰¤
V (x0, z0, 0) = rDÏˆâˆ—(z0, z
?).
4 Discretization
Next, we show that with a careful discretization of this continuous-time dynamics, we can obtain a
general family of accelerated mirror descent methods for constrained optimization. Using a mixed
forward/backward Euler scheme (see e.g. Chapter 2 in [10]), we can discretize the ODE system (5)
using a step size
âˆš
s as follows. Given a solution (X,Z) of the ODE (5), let tk = k
âˆš
s, and x(k) =
X(tk) = X(k
âˆš
s). Approximating XÌ‡(tk) with
X(tk+
âˆš
s)âˆ’X(tk)âˆš
s
, we propose the discretization{
x(k+1)âˆ’x(k)âˆš
s
= r
k
âˆš
s
(
âˆ‡Ïˆâˆ—(z(k))âˆ’ x(k+1)
)
,
z(k+1)âˆ’z(k)âˆš
s
+ k
âˆš
s
r âˆ‡f(x(k+1)) = 0.
(7)
The first equation can be rewritten as x(k+1) =
(
x(k) + rkâˆ‡Ïˆâˆ—(z(k))
)
/
(
1 + rk
)
(note the indepen-
dence on s, due to the time-scale invariance of the first ODE). In other words, x(k+1) is a convex
combination ofâˆ‡Ïˆâˆ—(z(k)) and x(k) with coefficients Î»k = rr+k and 1âˆ’ Î»k = kr+k . To summarize,
our first discrete scheme can be written as{
x(k+1) = Î»kâˆ‡Ïˆâˆ—(z(k)) + (1âˆ’ Î»k)x(k), Î»k = rr+k ,
z(k+1) = z(k) âˆ’ ksr âˆ‡f(x(k+1)).
(8)
Since âˆ‡Ïˆâˆ— maps into the feasible set X , starting from x(0) âˆˆ X guarantees that x(k) remains in X
for all k (by convexity ofX ). Note that by duality, we haveâˆ‡Ïˆâˆ—(xâˆ—) = arg maxxâˆˆX ã€ˆx, xâˆ—ã€‰âˆ’Ïˆ(x),
and if we additionally assume that Ïˆ is differentiable on the image of âˆ‡Ïˆâˆ—, then âˆ‡Ïˆ = (âˆ‡Ïˆâˆ—)âˆ’1
(Theorem 23.5 in [26]), thus if we write zÌƒ(k) = âˆ‡Ïˆâˆ—(z(k)), the second equation can be written as
zÌƒ(k+1) = âˆ‡Ïˆâˆ—(âˆ‡Ïˆ(zÌƒ(k))âˆ’ ks
r
âˆ‡f(x(k+1))) = arg min
xâˆˆX
Ïˆ(x)âˆ’
âŒ©
âˆ‡Ïˆ(zÌƒ(k))âˆ’ ks
r
âˆ‡f(x(k+1)), x
âŒª
= arg min
xâˆˆX
ks
r
âŒ©
âˆ‡f(x(k+1)), x
âŒª
+DÏˆ(x, zÌƒ
(k)).
We will eventually modify this scheme in order to be able to prove the desiredO(1/k2) convergence
rate. However, we start by analyzing this version. Motivated by the continuous-time Lyapunov
function (3), and using the correspondence t â‰ˆ kâˆšs, we consider the potential function E(k) =
V (x(k), z(k), k
âˆš
s) = k
2s
r (f(x
(k))âˆ’ f?) + rDÏˆâˆ—(z(k), z?). Then we have
E(k+1) âˆ’ E(k) = (k + 1)
2s
r
(f(x(k+1))âˆ’ f?)âˆ’ k
2s
r
(f(x(k))âˆ’ f?) + r(DÏˆâˆ—(z(k+1), z?)âˆ’DÏˆâˆ—(z(k), z?))
=
k2s
r
(f(x(k+1))âˆ’ f(x(k))) + s(1 + 2k)
r
(f(x(k+1))âˆ’ f?) + r(DÏˆâˆ—(z(k+1), z?)âˆ’DÏˆâˆ—(z(k), z?)).
5
And through simple algebraic manipulation, the last term can be bounded as follows
DÏˆâˆ—(z
(k+1), z?)âˆ’DÏˆâˆ—(z(k), z?)
= DÏˆâˆ—(z
(k+1), z(k)) +
âŒ©
âˆ‡Ïˆâˆ—(z(k))âˆ’âˆ‡Ïˆâˆ—(z?), z(k+1) âˆ’ z(k)
âŒª
by definition of the Bregman divergence
= DÏˆâˆ—(z
(k+1), z(k)) +
âŒ©
k
r
(x(k+1) âˆ’ x(k)) + x(k+1) âˆ’ x?,âˆ’ks
r
âˆ‡f(x(k+1))
âŒª
by the discretization (8)
â‰¤ DÏˆâˆ—(z(k+1), z(k)) +
k2s
r2
(f(x(k))âˆ’ f(x(k+1))) + ks
r
(f? âˆ’ f(x(k+1))). by convexity of f
Therefore we have E(k+1) âˆ’ E(k) â‰¤ âˆ’ s[(râˆ’2)kâˆ’1]r (f(x(k+1)) âˆ’ f?) + rDÏˆâˆ—(z(k+1), z(k)). Com-
paring this expression with the expression (4) of ddtV (X(t), Z(t), t) in the continuous-time case,
we see that we obtain an analogous expression, except for the additional Bregman divergence term
rDÏˆâˆ—(z
(k+1), z(k)), and we cannot immediately conclude that V is a Lyapunov function. This can
be remedied by the following modification of the discretization scheme.
4.1 A family of discrete-time accelerated mirror descent methods
In the expression (8) of x(k+1) = Î»kzÌƒ(k) + (1âˆ’ Î»k)x(k), we propose to replace x(k) with xÌƒ(k), ob-
tained as a solution to a minimization problem xÌƒ(k) = arg minxâˆˆX Î³s
âŒ©
âˆ‡f(x(k)), x
âŒª
+R(x, x(k)),
whereR is regularization function that satisfies the following assumptions: there exist 0 < `R â‰¤ LR
such that for all x, xâ€² âˆˆ X , `R2 â€–xâˆ’ xâ€²â€–2 â‰¤ R(x, xâ€²) â‰¤ LR2 â€–xâˆ’ xâ€²â€–2.
In the Euclidean case, one can take R(x, xâ€²) = â€–xâˆ’x
â€²â€–2
2 , in which case `R = LR = 1 and the
xÌƒ update becomes a prox-update. In the general case, one can take R(x, xâ€²) = DÏ†(x, xâ€²) for
some distance generating function Ï† which is `R-strongly convex and LR-smooth, in which case
the xÌƒ update becomes a mirror update. The resulting method is summarized in Algorithm 1. This
algorithm is a generalization of Allen-Zhu and Orecchiaâ€™s interpretation of Nesterovâ€™s method in [1],
where x(k+1) is a convex combination of a mirror descent update and a gradient descent update.
Algorithm 1 Accelerated mirror descent with distance generating function Ïˆâˆ—, regularizer R, step
size s, and parameter r â‰¥ 3
1: Initialize xÌƒ(0) = x0, zÌƒ(0) = x0,
(
or z(0) âˆˆ (âˆ‡Ïˆ)âˆ’1(x0)
)
.
2: for k âˆˆ N do
3: x(k+1) = Î»kzÌƒ(k) + (1âˆ’ Î»k)xÌƒ(k), with Î»k = rr+k .
4: zÌƒ(k+1) = arg minzÌƒâˆˆX
ks
r
âŒ©
âˆ‡f(x(k+1)), zÌƒ
âŒª
+DÏˆ(zÌƒ, zÌƒ
(k)).(
If Ïˆ is non-differentiable, z(k+1) = z(k) âˆ’ kr
s
âˆ‡f(x(k+1)) and zÌƒ(k+1) = âˆ‡Ïˆâˆ—(z(k+1)).
)
5: xÌƒ(k+1) = arg minxÌƒâˆˆX Î³s
âŒ©
âˆ‡f(x(k+1)), xÌƒ
âŒª
+R(xÌƒ, x(k+1))
4.2 Consistency of the modified scheme
One can show that given our assumptions on R, xÌƒ(k) = x(k) +O(s). Indeed, we have
`R
2
â€–xÌƒ(k) âˆ’ x(k)â€–2 â‰¤ R(xÌƒ(k), x(k)) â‰¤ R(x(k), x(k)) + Î³s
âŒ©
âˆ‡f(x(k)), x(k) âˆ’ xÌƒ(k)
âŒª
â‰¤ Î³sâ€–âˆ‡f(x(k))â€–âˆ—â€–xÌƒ(k) âˆ’ x(k)â€–
therefore â€–xÌƒ(k) âˆ’ x(k)â€– â‰¤ s 2Î³â€–âˆ‡f(x
(k))â€–âˆ—
`R
, which proves the claim. Using this observation, we
can show that the modified discretization scheme is consistent with the original ODE (5), that is,
the difference equations defining x(k) and z(k) converge, as s tends to 0, to the ordinary differential
equations of the continuous-time system (5). The difference equations of Algorithm 1 are equivalent
to (7) in which x(k) is replaced by xÌƒ(k), i.e.{
x(k+1)âˆ’xÌƒ(k)âˆš
s
= r
k
âˆš
s
(âˆ‡Ïˆâˆ—(z(k))âˆ’ x(k+1))
z(k+1)âˆ’z(k)âˆš
s
= âˆ’k
âˆš
s
r âˆ‡f(x(k+1))
6
Now suppose there exist C1 functions (X,Z), defined on R+, such that X(tk) â‰ˆ x(k) and
Z(tk) â‰ˆ z(k) for tk = k
âˆš
s. Then, using the fact that xÌƒ(k) = x(k) + O(s), we have
x(k+1)âˆ’xÌƒ(k)âˆš
s
= x
(k+1)âˆ’x(k)âˆš
s
+ O(âˆšs) â‰ˆ X(tk+
âˆš
s)âˆ’X(tk)âˆš
s
+ O(âˆšs) = XÌ‡(tk) + o(1), and simi-
larly, z
(k+1)âˆ’z(k)âˆš
s
â‰ˆ ZÌ‡(tk) + o(1), therefore the difference equation system can be written as{
XÌ‡(tk) + o(1) =
r
tk
(âˆ‡Ïˆâˆ—(Z(tk))âˆ’X(tk +
âˆš
s))
ZÌ‡(tk) + o(1) = âˆ’ tkr âˆ‡f(X(tk +
âˆš
s))
which converges to the ODE (5) as sâ†’ 0.
4.3 Convergence rate
To prove convergence of the algorithm, consider the modified potential function
EÌƒ(k) = V (xÌƒ(k), z(k), k
âˆš
s) = k
2s
r (f(xÌƒ
(k))âˆ’ f?) + rDÏˆâˆ—(z(k), z?).
Lemma 2. If Î³ â‰¥ LRLÏˆâˆ— and s â‰¤ `R2LfÎ³ , then for all k â‰¥ 0,
EÌƒ(k+1) âˆ’ EÌƒ(k) â‰¤ (2k + 1âˆ’ kr)s
r
(f(xÌƒ(k+1))âˆ’ f?).
As a consequence, if r â‰¥ 3, EÌƒ is a Lyapunov function for k â‰¥ 1.
This lemma is proved in the supplementary material.
Theorem 3. The discrete-time accelerated mirror descent Algorithm 1 with parameter r â‰¥ 3 and
step sizes Î³ â‰¥ LRLÏˆâˆ— , s â‰¤ `R2LfÎ³ , guarantees that for all k > 0,
f(xÌƒ(k)))âˆ’ f? â‰¤ r
sk2
EÌƒ(1) â‰¤ r
2DÏˆâˆ—(z0, z
?)
sk2
+
f(x0)âˆ’ f?
k2
.
Proof. The first inequality follows immediately from Lemma 2. The second inequality follows from
a simple bound on EÌƒ(1), proved in the supplementary material.
4.4 Example: accelerated entropic descent
We give an instance of Algorithm 1 for simplex-constrained problems. Suppose that X = âˆ†n =
{x âˆˆ Rn+ :
âˆ‘n
i=1 xi = 1} is the n-simplex. Taking Ïˆ to be the negative entropy on âˆ†, we have for
x âˆˆ X , z âˆˆ Eâˆ—,
Ïˆ(x) =
nâˆ‘
i=1
xi lnxi+Î´(x|âˆ†), Ïˆâˆ—(z) = ln
(
nâˆ‘
i=1
ezi
)
, âˆ‚Ïˆ(x) = (1 + lnxi)i+Ru, âˆ‡Ïˆ
âˆ—(z)i =
eziâˆ‘n
j=1 e
zj
.
where Î´(Â·|âˆ†) is the indicator function of the simplex (Î´(x|âˆ†) = 0 if x âˆˆ âˆ† and +âˆž otherwise),
and u âˆˆ Rn is a normal vector to the affine hull of the simplex. The resulting mirror descent
update is a simple entropy projection and can be computed exactly in O(n) operations, and Ïˆâˆ—
can be shown to be 1-smooth w.r.t. â€– Â· â€–âˆž, see for example [3, 6]. For the second update, we
take R(x, y) = DÏ†(x, y) where Ï† is a smoothed negative entropy function defined as follows:
let  > 0, and let Ï†(x) = 
âˆ‘n
i=1(xi + ) ln(xi + ) + Î´(x|âˆ†). Although no simple, closed-form
expression is known forâˆ‡Ï†âˆ—, it can be computed efficiently, inO(n log n) time using a deterministic
algorithm, or O(n) expected time using a randomized algorithm, see [17]. Additionally, Ï† satisfies
our assumptions: it is 1+n -strongly convex and 1-smooth w.r.t. â€– Â· â€–âˆž. The resulting accelerated
mirror descent method on the simplex can then be implemented efficiently, and by Theorem 3 it is
guaranteed to converge in O(1/k2) whenever Î³ â‰¥ 1 and s â‰¤ 2(1+n)LfÎ³ .
5 Numerical Experiments
We test the accelerated mirror descent method in Algorithm 1, on simplex-constrained prob-
lems in Rn, n = 100, with two different objective functions: a simple quadratic f(x) =
ã€ˆxâˆ’ x?, Q(xâˆ’ x?)ã€‰, for a random positive semi-definite matrix Q, and a log-sum-exp function
7
100 200 300 400 500 600 700
10âˆ’17
10âˆ’13
10âˆ’9
10âˆ’5
10âˆ’1
k
f
(x
(k
)
)
âˆ’
f
?
Mirror descent
Accelerated mirror descent
Speed restart
Gradient restart
(a) Weakly convex quadratic, rank 10
100 200 300 400 500 600
10âˆ’14
10âˆ’11
10âˆ’8
10âˆ’5
10âˆ’2
k
f
(x
(k
)
)
âˆ’
f
?
Mirror descent
Accelerated mirror descent
Speed restart
Gradient restart
(b) Log-sum-exp
100 200 300 400 500 600 700 800
10âˆ’17
10âˆ’14
10âˆ’11
10âˆ’8
10âˆ’5
10âˆ’2
k
f
(x
(k
)
)
âˆ’
f
?
r = 3
r = 10
r = 30
r = 90
(c) Effect of the parameter r.
Figure 1: Evolution of f(x(k)) âˆ’ f? on simplex-constrained problems, using different accelerated
mirror descent methods with entropy distance generating functions.
Algorithm 2 Accelerated mirror descent with restart
1: Initialize l = 0, xÌƒ(0) = zÌƒ(0) = x0.
2: for k âˆˆ N do
3: x(k+1) = Î»lzÌƒ(k) + (1âˆ’ Î»l)xÌƒ(k), with Î»l = rr+l
4: zÌƒ(k+1) = arg minzÌƒâˆˆX
ks
r
âŒ©
âˆ‡f(x(k+1)), zÌƒ
âŒª
+DÏˆ(zÌƒ, zÌƒ
(k))
5: xÌƒ(k+1) = arg minxÌƒâˆˆX Î³s
âŒ©
âˆ‡f(x(k+1)), xÌƒ
âŒª
+R(xÌƒ, x(k+1))
6: lâ† l + 1
7: if Restart condition then
8: zÌƒ(k+1) â† x(k+1), lâ† 0
given by f(x) = ln
(âˆ‘I
i=1 ã€ˆai, xã€‰+ bi
)
, where each entry in ai âˆˆ Rn and bi âˆˆ R is iid nor-
mal. We implement the accelerated entropic descent algorithm proposed in Section 4.4, and in-
clude the (non-accelerated) entropic descent for reference. We also adapt the gradient restarting
heuristic proposed by Oâ€™Donoghue and CandeÌ€s in [24], as well as the speed restart heuristic pro-
posed by Su et al. in [28]. The generic restart method is given in Algorithm 2. The restart condi-
tions are the following: (i) gradient restart:
âŒ©
x(k+1) âˆ’ x(k),âˆ‡f(x(k))
âŒª
> 0, and (ii) speed restart:
â€–x(k+1) âˆ’ x(k)â€– < â€–x(k) âˆ’ x(kâˆ’1)â€–.
The results are given in Figure 1. The accelerated mirror descent method exhibits a polynomial
convergence rate, which is empirically faster than the O(1/k2) rate predicted by Theorem 3. The
method also exhibits oscillations around the set of minimizers, and increasing the parameter r seems
to reduce the period of the oscillations, and results in a trajectory that is initially slower, but faster
for large k, see Figure 1-c. The restarting heuristics alleviate the oscillation and empirically speed
up the convergence. We also visualized, for each experiment, the trajectory of the iterates x(k) for
each method, projected on a 2-dimensional hyperplane. The corresponding videos are included in
the supplementary material.
6 Conclusion
By combining the Lyapunov argument that motivated mirror descent, and the recent ODE interpre-
tation [28] of Nesterovâ€™s method, we proposed a family of ODE systems for minimizing convex
functions with a Lipschitz gradient, which are guaranteed to converge at a O(1/t2) rate, and proved
existence and uniqueness of a solution. Then by discretizing the ODE, we proposed a family of
accelerated mirror descent methods for constrained optimization and proved an analogous O(1/k2)
rate when the step size is small enough. The connection with the continuous-time dynamics moti-
vates a more detailed study of the ODE (5), such as studying the oscillatory behavior of its solution
trajectories, its convergence rates under additional assumptions such as strong convexity, and a rig-
orous study of the restart heuristics.
Acknowledgments
We gratefully acknowledge the NSF (CCF-1115788, CNS-1238959, CNS-1238962, CNS-1239054,
CNS-1239166), the ARC (FL110100281 and ACEMS), and the Simons Institute Fall 2014 Algo-
rithmic Spectral Graph Theory Program.
8
References
[1] Zeyuan Allen-Zhu and Lorenzo Orecchia. Linear coupling: An ultimate unification of gradient and mirror
descent. In ArXiv, 2014.
[2] Arindam Banerjee, Srujana Merugu, Inderjit S. Dhillon, and Joydeep Ghosh. Clustering with Bregman
divergences. J. Mach. Learn. Res., 6:1705â€“1749, December 2005.
[3] Amir Beck and Marc Teboulle. Mirror descent and nonlinear projected subgradient methods for convex
optimization. Oper. Res. Lett., 31(3):167â€“175, May 2003.
[4] Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse prob-
lems. SIAM Journal on Imaging Sciences, 2(1):183â€“202, 2009.
[5] A. Ben-Tal and A. Nemirovski. Lectures on Modern Convex Optimization. SIAM, 2001.
[6] Aharon Ben-Tal, Tamar Margalit, and Arkadi Nemirovski. The ordered subsets mirror descent optimiza-
tion method with applications to tomography. SIAM J. on Optimization, 12(1):79â€“108, January 2001.
[7] Anthony Bloch, editor. Hamiltonian and gradient flows, algorithms, and control. American Mathematical
Society, 1994.
[8] A. A. Brown and M. C. Bartholomew-Biggs. Some effective methods for unconstrained optimization
based on the solution of systems of ordinary differential equations. Journal of Optimization Theory and
Applications, 62(2):211â€“224, 1989.
[9] SeÌbastien Bubeck and NicoloÌ€ Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed
bandit problems. Foundations and Trends in Machine Learning, 5(1):1â€“122, 2012.
[10] J. C. Butcher. Numerical Methods for Ordinary Differential Equations. John Wiley & Sons, Ltd, 2008.
[11] NicoloÌ€ Cesa-Bianchi and GaÌbor Lugosi. Prediction, Learning, and Games. Cambridge, 2006.
[12] Ofer Dekel, Ran Gilad-Bachrach, Ohad Shamir, and Lin Xiao. Optimal distributed online prediction. In
Proceedings of the 28th International Conference on Machine Learning (ICML), June 2011.
[13] U. Helmke and J.B. Moore. Optimization and dynamical systems. Communications and control engineer-
ing series. Springer-Verlag, 1994.
[14] Anatoli Juditsky. Convex Optimization II: Algorithms, Lecture Notes. 2013.
[15] Anatoli Juditsky, Arkadi Nemirovski, and Claire Tauvel. Solving variational inequalities with stochastic
mirror-prox algorithm. Stoch. Syst., 1(1):17â€“58, 2011.
[16] H.K. Khalil. Nonlinear systems. Macmillan Pub. Co., 1992.
[17] Walid Krichene, Syrine Krichene, and Alexandre Bayen. Efficient Bregman projections onto the simplex.
In 54th IEEE Conference on Decision and Control, 2015.
[18] A.M. Lyapunov. General Problem of the Stability Of Motion. Control Theory and Applications Series.
Taylor & Francis, 1992.
[19] A. S. Nemirovsky and D. B. Yudin. Problem Complexity and Method Efficiency in Optimization. Wiley-
Interscience series in discrete mathematics. Wiley, 1983.
[20] Yu. Nesterov. Smooth minimization of non-smooth functions. Mathematical Programming, 103(1):127â€“
152, 2005.
[21] Yu. Nesterov. Gradient methods for minimizing composite functions. Mathematical Programming,
140(1):125â€“161, 2013.
[22] Yurii Nesterov. A method of solving a convex programming problem with convergence rate o(1/k2).
Soviet Mathematics Doklady, 27(2):372â€“376, 1983.
[23] Yurii Nesterov. Introductory Lectures on Convex Optimization, volume 87. Springer Science & Business
Media, 2004.
[24] Brendan Oâ€™Donoghue and Emmanuel CandeÌ€s. Adaptive restart for accelerated gradient schemes. Foun-
dations of Computational Mathematics, 15(3):715â€“732, 2015.
[25] M. Raginsky and J. Bouvrie. Continuous-time stochastic mirror descent on a network: Variance reduction,
consensus, convergence. In CDC 2012, pages 6793â€“6800, 2012.
[26] R.T. Rockafellar. Convex Analysis. Princeton University Press, 1970.
[27] J. Schropp and I. Singer. A dynamical systems approach to constrained minimization. Numerical Func-
tional Analysis and Optimization, 21(3-4):537â€“551, 2000.
[28] Weijie Su, Stephen Boyd, and Emmanuel CandeÌ€s. A differential equation for modeling Nesterovâ€™s accel-
erated gradient method: Theory and insights. In NIPS, 2014.
[29] Gerald Teschl. Ordinary differential equations and dynamical systems, volume 140. American Mathe-
matical Soc., 2012.
9
