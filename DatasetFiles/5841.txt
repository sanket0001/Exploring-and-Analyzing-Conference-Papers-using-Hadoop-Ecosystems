


Paper ID = 5841
Title = Information-theoretic lower bounds for convex
optimization with erroneous oracles
Yaron Singer
Harvard University
Cambridge, MA 02138
yaron@seas.harvard.edu
Jan VondraÃÅk
IBM Almaden Research Center
San Jose, CA 95120
jvondrak@us.ibm.com
Abstract
We consider the problem of optimizing convex and concave functions with access
to an erroneous zeroth-order oracle. In particular, for a given function x ‚Üí f(x)
we consider optimization when one is given access to absolute error oracles that
return values in [f(x) ‚àí , f(x) + ] or relative error oracles that return value in
[(1‚àí )f(x), (1 + )f(x)], for some  > 0. We show stark information theoretic
impossibility results for minimizing convex functions and maximizing concave
functions over polytopes in this model.
1 Introduction
Consider the problem of minimizing a convex function over some convex domain. It is well known
that this problem is solvable in the sense that there are algorithms which make polynomially-many
calls to an oracle that evaluates the function at every given point, and return a point which is ar-
bitrarily close to the true minimum of the function. But suppose that instead of the true value of
the function, the oracle has some small error. Would it still be possible to optimize the function
efficiently? To formalize the notion of error, we can consider two types of erroneous oracles:
‚Ä¢ For a given function f : [0, 1]n ‚Üí [0, 1] we say that fÃÉ : [0, 1]n ‚Üí [0, 1] is an absolute
-erroneous oracle if ‚àÄx ‚àà [0, 1]n we have that: fÃÉ(x) = f(x) + Œæx where Œæx ‚àà [‚àí, ].
‚Ä¢ For a given function f : [0, 1]n ‚Üí R we say that fÃÉ : [0, 1]n ‚Üí R is a relative -erroneous
oracle if ‚àÄx ‚àà [0, 1]n we have that: fÃÉ(x) = Œæxf(x) where Œæx ‚àà [1‚àí , 1 + ].
Note that we intentionally do not make distributional assumptions about the errors. This is in con-
trast to noise, where the errors are assumed to be random and independently generated from some
distribution. In such cases, under reasonable conditions on the distribution, one can obtain arbitrar-
ily good approximations of the true function value by averaging polynomially many points in some
-ball around the point of interest. Stated in terms of noise, in this paper we consider oracles that
have some small adversarial noise, and wish to understand whether desirable optimization guaran-
tees are obtainable. To avoid ambiguity, we refrain from using the term noise altogether, and refer
to such as inaccuracies in evaluation as error.
While distributional i.i.d. assumptions are often reasonable models, evaluating our dependency on
these assumptions seems necessary. From a practical perspective, there are cases in which noise
can be correlated, or where the data we use to estimate the function is corrupted in some arbitrary
way. Furthermore, since we often optimize over functions that we learn from data, the process of
fitting a model to a function may also introduce some bias that does not necessarily vanish, or may
vanish. But more generally, it seems like we should morally know the consequences that modest
inaccuracies may have.
1
x
f(x)
Figure 1: An illustration of an erroneous oracle to a convex function that fools a gradient descent algorithm.
Benign cases. In the special case of a linear function f(x) = c·µÄx, for some c ‚àà Rn, a rela-
tive -error has little effect on the optimization. By querying f(ei), for every i ‚àà [n] we can extract
cÃÉi ‚àà [(1‚àí)ci, (1+)ci] and then optimize over f ‚Ä≤(x) = cÃÉ·µÄx. This results in a (1¬±)-multiplicative
approximation. Alternatively, if the erroneous oracle fÃÉ happens to be a convex function, optimiz-
ing fÃÉ(x) directly retains desirable optimization guarantees, up to either additive and multiplicative
errors. We are therefore interested in scenarios where the error does not necessarily have nice prop-
erties.
Gradient descent fails with error. For a simple example, consider the function illustrated in
Figure 1. The figure illustrates a convex function (depicted in blue) and an erroneous version of
it (dotted red), s.t. on every point, the oracle is at most some additive  > 0 away from the true
function value (the  margins of the function are depicted in grey). If we assume that a gradient
descent algorithm is given access to the erroneous version (dotted red) instead of the true function
(blue), the algorithm will be trapped in a local minimum that can be arbitrarily far from the true
minimum. But the fact that a naive gradient descent algorithm fails does not necessarily mean that
there isn‚Äôt an algorithm that can overcome small errors. This narrates the main question in this paper.
Is convex optimization robust to error?
Main Results. Our results are largely spoilers. We present stark information-theoretic lower
bounds for both relative and absolute -erroneous oracles, for any constant and even sub-constant
 > 0. In particular, we show that:
‚Ä¢ For minimizing a convex function (or maximizing a concave function) f : [0, 1]n ‚Üí [0, 1]
over [0, 1]n: we show that for any fixed Œ¥ > 0, no algorithm can achieve an additive
approximation within 1/2 ‚àí Œ¥ of the optimum, using a subexponential number of calls to
an absolute n‚àí1/2+Œ¥-erroneous oracle.
‚Ä¢ For minimizing a convex function f : [0, 1]n ‚Üí [0, 1] over a polytope P ‚äÇ [0, 1]n: for any
fixed  > 0, no algorithm can achieve a finite multiplicative factor using a subexponential
number of calls to a relative -erroneous oracle.
‚Ä¢ For maximizing a concave function f : [0, 1]n ‚Üí [0, 1] over a polytope P ‚äÇ [0, 1]n: for
any fixed  > 0, no algorithm can achieve a multiplicative factor better than Œò(n‚àí1/2+)
using a subexponential number of calls to a relative -erroneous oracle;
‚Ä¢ For maximizing a concave function f : [0, 1]n ‚Üí [0, 1] over [0, 1]n: for any fixed  > 0,
no algorithm can obtain a multiplicative factor better than 1/2 +  using a subexponential
number of calls to a relative -erroneous oracle. (And there is a trivial 1/2-approximation
without asking any queries.)
Somewhat surprisingly, many of the impossibility results listed above are shown for a class of ex-
tremely simple convex and concave functions, namely, affine functions: f(x) = c·µÄx + b. This is
2
in sharp contrast to the case of linear functions (without the constant term b) with relative erroneous
oracles as discussed above. In addition, we note that our results extend to strongly convex functions.
1.1 Related work
The oracle models we study here fall in the category of zeroth-order or derivative free. Derivative-
free methods have a rich history in convex optimization and were among the earliest to numerically
solve unconstrained optimization problems. Recently these approaches have enjoyed increasing
interest, as they are useful in scenarios where black-box access is given to the function or cases in
which gradient information is difficult to compute or does not exist [9, 8, 11, 15, 14, 6]
There has been a rich line of work for noisy oracles, where the oracles return some erroneous version
of the function value which is random. In a stochastic framework, these settings correspond to
repeatedly choosing points in some convex domain, obtaining noisy realizations of some underlying
convex function‚Äôs value. Most frequently, the assumption is that one is given a first-order noisy
oracle with some assumptions about the distribution that generates the error [13, 12]. In the learning
theory community, optimization with stochastic noisy oracles is often motivated by multi-armed
bandits settings [4, 1], and regret minimization with zeroth-order feedback [2]. All these models
consider the case in which the error is drawn from a distribution.
The model of adversarial noise in zeroth order oracles has been mentioned in [10] which considers
a related model of erroneous oracles and informally argues that exponentially many queries are
required to approximately minimize a convex function in this model (under an `2-ball constraint).
In recent work, Belloni et al. [3] study convex optimization with erroneous oracles. Interestingly,
Belloni et al. show positive results. In their work they develop a novel algorithm that is based on
sampling from an approximately log-concave distribution using the Hit-and-Run method and show
that their method has polynomial query complexity. In contrast to the negative results we show in
this work, the work of Belloni et al. assumes the (absolute) erroneous oracle returns f(x) + Œæx
with Œæx ‚àà [‚àí n ,

n ]. That is, the error is not a constant term, but rather is inversely proportional
to the dimension. Our lower bounds for additive approximation hold when the oracle error is not
necessarily a constant but Œæx ‚àà [ 1n1/2‚àíŒ¥ ,
1
n1/2‚àíŒ¥
] for a constant 0 < Œ¥ < 1/2.
2 Preliminaries
Optimization and convexity. For a minimization problem, given a nonnegative objective function
f and a polytope P we will say that an algorithm provides a (multiplicative) Œ±-approximation (Œ± >
1) if it finds a point xÃÑ ‚àà P s.t. f(xÃÑ) ‚â§ Œ±minx‚ààP f(x). For a maximization problem, an algorithm
provides an Œ±-approximation (Œ± < 1) if it finds a point xÃÑ s.t. f(xÃÑ) ‚â• Œ±maxx‚ààP f(x).
For absolute erroneous oracles, given an objective function f and a polytope P we will aim to find
a point xÃÑ ‚àà P which is within an additive error of Œ¥ from the optimum, with Œ¥ as small as possible.
That is, for a Œ¥ > 0 we aim to find a point xÃÑ s.t. |f(xÃÑ)‚àíminx f(x)| < Œ¥ in the case of minimization.
A function f : P ‚Üí R is convex on P if f(tx + (1 ‚àí t)y) ‚â§ tf(x) + (1 ‚àí t)f(y) (or concave if
f(tx + (1‚àí t)y) ‚â• tf(x) + (1‚àí t)f(y)) for every x,y ‚àà P and t ‚àà [0, 1].
Chernoff bounds. Throughout the paper we appeal to the Chernoff bounds. We note that while
typically stated for independent random variables X1, . . . , Xm, Chernoff bounds also hold for neg-
atively associated random variables.
Definition 2.1 ([5], Definition 1). Random variables X1, . . . , Xn are negatively associated, if for
every I ‚äÜ [n] and every non-decreasing f : RI ‚Üí R, g : RIÃÑ ‚Üí R,
E[f(Xi, i ‚àà I)g(Xj , j ‚àà IÃÑ)] ‚â§ E[f(Xi, i ‚àà I)]E[g(Xj , j ‚àà IÃÑ)].
Claim 2.2 ([5], Theorem 14). Let X1, . . . , Xn be negatively associated random variables that take
values in [0, 1] and ¬µ = E[
‚àën
i=1Xi]. Then, for any Œ¥ ‚àà [0, 1] we have that:
Pr[
n‚àë
i=1
Xi > (1 + Œ¥)¬µ] ‚â§ e‚àíŒ¥
2¬µ/3,
3
Pr[
n‚àë
i=1
Xi < (1‚àí Œ¥)¬µ] ‚â§ e‚àíŒ¥
2¬µ/2.
We apply this to random variables that are formed by selecting a random subset of a fixed size. In
particular, we use the following.
Claim 2.3. Let x1, . . . , xn ‚â• 0 be fixed. For 1 ‚â§ k ‚â§ n, let R be a uniformly random subset of k
elements out of [n]. Let Xi = xi if i ‚àà R and Xi = 0 otherwise. Then X1, . . . , Xn are negatively
associated.
Proof. For x1 = x2 = . . . = xn = 1, the statement holds by Corollary 11 of [5] (which refers
to this distribution as the Fermi-Dirac model). The generalization to arbitrary xi ‚â• 0 follows from
Proposition 4 of [5] with Ij = {j} and hj(t) = xjt.
3 Optimization over the unit cube
We start with optimization over [0, 1]n, arguably the simplest possible polytope. We show that
already in this setting, the presence of adversarial noise prevents us from achieving much more than
trivial results.
3.1 Convex minimization
First let us consider convex minimization over [0, 1]n. In this setting, we show that errors as small
as n‚àí(1‚àíŒ¥)/2 prevent us from optimizing within a constant additive error.
Theorem 3.1. Let Œ¥ > 0 be a constant. There are instances of a convex function f : [0, 1]n ‚Üí
[0, 1] accessible through an absolute n‚àí(1‚àíŒ¥)/2-erroneous oracle, such that a (possibly randomized)
algorithm that makes eO(n
Œ¥) queries cannot find a solution of value better than within additive
1/2‚àí o(1) of the optimum with probability more than e‚àí‚Ñ¶(nŒ¥).
We remark that the proof of this theorem is inspired by the proof of hardness of ( 12 + )-
approximation for unconstrained submodular maximization [7]; in particular it can be viewed as
a simple application of the ‚Äúsymmetry gap‚Äù argument (see [16] for a more general exposition).
Proof. Let  = n‚àí(1‚àíŒ¥)/2; we can assume that  < 12 , otherwise n is constant and the statement
is trivial. We will construct an -erroneous oracle (both in the relative and absolute sense) for a
convex function f : [0, 1]n ‚Üí [0, 1]. Consider a partition of [n] into two subsets A,B of size
|A| = |B| = n/2 (which will be eventually chosen randomly). We define the following function:
‚Ä¢ f(x) = 12 +
1
n (
‚àë
i‚ààA xi ‚àí
‚àë
j‚ààB xj).
This is a convex (in fact linear) function. Next, we define the following modification of f , which
could be the function returned by an -erroneous oracle.
‚Ä¢ If |
‚àë
i‚ààA xi ‚àí
‚àë
j‚ààB xj | >
1
2n, then fÃÉ(x) = f(x) =
1
2 +
1
n (
‚àë
i‚ààA xi ‚àí
‚àë
j‚ààB xj).
‚Ä¢ If |
‚àë
i‚ààA xi ‚àí
‚àë
j‚ààB xj | ‚â§
1
2n, then fÃÉ(x) =
1
2 .
Note that f(x) and fÃÉ(x) differ only in the region where |
‚àë
i‚ààA xi‚àí
‚àë
j‚ààB xj | ‚â§
1
2n. In particular,
the value of f(x) in this region is within [ 1‚àí2 ,
1+
2 ], while fÃÉ(x) =
1
2 , so an -erroneous oracle for
f(x) (both in the relative and absolute sense) could very well return fÃÉ(x) instead.
Now assume that (A,B) is a random partition, unknown to the algorithm. We argue that with
high probability, a fixed query x issued by the algorithm will have the property that |
‚àë
i‚ààA xi ‚àí‚àë
j‚ààB xj | ‚â§
1
2n. More precisely, since (A,B) is chosen at random subject to |A| = |B| = n/2,
4
we have that
‚àë
i‚ààA xi is a sum of negatively associated random variables in [0, 1] (by Claim 2.3).
The expectation of this quantity is ¬µ = E[
‚àë
i‚ààA xi] =
1
2
‚àën
i=1 xi ‚â§
1
2n. By Claim 2.2, we have
Pr[
‚àë
i‚ààA
xi > ¬µ+
1
4
n] = Pr[
‚àë
i‚ààA
xi > (1 +
n
4¬µ
)¬µ] < e‚àí(n/(4¬µ))
2¬µ/3 ‚â§ e‚àí
2n/24.
Since 12
‚àë
i‚ààA xi +
1
2
‚àë
i‚ààB xi =
1
2
‚àën
i=1 xi = ¬µ, we get
Pr[
‚àë
i‚ààA
xi ‚àí
‚àë
i‚ààB
xi >
1
2
n] = Pr[
‚àë
i‚ààA
xi ‚àí ¬µ >
1
4
n] < e‚àí
2n/24.
By symmetry,
Pr[|
‚àë
i‚ààB
xi ‚àí
‚àë
j‚ààA
xj | >
1
2
n] < 2e‚àí
2n/24.
We emphasize that this holds for a fixed query x.
Recall that we assumed the algorithm to be deterministic. Hence, as long as its queries satisfy the
property above, the answers will be fÃÉ(x) = 1/2, and the algorithm will follow the same path of
computation, no matter what the choice of (A,B) is. (Effectively we will not learn anything about
A and B.) Considering the sequence of queries on this computation path, if the number of queries is
t then with probability at least 1‚àí2te‚àí2n/24 the queries will indeed fall in the region where fÃÉ(x) =
1/2 and the algorithm will follow this path. If t ‚â§ e2n/48, this happens with probability at least
1 ‚àí 2e‚àí2n/48. In this case, all the points queried by the algorithm as well as the returned solution
xout (by the same argument) satisfies fÃÉ(xout) = 1/2, and hence f(xout) ‚â• 1‚àí2 . In contrast, the
actual optimum is f(1B) = 0. Recall that  = n‚àí(1‚àíŒ¥)/2; hence, f(xout) ‚â• 12 (1 ‚àí n
‚àí(1‚àíŒ¥)/2)
and the bounds on the number of queries and probability of success are as in the statement of the
theorem.
Finally, consider a randomized algorithm. Denote by (R1, R2, . . . , ...) the random variables used
by the algorithm in its decisions. We can condition on a fixed choice of (R1 = r1, R2 = r2, . . .)
which makes the algorithm deterministic. By our proof, the algorithm conditioned on this choice
cannot succeed with probability more than e‚àí‚Ñ¶(n
Œ¥). Since this is true for each particular choice of
(r1, r2, . . .), by averaging it is also true for a random choice of (R1, R2, . . .). Hence, we obtain the
same result for randomized algorithms as well.
3.2 Concave maximization
Here we consider the problem of maximizing a concave function f : [0, 1]n ‚Üí [0, 1]. One can
obtain a result for concave maximization analogous to Theorem 3.1, which we do not state; in
terms of additive errors, there is really no difference between convex minimization and concave
maximization. However, in the case of concave maximization we can also formulate the following
hardness result for multiplicative approximation.
Theorem 3.2. If a concave function f : [0, 1]n ‚Üí [0, 1] is accessible through a relative-Œ¥-erroneous
oracle, then for any  ‚àà [0, Œ¥], an algorithm that makes less than e2n/48 queries cannot find a
solution of value greater than 1+2 OPT with probability more than 2e
‚àí2n/48.
Proof. This result follows from the same construction as Theorem 3.1. Recall that f(x) is a linear
function, hence also concave. As we mentioned in the proof of Theorem 3.1, fÃÉ(x) could be the
values returned by a relative -erroneous oracle. Now we consider an arbitrary  > 0; note that for
Œ¥ ‚â•  it still holds that fÃÉ(x) is a relative Œ¥-erroneous oracle.
By the same proof, an algorithm querying less than e
nn/48 points cannot find a solution of value
better than 1+2 with probability more than 2e
‚àí2n/48. In contrast, the optimum of the maximization
problem is supx‚àà[0,1]n f(x) = 1. Therefore, the algorithm cannot achieve multiplicative approxi-
mation better than 1+2 .
We note that this hardness result is optimal due to the following easy observation.
5
Theorem 3.3. For any concave function f : [0, 1]n ‚Üí R+, let OPT = supx‚àà[0,1]n f(x). Then
f
(
1
2
,
1
2
, . . . ,
1
2
)
‚â• 1
2
OPT.
Proof. By compactness, the optimum is attained at a point: let OPT = f(x‚àó). Let also x‚Ä≤ =
(1, 1, . . . , 1)‚àí x‚àó. We have x‚Ä≤ ‚àà [0, 1]n and hence f(x‚Ä≤) ‚â• 0. By concavity, we obtain
f
(
1
2
,
1
2
, . . . ,
1
2
)
= f
(
x‚àó + x‚Ä≤
2
)
‚â• f(x
‚àó) + f(x‚Ä≤)
2
‚â• 1
2
f(x‚àó) =
1
2
OPT.
In other words, a multiplicative 12 -approximation for this problem is trivial to obtain ‚Äî even without
asking any queries about f . We just return the point ( 12 ,
1
2 , . . . ,
1
2 ). Thus we can conclude that for
concave maximization, a relative -erroneous oracle is not useful at all.
4 Optimization over polytopes
In this section we consider optimization of convex and concave functions over a polytope
P = {x ‚â• 0 : Ax = b}. We will show inappoximability results for the relative error model. Note
that for the absolute error case, the lower bound on convex minimization from the previous section
holds, and can be applied to show a lower bound for concave maximization with absolute errors.
Theorem 4.1. Let , Œ¥ ‚àà (0, 1/2) be some constants. There are convex functions for which no
algorithm can obtain a finite approximation ratio to minx‚ààP f(x) using ‚Ñ¶(en
Œ¥
) queries to a relative
-erroneous oracle of the function.
Proof. We will prove our theorem for the case in which P = {x ‚â• 0 :
‚àë
i xi ‚â§ n1/2+Œ¥}. Let
H be a subset of indices chosen uniformly at random from all subsets of size exactly n1/2+Œ¥ . We
construct two functions:
f(x) = n1+Œ¥ ‚àí n1/2
‚àë
i‚ààH
xi
g(x) = n1+Œ¥ ‚àí nŒ¥
‚àë
i
xi
Observe that both these functions are convex and non-negative. Also, observe that the minimizer
of f is x‚àó = 1H and f(x‚àó) = 0, while the minimizer of g is any vector x‚Ä≤ :
‚àë
i xi = n
1/2+Œ¥
and g(x‚Ä≤) = n1+Œ¥ ‚àí n1/2+2Œ¥ = Œò(n1+Œ¥). Therefore, the ratio between these two functions is
unbounded. We will now construct the erroneous oracle in the following manner:
fÃÉ(x) =
{
g(x), if (1‚àí )f(x) ‚â§ g(x) ‚â§ (1 + )f(x)
f(x) otherwise
By definition, fÃÉ is an -erroneous oracle to f . The claim will follow from the fact that given access
to fÃÉ one cannot distinguish between f and g using a subexponential number of queries. This implies
the inapproximability result since an approximation algorithm which guarantees a finite approxima-
tion ratio using a subexponential number of queries could be used to distinguish between the two
functions: if the algorithm returns an answer strictly greater than 0 then we know the underlying
function is g and otherwise it is f.
Given a query x ‚àà [0, 1]n to the oracle, we will consider two cases.
‚Ä¢ In case the query x is such that
‚àë
i xi ‚â§ n1/2 then we have that:
n1+Œ¥ ‚àí n ‚â§ f(x) ‚â§ n1+Œ¥
n1+Œ¥ ‚àí nŒ¥+1/2 ‚â§ g(x) ‚â§ n1+Œ¥
6
Since for any , Œ¥ > 0 there is a large enough n s.t. nŒ¥ > (1 + )/, this implies that for
any query for which
‚àë
i xi ‚â§ n1/2 then we have that g(x) ‚àà [(1 ‚àí )f(x), (1 + )f(x)]
and thus the oracle returns g(x).
‚Ä¢ In case the query is such that
‚àë
i xi > n
1/2 then we can interpret the value of‚àë
i‚ààH xi which determines value of f as a sum of negatively associated random variables
X1, . . . , Xn where Xi realizes with probability n‚àí1/2+Œ¥ and takes value xi if realized
(see Claim 2.3). We can then apply the Chernoff bound (Claim 2.2), using the fact that
E[f(x)] = n1/2‚àíŒ¥
‚àë
i xi, and get that for any constant 0 < Œ≤ < 1 we have that with
probability 1‚àí e‚àí‚Ñ¶(nŒ¥):(
1‚àí Œ≤
) ‚àë
i xi
n1/2‚àíŒ¥
‚â§
‚àë
i‚ààH
xi ‚â§
(
1 + Œ≤
) ‚àë
i xi
n1/2‚àíŒ¥
By using Œ≤ ‚â§ /(1 + ), this implies that with probability at least 1‚àí e‚àí‚Ñ¶(nŒ¥) we get that:
(1‚àí )f(x) ‚â§ g(x) ‚â§ (1 + )f(x)
Since the likelihood of distinguishing between f and g on a single query is exponentially
small in nŒ¥ , the same arguments used throughout the paper imply that it takes an exponen-
tial number of queries to distinguish between f and g.
To conclude, for any query x ‚àà [0, 1]n it takes ‚Ñ¶(enŒ¥) queries to distinguish between f and g.
As discussed above, due to the fact that the ratio between the optima of these two functions is
unbounded, this concludes the proof.
Theorem 4.2. ‚àÄ constants , Œ¥ ‚àà (0, 1/2) there is a concave function f : [0, 1]n ‚Üí R+ for which
no algorithm can obtain an approximation strictly better than O(n‚àí1/2+Œ¥) to maxx‚ààP f(x) using
‚Ñ¶(en
Œ¥
) queries to a relative -erroneous oracle of the function.
Proof. We follow a similar methodology as in the proof of Theorem 4.1. We again we select a
set H of size n1/2+Œ¥ u.a.r. and construct two functions: f(x) = n1/2
‚àë
i‚ààH xi +
n1/2+Œ¥
 and
g(x) = nŒ¥
‚àë
i xi +
n1/2+Œ¥
 . As in the proof of Theorem 4.1 the noisy oracle fÃÉ(x) = g(x) when
(1‚àí)f(x) ‚â§ g(x) ‚â§ (1+)f(x) and otherwise fÃÉ(x) = f(x). Note that both functions are concave
and non-negative, and by its definition the oracle is -erroneous for the function f . For b = n1/2+Œ¥
it is easy to see that the optimal value when the objective is f is n1+Œ¥ while the optimal value is
O(n1/2+Œ¥) when the objective is g, which implies that one cannot obtain an approximation better
than ‚Ñ¶(n‚àí1/2+Œ¥) with a subexponential number of queries. In case the query to the oracle is a point
x s.t.
‚àë
i xi ‚â§ n1/2, then by Chernoff bound arguments, similar to the ones we used above, with
probability at least 1‚àí e‚àí‚Ñ¶(nŒ¥) we get (1‚àí )f(x) ‚â§ g(x) ‚â§ (1 + )f(x). Thus, for any query in
which
‚àë
i xi ‚â§ n1/2, the likelihood of the oracle returning f is exponentially small in nŒ¥ .
In case the query is a point x s.t.
‚àë
i xi > n
1/2 standard concentration bound arguments as before,
imply that with probability at least 1‚àí e‚àí‚Ñ¶(nŒ¥) we get (1 ‚àí )f(x) ‚â§ g(x) ‚â§ (1 + )f(x). Since
the likelihood of distinguishing between f and g on a single query is exponentially small in nŒ¥ , we
can conclude that it takes an exponential number of queries to distinguish between f and g.
5 Optimization over assignments
In this section, we consider the concave maximization problem over a more specific polytope,
Pn,k =
Ô£±Ô£≤Ô£≥x ‚àà Rn√ók+ :
k‚àë
j=1
xij = 1 ‚àÄi ‚àà [n]
Ô£ºÔ£ΩÔ£æ .
This can be viewed as the matroid polytope for a partition matroid on n blocks of k elements, or
alternatively the convex hull of assignments of n items to k agents. In this case, there is a trivial
1
k -approximation, similar to the
1
2 -approximation in the case of a unit cube.
7
Theorem 5.1. For any k ‚â• 2 and a concave function f : Pn,k ‚Üí R+, let OPT = supx‚ààPn,k f(x).
Then
f
(
1
k
,
1
k
, . . . ,
1
k
)
‚â• 1
k
OPT.
Proof. By compactness, the optimum is attained at a point: let OPT = f(x‚àó). Let x(`)ij =
x‚àói,(j+` mod k) ; i.e., x
(`) is a cyclic shift of the coordinates of x‚àó by ` in each block. We have
x(`) ‚àà Pn,k and 1k
‚àëk‚àí1
`=0 x
(`)
ij =
1
k
‚àëk
j=1 x
‚àó
ij =
1
k . By concavity and nonnegativity of f , we obtain
f
(
1
k
,
1
k
, . . . ,
1
k
)
= f
(
1
k
k‚àí1‚àë
`=0
x(`)
)
‚â• 1
k
f(x(0)) =
1
k
OPT.
We show that this approximation is best possible, if we have access only to a Œ¥-erroneous oracle.
Theorem 5.2. If k ‚â• 2 and a concave function f : Pn,k ‚Üí [0, 1] is accessible through a relative-Œ¥-
erroneous oracle, then for any  ‚àà [0, Œ¥], an algorithm that makes less than e2n/6k queries cannot
find a solution of value greater than 1+k OPT with probability more than 2e
‚àí2n/6k.
Note that this result is nontrivial only for n  k. In other words, the hardness factor of k is never
worse than a square root of the dimension of the problem. Therefore, this result can be viewed as
interpolating between the hardness of 1+2 -approximation over the unit cube (Theorem 3.2), and the
hardness of nŒ¥‚àí1/2-approximation over a general polytope (Theorem 4.2).
Proof. Given œÄ : [n] ‚Üí [k], we construct a function fœÄ : Pn,k ‚Üí [0, 1] (where œÄ describes the
intended optimal solution):
‚Ä¢ fœÄ(x) = 1n
‚àën
i=1 xi,œÄ(i).
Next we define a modified function fÃÉœÄ as follows:
‚Ä¢ If |fœÄ(x)‚àí 1k | >

k then fÃÉ
œÄ(x) = fœÄ(x)
‚Ä¢ If |fœÄ(x)‚àí 1k | ‚â§

k then fÃÉ
œÄ(x) = 1k .
By definition, fœÄ(x) and fÃÉœÄ(x) differ only if |fœÄ(x)‚àí 1k | ‚â§

k , and then f
œÄ(x) ‚àà [ 1‚àík ,
1+
k ] while
fÃÉœÄ(x) = 1k . Therefore, fÃÉ
œÄ(x) is a valid relative -erroneous oracle for fœÄ .
Similarly to the proofs above, we argue that if œÄ is chosen uniformly at random, then with high
probability fÃÉœÄ(x) = 1k for any fixed query x ‚àà Pn,k. This holds again by a Chernoff bound: For a
fixed xij such that
‚àëk
j=1 xij = 1, we have that f
œÄ(x) = 1n
‚àën
i=1 xi,œÄ(i) =
1
nZ where Z is a sum of
independent random variables with expectation 1k
‚àë
i,j xij =
n
k . The random variables attain values
in [0, 1]. By the Chernoff bound, Pr[|Z ‚àí nk | > 
n
k ] < 2e
‚àí2n/3k. This gives
Pr
[
|fœÄ(x)‚àí 1
k
| > 
k
]
< 2e‚àí
2n/3k.
By the same arguments as before, if the algorithm asks less than e
2n/6k queries, then it will not
detect a point such that |fœÄ(x)‚àí 1k | >

k with probability more than 2e
‚àí2n/6k. Then the query an-
swers will all be fÃÉœÄ(x) = 1k and the value of the returned solution will be at most
1+
k . Meanwhile,
the optimum solution is x‚àói,œÄ(i) = 1 for all i, which gives f(x
‚àó) = 1.
Acknowledgements. YS was supported by NSF grant CCF-1301976, CAREER CCF-1452961 and a Google
Faculty Research Award.
8
References
[1] Alekh Agarwal, Ofer Dekel, and Lin Xiao. Optimal algorithms for online convex optimization with
multi-point bandit feedback. In COLT 2010 - The 23rd Conference on Learning Theory, Haifa, Israel,
June 27-29, 2010, pages 28‚Äì40, 2010.
[2] Alekh Agarwal, Dean P. Foster, Daniel Hsu, Sham M. Kakade, and Alexander Rakhlin. Stochastic convex
optimization with bandit feedback. SIAM Journal on Optimization, 23(1):213‚Äì240, 2013.
[3] Alexandre Belloni, Tengyuan Liang, Hariharan Narayanan, and Alexander Rakhlin. Escaping the local
minima via simulated annealing: Optimization of approximately convex functions. COLT 2015.
[4] SeÃÅbastien Bubeck and NicoloÃÄ Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed
bandit problems. Foundations and Trends in Machine Learning, 5(1):1‚Äì122, 2012.
[5] Devdatt Dubhashi, Volker Priebe, and Desh Ranjan. Negative dependence through the FKG inequality.
In Research report MPI-I-96-1-020, Max-Planck Institut fuÃàr Informatik, SaarbruÃàcken, 1996.
[6] John C. Duchi, Michael I. Jordan, Martin J. Wainwright, and Andre Wibisono. Optimal rates for zero-
order convex optimization: The power of two function evaluations. IEEE Transactions on Information
Theory, 61(5):2788‚Äì2806, 2015.
[7] Uriel Feige, Vahab S. Mirrokni, and Jan VondraÃÅk. Maximizing non-monotone submodular functions.
SIAM J. Comput., 40(4):1133‚Äì1153, 2011.
[8] Abraham Flaxman, Adam Tauman Kalai, and H. Brendan McMahan. Online convex optimization in the
bandit setting: gradient descent without a gradient. In Proceedings of the Sixteenth Annual ACM-SIAM
Symposium on Discrete Algorithms, SODA 2005, Vancouver, British Columbia, Canada, January 23-25,
2005, pages 385‚Äì394, 2005.
[9] Kevin G. Jamieson, Robert D. Nowak, and Benjamin Recht. Query complexity of derivative-free opti-
mization. In Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural
Information Processing Systems 2012. Proceedings of a meeting held December 3-6, 2012, Lake Tahoe,
Nevada, United States., pages 2681‚Äì2689, 2012.
[10] A.S. Nemirovsky and D.B. Yudin. Problem Complexity and Method Efficiency in Optimization. J. Wiley
& Sons, New York, 1983.
[11] Yurii Nesterov. Random gradient-free minimization of convex functions. CORE Discussion Papers
2011001, UniversiteÃÅ catholique de Louvain, Center for Operations Research and Econometrics (CORE),
2011.
[12] Aaditya Ramdas, BarnabaÃÅs PoÃÅczos, Aarti Singh, and Larry A. Wasserman. An analysis of active learning
with uniform feature noise. In Proceedings of the Seventeenth International Conference on Artificial
Intelligence and Statistics, AISTATS 2014, Reykjavik, Iceland, April 22-25, 2014, pages 805‚Äì813, 2014.
[13] Aaditya Ramdas and Aarti Singh. Optimal rates for stochastic convex optimization under tsybakov noise
condition. In Proceedings of the 30th International Conference on Machine Learning, ICML 2013, At-
lanta, GA, USA, 16-21 June 2013, pages 365‚Äì373, 2013.
[14] Ohad Shamir. On the complexity of bandit and derivative-free stochastic convex optimization. In COLT
2013 - The 26th Annual Conference on Learning Theory, June 12-14, 2013, Princeton University, NJ,
USA, pages 3‚Äì24, 2013.
[15] Sebastian U. Stich, Christian L. MuÃàller, and Bernd GaÃàrtner. Optimization of convex functions with random
pursuit. CoRR, abs/1111.0194, 2011.
[16] Jan VondraÃÅk. Symmetry and approximability of submodular maximization problems. SIAM J. Comput.,
42(1):265‚Äì304, 2013.
9
