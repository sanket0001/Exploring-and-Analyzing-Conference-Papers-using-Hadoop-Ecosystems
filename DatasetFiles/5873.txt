


Paper ID = 5873
Title = A Framework for Individualizing Predictions of Disease
Trajectories by Exploiting Multi-Resolution Structure
Peter Schulam
Dept. of Computer Science
Johns Hopkins University
Baltimore, MD 21218
pschulam@jhu.edu
Suchi Saria
Dept. of Computer Science
Johns Hopkins University
Baltimore, MD 21218
ssaria@cs.jhu.edu
Abstract
For many complex diseases, there is a wide variety of ways in which an indi-
vidual can manifest the disease. The challenge of personalized medicine is to
develop tools that can accurately predict the trajectory of an individual’s disease,
which can in turn enable clinicians to optimize treatments. We represent an in-
dividual’s disease trajectory as a continuous-valued continuous-time function de-
scribing the severity of the disease over time. We propose a hierarchical latent
variable model that individualizes predictions of disease trajectories. This model
shares statistical strength across observations at different resolutions–the popula-
tion, subpopulation and the individual level. We describe an algorithm for learning
population and subpopulation parameters offline, and an online procedure for dy-
namically learning individual-specific parameters. Finally, we validate our model
on the task of predicting the course of interstitial lung disease, a leading cause
of death among patients with the autoimmune disease scleroderma. We compare
our approach against state-of-the-art and demonstrate significant improvements in
predictive accuracy.
1 Introduction
In complex, chronic diseases such as autism, lupus, and Parkinson’s, the way the disease manifests
may vary greatly across individuals [1]. For example, in scleroderma, the disease we use as a running
example in this work, individuals may be affected across six organ systems—the lungs, heart, skin,
gastrointestinal tract, kidneys, and vasculature—to varying extents [2]. For any single organ system,
some individuals may show rapid decline throughout the course of their disease, while others may
show early decline but stabilize later on. Often in such diseases, the most effective drugs have
strong side-effects. With tools that can accurately predict an individual’s disease activity trajectory,
clinicians can more aggressively treat those at greatest risk early, rather than waiting until the disease
progresses to a high level of severity. To monitor the disease, physicians use clinical markers to
quantify severity. In scleroderma, for example, PFVC is a clinical marker used to measure lung
severity. The task of individualized prediction of disease activity trajectories is that of using an
individual’s clinical history to predict the future course of a clinical marker; in other words, the goal
is to predict a function representing a trajectory that is updated dynamically using an individual’s
previous markers and individual characteristics.
Predicting disease activity trajectories presents a number of challenges. First, there are multiple la-
tent factors that cause heterogeneity across individuals. One such factor is the underlying biological
mechanism driving the disease. For example, two different genetic mutations may trigger distinct
disease trajectories (e.g. as in Figures 1a and 1b). If we could divide individuals into groups accord-
ing to their mechanisms—or disease subtypes (see e.g. [3, 4, 5, 6])—it would be straightforward
to fit separate models to each subpopulation. In most complex diseases, however, the mechanisms
are poorly understood and clear definitions of subtypes do not exist. If subtype alone determined
trajectory, then we could cluster individuals. However, other unobserved individual-specific factors
1
such as behavior and prior exposures affect health and can cause different trajectories across indi-
viduals of the same subtype. For instance, a chronic smoker will typically have unhealthy lungs and
so may have a trajectory that is consistently lower than a non-smoker’s, which we must account for
using individual-specific parameters. An individual’s trajectory may also be influenced by transient
factors—e.g. an infection unrelated to the disease that makes it difficult to breath (similar to the
“dips” in Figure 1c or the third row in Figure 1d). This can cause marker values to temporarily drop,
and may be hard to distinguish from disease activity. We show that these factors can be arranged in
a hierarchy (population, subpopulation, and individual), but that not all levels of the hierarchy are
observed. Finally, the functional outcome is a rich target, and therefore more challenging to model
than scalar outcomes. In addition, the marker data is observed in continuous-time and is irregularly
sampled, making commonly used discrete-time approaches to time series modeling (or approaches
that rely on imputation) not well suited to this domain.
Related work. The majority of predictive models in medicine explain variability in the target out-
come by conditioning on observed risk factors alone. However, these do not account for latent
sources of variability such as those discussed above. Further, these models are typically cross-
sectional—they use features from data measured up until the current time to predict a clinical marker
or outcome at a fixed point in the future. As an example, consider the mortality prediction model by
Lee et al. [7], where logistic regression is used to integrate features into a prediction about the prob-
ability of death within 30 days for a given patient. To predict the outcome at multiple time points,
typically separate models are trained. Moreover, these models use data from a fixed-size window,
rather than a growing history.
Researchers in the statistics and machine learning communities have proposed solutions that ad-
dress a number of these limitations. Most related to our work is that by Rizopoulos [8], where the
focus is on making dynamical predictions about a time-to-event outcome (e.g. time until death).
Their model updates predictions over time using all previously observed values of a longitudinally
recorded marker. Besides conditioning on observed factors, they account for latent heterogeneity
across individuals by allowing for individual-specific adjustments to the population-level model—
e.g. for a longitudinal marker, deviations from the population baseline are modeled using random
effects by sampling individual-specific intercepts from a common distribution. Other closely related
work by Proust-Lima et al. [9] tackle a similar problem as Rizopoulos, but address heterogeneity
using a mixture model.
Another common approach to dynamical predictions is to use Markov models such as order-p
autoregressive models (AR-p), HMMs, state space models, and dynamic Bayesian networks
(see e.g. in [10]). Although such models naturally make dynamic predictions using the full history
by forward-filtering, they typically assume discrete, regularly-spaced observation times. Gaussian
processes (GPs) are a commonly used alternative for handling continuous-time observations—see
Roberts et al. [11] for a recent review of GP time series models. Since Gaussian processes are non-
parametric generative models of functions, they naturally produce functional predictions dynami-
cally by using the posterior predictive conditioned on the observed data. Mixtures of GPs have been
applied to model heterogeneity in the covariance structure across time series (e.g. [12]), however as
noted in Roberts et al., appropriate mean functions are critical for accurate forecasts using GPs. In
our work, an individual’s trajectory is expressed as a GP with a highly structured mean comprising
population, subpopulation and individual-level components where some components are observed
and others require inference.
More broadly, multi-level models have been applied in many fields to model heterogeneous collec-
tions of units that are organized within a hierarchy [13]. For example, in predicting student grades
over time, individuals within a school may have parameters sampled from the school-level model,
and the school-level model parameters in turn may be sampled from a county-specific model. In our
setting, the hierarchical structure—which individuals belong to the same subgroup—is not known a
priori. Similar ideas are studied in multi-task learning, where relationships between distinct predic-
tion tasks are used to encourage similar parameters. This has been applied to modeling trajectories
by treating predictions at each time point as a separate task and enforcing similarity between sub-
models close in time [14]. This approach is limited, however, in that it models a finite number
of times. Others, more recently, have developed models for disease trajectories (see [15, 16] and
references within) but these focus on retrospective analysis to discover disease etiology rather than
dynamical prediction. Schulam et al. [16] incorporate differences in trajectories due to subtypes and
individual-specific factors. We build upon this work here. Finally, recommender systems also share
2
Subtype marginal model 
coefficients
zi
fi
M
↵
yij tij
Ni
~ g G
~bi
⌃b
~⇢i
Population model 
featuresPopulation model coefficients 
Population model features-to-coefficient map
Subtype B-spline coefficients
Subtype indicator 2 {1, . . . , G}
Individual model covariance matrix2 Rd`⇥d`
Individual model coefficients2 Rd`
Structured noise GP 
hyper-parameters
Structured noise function 2 RR
~xiz
Subtype marginal 
model features
~wg
2 Rqz
2 Rqz
2 Rdz
2 Rqp2 Rdp
2 Rdp⇥qp
~xip
⇤
(d)
(a)
(b)
(c)
(e)
Figure 1: Plots (a-c) show example marker trajectories. Plot (d) shows adjustments to a population and
subpopulation fit (row 1). Row 2 makes an individual-specific long-term adjustment. Row 3 makes short-
term structured noise adjustments. Plot (e) shows the proposed graphical model. Levels in the hierarchy are
color-coded. Model parameters are enclosed in dashed circles. Observed random variables are shaded.
information across individuals with the aim of tailoring predictions (see e.g. [17, 18, 19]), but the
task is otherwise distinct from ours.
Contributions. We propose a hierarchical model of disease activity trajectories that directly ad-
dresses common—latent and observed—sources of heterogeneity in complex, chronic diseases us-
ing three levels: the population level, subpopulation level, and individual level. The model discovers
the subpopulation structure automatically, and infers individual-level structure over time when mak-
ing predictions. In addition, we include a Gaussian process as a model of structured noise, which
is designed to explain away temporary sources of variability that are unrelated to disease activity.
Together, these four components allow individual trajectories to be highly heterogeneous while si-
multaneously sharing statistical strength across observations at different “resolutions” of the data.
When making predictions for a given individual, we use Bayesian inference to dynamically update
our posterior belief over individual-specific parameters given the clinical history and use the poste-
rior predictive to produce a trajectory estimate. Finally, we evaluate our approach by developing a
state-of-the-art trajectory prediction tool for lung disease in scleroderma. We train our model using
a large, national dataset containing individuals with scleroderma tracked over 20 years and compare
our predictions against alternative approaches. We find that our approach yields significant gains in
predictive accuracy of disease activity trajectories.
2 Disease Trajectory Model
We describe a hierarchical model of an individual’s clinical marker values. The graphical model
is shown in Figure 1e. For each individual i, we use Ni to denote the number of observed mark-
ers. We denote each individual observation using yij and its measurement time using tij where
j ∈ {1, . . . , Ni}. We use ~yi ∈ RNi and ~ti ∈ RNi to denote all of individual i’s marker values and
measurement times respectively. In the following discussion, Φ(tij) denotes a column-vector con-
taining a basis expansion of the time tij and we use Φ
(
~ti
)
= [Φ(ti1), . . . ,Φ(tiNi)]
> to denote the
matrix containing the basis expansion of points in ~ti in each of its rows. We model the jth marker
value for individual i as a normally distributed random variable with a mean assumed to be the sum
of four terms: a population component, a subpopulation component, an individual component, and
a structured noise component:
yij ∼ N
Φp(tij)>Λ ~xip︸ ︷︷ ︸
(A) population
+ Φz(tij)
>~βzi︸ ︷︷ ︸
(B) subpopulation
+ Φ`(tij)
>~bi︸ ︷︷ ︸
(C) individual
+ fi(tij)︸ ︷︷ ︸
(D) structured noise
, σ2
 . (1)
The four terms in the sum serve two purposes. First, they allow for a number of different sources
of variation to influence the observed marker value, which allows for heterogeneity both across and
within individuals. Second, they share statistical strength across different subsets of observations.
The population component shares strength across all observations. The subpopulation component
3
shares strength across observations belonging to subgroups of individuals. The individual compo-
nent shares strength across all observations belonging to the same individual. Finally, the structured
noise shares information across observations belonging to the same individual that are measured at
similar times. Predicting an individual’s trajectory involves estimating her subtype and individual-
specific parameters as new clinical data becomes available1. We describe each of the components in
detail below.
Population level. The population model predicts aspects of an individual’s disease activity trajec-
tory using observed baseline characteristics (e.g. gender and race), which are represented using the
feature vector ~xip. This sub-model is shown within the orange box in Figure 1e. Here we assume
that this component is a linear model where the coefficients are a function of the features ~xip ∈ Rqp .
The predicted value of the jth marker of individual i measured at time tij is shown in Eq. 1 (A),
where Φp (t) ∈ Rdp is a basis expansion of the observation time and Λ ∈ Rdp×qp is a matrix used as
a linear map from an individual’s covariates ~xip to coefficients ρi ∈ Rdp . At this level, individuals
with similar covariates will have similar coefficients. The matrix Λ is learned offline.
Subpopulation level. We model an individual’s subtype using a discrete-valued latent variable
zi ∈ {1, . . . , G}, where G is the number of subtypes. We associate each subtype with a unique
disease activity trajectory represented using B-splines, where the number and location of the knots
and the degree of the polynomial pieces are fixed prior to learning. These hyper-parameters de-
termine a basis expansion Φz(t) ∈ Rdz mapping a time t to the B-spline basis function values at
that time. Trajectories for each subtype are parameterized by a vector of coefficients ~βg ∈ Rdz
for g ∈ {1, . . . , G}, which are learned offline. Under subtype zi, the predicted value of marker
yij measured at time tij is shown in Eq. 1 (B). This component explains differences such as those
observed between the trajectories in Figures 1a and 1b. In many cases, features at baseline may be
predictive of subtype. For example, in scleroderma, the types of antibody an individual produces
(i.e. the presence of certain proteins in the blood) are correlated with certain trajectories. We can
improve predictive performance by conditioning on baseline covariates to infer the subtype. To do
this, we use a multinomial logistic regression to define feature-dependent marginal probabilities:
zi | ~xiz ∼ Mult (π1:G (~xiz)), where πg (~xiz) ∝ e~w
>
g ~xiz . We denote the weights of the multinomial
regression using ~w1:G, where the weights of the first class are constrained to be ~0 to ensure model
identifiability. The remaining weights are learned offline.
Individual level. This level models deviations from the population and subpopulation models us-
ing parameters that are learned dynamically as the individual’s clinical history grows. Here, we
parameterize the individual component using a linear model with basis expansion Φ`(t) ∈ Rd` and
individual-specific coefficients ~bi ∈ Rd` . An individual’s coefficients are modeled as latent vari-
ables with marginal distribution ~bi ∼ N (~0,Σb). For individual i, the predicted value of marker yij
measured at time tij is shown in Eq. 1 (C). This component can explain, for example, differences in
overall health due to an unobserved characteristic such as chronic smoking, which may cause atyp-
ically lower lung function than what is predicted by the population and subpopulation components.
Such an adjustment is illustrated across the first and second rows of Figure 1d.
Structured noise. Finally, the structured noise component fi captures transient trends. For ex-
ample, an infection may cause an individual’s lung function to temporarily appear more restricted
than it actually is, which may cause short-term trends like those shown in Figure 1c and the third
row of Figure 1d. We treat fi as a function-valued latent variable and model it using a Gaus-
sian process with zero-valued mean function and Ornstein-Uhlenbeck (OU) covariance function:
KOU(t1, t2) = a
2 exp
{
−`−1|t1 − t2|
}
. The amplitude a controls the magnitude of the structured
noise that we expect to see and the length-scale ` controls the length of time over which we expect
these temporary trends to occur. The OU kernel is ideal for modeling such deviations as it is both
mean-reverting and draws from the corresponding stochastic process are only first-order continuous,
which eliminates long-range dependencies between deviations [20]. Applications in other domains
may require different kernel structures motivated by properties of the noise in the trajectories.
1The model focuses on predicting the long-term trajectory of an individual when left untreated. In many
chronic conditions, as is the case for scleroderma, drugs only provide short-term relief (accounted for in our
model by the individual-specific adjustments). If treatments that alter long-term course are available and com-
monly prescribed, then these should be included within the model as an additional component that influences
the trajectory.
4
2.1 Learning
Objective function. To learn the parameters of our model Θ = {Λ, ~w1:G, ~β1:G,Σb, a, `, σ2}, we
maximize the observed-data log-likelihood (i.e. the probability of all individual’s marker values ~yi
given measurement times ~ti and features {~xip, ~xiz}). This requires marginalizing over the latent
variables {zi,~bi, fi} for each individual. This yields a mixture of multivariate normals:
P (~yi | Xi,Θ) =
G∑
zi=1
πzi (~xiz)N
(
~yi | Φp
(
~ti
)
Λ ~xip + Φz
(
~ti
)
~βzi ,K
(
~ti,~ti
))
, (2)
where K(t1, t2) = Φ`(t1)>ΣbΦ`(t2) + KOU(t1, t2) + σ2I(t1 = t2). The observed-data
log-likelihood for all individuals is therefore: L (Θ) =
∑M
i=1 logP (~yi | Xi,Θ). A more detailed
derivation is provided in the supplement.
Optimizing the objective. To maximize the observed-data log-likelihood with respect to Θ, we
partition the parameters into two subsets. The first subset, Θ1 = {Σb, α, `, σ2}, contains values that
parameterize the covariance function K(t1, t2) above. As is often done when designing the ker-
nel of a Gaussian process, we use a combination of domain knowledge to choose candidate values
and model selection using observed-data log-likelihood as a criterion for choosing among candi-
dates [20]. The second subset, Θ2 = {Λ, ~w1:G, ~β1:G}, contains values that parameterize the mean
of the multivariate normal distribution in Equation 2. We learn these parameters using expectation
maximization (EM) to find a local maximum of the observed-data log-likelihood.
Expectation step. All parameters related to ~bi and fi are limited to the covariance kernel and are
not optimized using EM. We therefore only need to consider the subtype indicators zi as unob-
served in the expectation step. Because zi is discrete, its posterior is computed by normalizing the
joint probability of zi and ~yi. Let π∗ig denote the posterior probability that individual i has subtype
g ∈ {1, . . . , G}, then we have
π∗ig ∝ πg (~xiz)N
(
~yi | Φp
(
~ti
)
Λ ~xip + Φz
(
~ti
)
~βg,K
(
~ti,~ti
))
. (3)
Maximization step. In the maximization step, we optimize the marginal probability of the soft
assignments under the multinomial logistic regression model with respect to ~w1:G using gradient-
based methods. To optimize the expected complete-data log-likelihood with respect to Λ and ~β1:G,
we note that the mean of the multivariate normal for each individual is a linear function of these
parameters. Holding Λ fixed, we can therefore solve for ~β1:G in closed form and vice versa. We use
a block coordinate ascent approach, alternating between solving for Λ and ~β1:G until convergence.
Because the expected complete-data log-likelihood is concave with respect to all parameters in Θ2,
each maximization step is guaranteed to converge. We provide additional details in the supplement.
2.2 Prediction
Our prediction ŷ(t′i) for the value of the trajectory at time t
′
i is the expectation of the marker y
′
i
under the posterior predictive conditioned on observed markers ~yi measured at times ~ti thus far.
This requires evaluating the following expression:
ŷ (t′i) =
G∑
zi=1
∫
Rd`
∫
RNi
E
[
y′i | zi,~bi, fi, t′i
]
︸ ︷︷ ︸
prediction given latent vars.
P
(
zi,~bi, fi | ~yi, Xi,Θ
)
︸ ︷︷ ︸
posterior over latent vars.
dfi d~bi (4)
= E∗
zi,~bi,fi
[
Φp (t
′
i)
>
Λ ~xip + Φz (t
′
i)
> ~βzi + Φ` (t
′
i)
>~bi + fi (t
′
i)
]
(5)
= Φp (t
′
i)
>
Λ ~xip︸ ︷︷ ︸
population prediction
+ Φz (t
′
i)
>
~β∗i (Eq. 7)︷ ︸︸ ︷
E∗zi
[
~βzi
]
︸ ︷︷ ︸
subpopulation prediction
+ Φ` (t
′
i)
>
~b∗i (Eq. 10)︷ ︸︸ ︷
E∗~bi
[
~bi
]
︸ ︷︷ ︸
individual prediction
+
f∗i (t
′
i) (Eq. 12)︷ ︸︸ ︷
E∗fi [fi (t
′
i)]︸ ︷︷ ︸
structured noise prediction
, (6)
where E∗ denotes an expectation conditioned on ~yi, Xi,Θ. In moving from Eq. 4 to 5, we have
written the integral as an expectation and substituted the inner expectation with the mean of the
normal distribution in Eq. 1. From Eq. 5 to 6, we use linearity of expectation. Eqs. 7, 10, and 12
5
1 2 4
●
●
●●
●
●
●
● ●
●
●
●
● ●● ●
●
●
●●
●
●
●
● ●
●
●
●
● ●● ●
●
●
●●
●
●
●
● ●
●
●
●
● ●● ●
40
60
80
0.0 2.5 5.0 7.5 10.0 0.0 2.5 5.0 7.5 10.0 0.0 2.5 5.0 7.5 10.0
1 2 4
●
●
●
●
● ●
●
●
●●
●
● ●
●
● ●
●
●
●
●
●
● ●
●
●
●●
●
● ●
●
● ●
●
●
●
●
●
● ●
●
●
●●
●
● ●
●
● ●
●
20
40
60
80
100
0.0 2.5 5.0 7.5 10.0 0.0 2.5 5.0 7.5 10.0 0.0 2.5 5.0 7.5 10.0
1 2 4
●
●
●●
●
●
●
● ●
●
●
●
● ●● ●
●
●
●●
●
●
●
● ●
●
●
●
● ●● ●
●
●
●●
●
●
●
● ●
●
●
●
● ●● ●
40
60
80
0.0 2.5 5.0 7.5 10.0 0.0 2.5 5.0 7.5 10.0 0.0 2.5 5.0 7.5 10.0
Pr( ) =
Pr( ) =
0.57 
0.18
Pr( ) =
Pr( ) =
0.71 
0.21
Pr( ) =
Pr( ) =
0.60 
0.39
1 2 4
●
●
●
●
● ●
●
●
●●
●
● ●
●
● ●
●
●
●
●
●
● ●
●
●
●●
●
● ●
●
● ●
●
●
●
●
●
● ●
●
●
●●
●
● ●
●
● ●
●
20
40
60
80
100
0.0 2.5 5.0 7.5 10.0 0.0 2.5 5.0 7.5 10.0 0.0 2.5 5.0 7.5 10.0
Pr( ) =
Pr( ) =
0.53 
0.26
Pr( ) =
Pr( ) =
0.54 
0.46
Pr( ) =
Pr( ) =
0.99 
0.01
Pr( ) =
Pr( ) =
0.56 
0.40
Pr( ) =
Pr( ) =
0.54 
0.46
Years Since First Seen
(a) (b)
(c) (d)
Figure 2: Plots (a) and (c) show dynamic predictions using the proposed model for two individuals. Red
markers are unobserved. Blue shows the trajectory predicted using the most likely subtype, and green shows
the second most likely. Plot (b) shows dynamic predictions using the B-spline GP baseline. Plot (d) shows
predictions made using the proposed model without individual-specific adjustments.
below show how the expectations in Eq. 6 are computed. An expanded version of these steps are
provided in the supplement.
Computing the population prediction is straightforward as all quantities are observed. To compute
the subpopulation prediction, we need to compute the marginal posterior over zi, which we used in
the expectation step above (Eq. 3). The expected subtype coefficients are therefore
~β∗i ,
(∑G
zi=1
π∗izi
~βzi
)
. (7)
To compute the individual prediction, note that by conditioning on zi, the integral over the likelihood
with respect to fi and the prior over~bi form the likelihood and prior of a Bayesian linear regression.
Let Kf = KOU(~ti,~ti) + σ2I , then the posterior over~bi conditioned on zi is:
P
(
~bi | zi, ~yi, Xi,Θ
)
∝ N
(
~bi | 0,Σb
)
N
(
~yi | ΦpΛ ~xip + Φz
(
~ti
)
~βzi + Φ`
(
~ti
)
~bi, Kf
)
. (8)
Just as in Eq. 2, we have integrated over fi moving its effect from the mean of the normal distribution
to the covariance. Because the prior over~bi is conjugate to the likelihood on the right side of Eq. 8,
the posterior can be written in closed form as a normal distribution (see e.g. [10]). The mean of the
left side of Eq. 8 is therefore[
Σ−1b + Φ`(~ti)
>K−1f Φ`(~ti)
]−1 [
Φ`(~ti)
>K−1f
(
~yi − Φp(~ti)Λ ~xip − Φz(~ti)~βzi
)]
, (9)
To compute the unconditional posterior mean of ~bi we take the expectation of Eq. 9 with respect to
the posterior over zi. Eq. 9 is linear in ~βzi , so we can directly replace ~βzi with its mean (Eq. 7):
~b∗i ,
[
Σ−1b + Φ`(~ti)
>K−1f Φ`(~ti)
]−1 [
Φ`(~ti)
>K−1f
(
~yi − Φp(~ti)Λ ~xip − Φz(~ti)~β∗i
)]
. (10)
Finally, to compute the structured noise prediction, note that conditioned on zi and ~bi, the GP prior
and marker likelihood (Eq. 1) form a standard GP regression (see e.g. [20]). The conditional
posterior of fi(t′i) is therefore a GP with mean
KOU(t
′
i,~ti)
[
KOU(~ti,~ti) + σ
2I
]−1 (
~yi − Φp(~ti)Λ ~xip − Φz(~ti)~βzi − Φ`(~ti)~bi
)
. (11)
To compute the unconditional posterior expectation of fi(t′i), we note that the expression above is
linear in zi and~bi and so their expectations can be plugged in to obtain
f∗(t′i) , KOU(t
′
i,~ti)
[
KOU(~ti,~ti) + σ
2I
]−1 (
~yi − Φp(~ti)Λ ~xip − Φz(~ti)~β∗i − Φ`(~ti)~b∗i
)
. (12)
6
3 Experiments
We demonstrate our approach by building a tool to predict the lung disease trajectories of individ-
uals with scleroderma. Lung disease is currently the leading cause of death among scleroderma
patients, and is notoriously difficult to treat because there are few predictors of decline and there is
tremendous variability across individual trajectories [21]. Clinicians track lung severity using per-
cent of predicted forced vital capacity (PFVC), which is expected to drop as the disease progresses.
In addition, demographic variables and molecular test results are often available at baseline to aid
prognoses. We train and validate our model using data from the Johns Hopkins Scleroderma Center
patient registry, which is one of the largest in the world. To select individuals from the registry, we
used the following criteria. First, we include individuals who were seen at the clinic within two
years of their earliest scleroderma-related symptom. Second, we exclude all individuals with fewer
than two PFVC measurements after their first visit. Finally, we exclude individuals who received a
lung transplant. The dataset contains 672 individuals and a total of 4, 992 PFVC measurements.
For the population model, we use constant functions (i.e. observed covariates adjust an individual’s
intercept). The population covariates (~xip) are gender, African American race, and indicators of
ACA and Scl-70 antibodies—two proteins believed to be connected to scleroderma-related lung
disease. Note that all features are binary. For the subpopulation B-splines, we set boundary knots
at 0 and 25 years (the maximum observation time in our data set is 23 years), use two interior knots
that divide the time period from 0-25 years into three equally spaced chunks, and use quadratics
as the piecewise components. These B-spline hyperparameters (knots and polynomial degree) are
also used for all baseline models. We select G = 9 subtypes using BIC. The covariates in the
subtype marginal model (~xiz) are the same used in the population model. For the individual model,
we use linear functions. For the hyper-parameters Θ1 = {Σb, α, `, σ2} we set Σb to be a diagonal
covariance matrix with entries [16, 10−2] along the diagonal, which correspond to intercept and
slope variances respectively. Finally, we set α = 6, ` = 2, and σ2 = 1 using domain knowledge;
we expect transient deviations to last around 2 years and to change PFVC by around ±6 units.
Baselines. First, to compare against typical approaches used in clinical medicine that condition on
baseline covariates only (e.g. [22]), we fit a regression model conditioned on all covariates included
in ~xiz above. The mean is parameterized using B-spline bases (Φ(t)) as:
ŷ | ~xiz = Φ(t)>
(
~β0 +
∑
xi in ~xiz xi
~βi +
∑
xi,xj in pairs of ~xiz xixj
~βij
)
. (13)
The second baseline is similar to [8] and [23] and extends the first baseline by accounting for
individual-specific heterogeneity. The model has a mean function identical to the first baseline and
individualizes predictions using a GP with the same kernel as in Equation 2 (using hyper-parameters
as above). Another natural approach is to explain heterogeneity by using a mixture model similar to
[9]. However, a mixture model cannot adequately explain away individual-specific sources of vari-
ability that are unrelated to subtype and therefore fails to recover subtypes that capture canonical
trajectories (we discuss this in detail in the supplemental section). The recovered subtypes from the
full model do not suffer from this issue. To make the comparison fair and to understand the extent
to which the individual-specific component contributes towards personalizing predictions, we create
a mixture model (Proposed w/ no personalization) where the subtypes are fixed to be the same as
those in the full model and the remaining parameters are learned. Note that this version does not
contain the individual-specific component.
Evaluation. We make predictions after one, two, and four years of follow-up. Errors are summa-
rized within four disjoint time periods: (1, 2], (2, 4], (4, 8], and (8, 25] years2. To measure error,
we use the absolute difference between the prediction and a smoothed version of the individual’s
observed trajectory. We estimate mean absolute error (MAE) using 10-fold CV at the level of indi-
viduals (i.e. all of an individual’s data is held-out), and test for statistically significant reductions in
error using a one-sided, paired t-test. For all models, we use the MAP estimate of the individual’s
trajectory. In the models that include subtypes, this means that we choose the trajectory predicted by
the most likely subtype under the posterior. Although this discards information from the posterior,
in our experience clinicians find this choice to be more interpretable.
Qualitative results. In Figure 2 we present dynamically updated predictions for two patients (one
per row, dynamic updates move left to right). Blue lines indicate the prediction under the most likely
subtype and green lines indicate the prediction under the second most likely. The first individual
2After the eighth year, data becomes too sparse to further divide this time span.
7
Predictions using 1 year of data
Model (1, 2] % Im. (2, 4] % Im. (4, 8] % Im. (8, 25] % Im.
B-spline with Baseline Feats. 12.78 12.73 12.40 12.14
B-spline + GP 5.49 7.70 9.67 10.71
Proposed 5.26 ∗7.04 8.6 10.17 12.12
Proposed w/ no personalization 6.17 7.12 9.38 12.85
Predictions using 2 years of data
B-spline with Baseline Feats. 12.73 12.40 12.14
B-spline + GP 5.88 8.65 10.02
Proposed ∗5.48 6.8 ∗7.95 8.1 9.53
Proposed w/ no personalization 6.00 8.12 11.39
Predictions using 4 years of data
B-spline with Baseline Feats. 12.40 12.14
B-spline + GP 6.00 8.88
Proposed ∗5.14 14.3 ∗7.58 14.3
Proposed w/ no personalization 5.75 9.16
Table 1: MAE of PFVC predictions for the two baselines and the proposed model. Bold numbers indicate best
performance across models (∗ is stat. significant). “% Im.” reports percent improvement over next best.
(Figure 2a) is a 50-year-old, white woman with Scl-70 antibodies, which are thought to be associated
with active lung disease. Within the first year, her disease seems stable, and the model predicts this
course with 57% confidence. After another year of data, the model shifts 21% of its belief to a
rapidly declining trajectory; likely in part due to the sudden dip in year 2. We contrast this with the
behavior of the B-spline GP shown in Figure 2b, which has limited capacity to express individualized
long-term behavior. We see that the model does not adequately adjust in light of the downward trend
between years one and two. To illustrate the value of including individual-specific adjustments, we
now turn to Figures 2c and 2d (which plot predictions made by the proposed model with and without
personalization respectively). This individual is a 60-year-old, white man that is Scl-70 negative,
which makes declining lung function less likely. Both models use the same set of subtypes, but
whereas the model without individual-specific adjustment does not consider the recovering subtype
to be likely until after year two, the full model shifts the recovering subtype trajectory downward
towards the man’s initial PFVC value and identify the correct trajectory using a single year of data.
Quantitative results. Table 1 reports MAE for the baselines and the proposed model. We note that
after observing two or more years of data, our model’s errors are smaller than the two baselines (and
statistically significantly so in all but one comparison). Although the B-spline GP improves over the
first baseline, these results suggest that both subpopulation and individual-specific components en-
able more accurate predictions of an individual’s future course as more data are observed. Moreover,
by comparing the proposed model with and without personalization, we see that subtypes alone are
not sufficient and that individual-specific adjustments are critical. These improvements also have
clinical significance. For example, individuals who drop by more than 10 PFVC are candidates for
aggressive immunosuppressive therapy. Out of the 7.5% of individuals in our data who decline by
more than 10 PFVC, our model predicts such a decline at twice the true-positive rate of the B-spline
GP (31% vs. 17%) and with a lower false-positive rate (81% vs. 90%).
4 Conclusion
We have described a hierarchical model for making individualized predictions of disease activity
trajectories that accounts for both latent and observed sources of heterogeneity. We empirically
demonstrated that using all elements of the proposed hierarchy allows our model to dynamically
personalize predictions and reduce error as more data about an individual is collected. Although
our analysis focused on scleroderma, our approach is more broadly applicable to other complex,
heterogeneous diseases [1]. Examples of such diseases include asthma [3], autism [4], and COPD
[5]. There are several promising directions for further developing the ideas presented here. First, we
observed that predictions are less accurate early in the disease course when little data is available to
learn the individual-specific adjustments. To address this shortcoming, it may be possible to leverage
time-dependent covariates in addition to the baseline covariates used here. Second, the quality of our
predictions depends upon the allowed types of individual-specific adjustments encoded in the model.
More sophisticated models of individual variation may further improve performance. Moreover,
approaches for automatically learning the class of possible adjustments would make it possible to
apply our approach to new diseases more quickly.
8
References
[1] J. Craig. Complex diseases: Research and applications. Nature Education, 1(1):184, 2008.
[2] J. Varga, C.P. Denton, and F.M. Wigley. Scleroderma: From Pathogenesis to Comprehensive Manage-
ment. Springer Science & Business Media, 2012.
[3] J. Lötvall et al. Asthma endotypes: a new approach to classification of disease entities within the asthma
syndrome. Journal of Allergy and Clinical Immunology, 127(2):355–360, 2011.
[4] L.D. Wiggins, D.L. Robins, L.B. Adamson, R. Bakeman, and C.C. Henrich. Support for a dimensional
view of autism spectrum disorders in toddlers. Journal of autism and developmental disorders, 42(2):191–
200, 2012.
[5] P.J. Castaldi et al. Cluster analysis in the copdgene study identifies subtypes of smokers with distinct
patterns of airway disease and emphysema. Thorax, 2014.
[6] S. Saria and A. Goldenberg. Subtyping: What Is It and Its Role in Precision Medicine. IEEE Intelligent
Systems, 30, 2015.
[7] D.S. Lee, P.C. Austin, J.L. Rouleau, P.P Liu, D. Naimark, and J.V. Tu. Predicting mortality among patients
hospitalized for heart failure: derivation and validation of a clinical model. Jama, 290(19):2581–2587,
2003.
[8] D. Rizopoulos. Dynamic predictions and prospective accuracy in joint models for longitudinal and time-
to-event data. Biometrics, 67(3):819–829, 2011.
[9] C. Proust-Lima et al. Joint latent class models for longitudinal and time-to-event data: A review. Statisti-
cal Methods in Medical Research, 23(1):74–90, 2014.
[10] K.P. Murphy. Machine learning: a probabilistic perspective. MIT press, 2012.
[11] S. Roberts, M. Osborne, M. Ebden, S. Reece, N. Gibson, and S. Aigrain. Gaussian processes for time-
series modelling. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engi-
neering Sciences, 371(1984):20110550, 2013.
[12] J.Q. Shi, R. Murray-Smith, and D.M. Titterington. Hierarchical gaussian process mixtures for regression.
Statistics and computing, 15(1):31–41, 2005.
[13] A. Gelman and J. Hill. Data analysis using regression and multilevel/hierarchical models. Cambridge
University Press, 2006.
[14] H. Wang et al. High-order multi-task feature learning to identify longitudinal phenotypic markers for
alzheimer’s disease progression prediction. In Advances in Neural Information Processing Systems, pages
1277–1285, 2012.
[15] J. Ross and J. Dy. Nonparametric mixture of gaussian processes with constraints. In Proceedings of the
30th International Conference on Machine Learning (ICML-13), pages 1346–1354, 2013.
[16] P.F. Schulam, F.M. Wigley, and S. Saria. Clustering longitudinal clinical marker trajectories from elec-
tronic health data: Applications to phenotyping and endotype discovery. In Proceedings of the Twinty-
Ninth AAAI Conference on Artificial Intelligence, 2015.
[17] B.M. Marlin. Modeling user rating profiles for collaborative filtering. In Advances in neural information
processing systems, 2003.
[18] G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of
the state-of-the-art and possible extensions. Knowledge and Data Engineering, IEEE Transactions on,
17(6):734–749, 2005.
[19] D. Sontag, K. Collins-Thompson, P.N. Bennett, R.W. White, S. Dumais, and B. Billerbeck. Probabilistic
models for personalizing web search. In Proceedings of the fifth ACM international conference on Web
search and data mining, pages 433–442. ACM, 2012.
[20] C.E. Rasmussen and C.K. Williams. Gaussian Processes for Machine Learning. The MIT Press, 2006.
[21] Y. Allanore et al. Systemic sclerosis. Nature Reviews Disease Primers, 2015.
[22] D. Khanna et al. Clinical course of lung physiology in patients with scleroderma and interstitial lung
disease: analysis of the scleroderma lung study placebo group. Arthritis & Rheumatism, 63(10):3078–
3085, 2011.
[23] J.Q. Shi, B. Wang, E.J. Will, and R.M. West. Mixed-effects gaussian process functional regression models
with application to dose–response curve prediction. Stat. Med., 31(26):3165–3177, 2012.
9
